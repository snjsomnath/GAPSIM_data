{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to GAPSIM GAPSIM (Gothenburg Activity-based Population Simulator) Welcome to GAPSIM , a library designed for modelling synthetic populations for neighbourhoods in Gothenburg, Sweden. This documentation provides an overview of GAPSIM's core functionalities. Key Features 1. Population Synthesis This module generates a synthetic population reflecting real-world demographics. It includes: - Person Generation : Creates individuals based on age, household type, and sex distribution. - Household Formation : Groups individuals into households considering various compositions. - Attribute Assignment : Assigns socioeconomic attributes to individuals and households to match observed distributions. 2. Active Mobility Route Choice This module models route choices for individuals engaged in active mobility, such as walking or cycling. It factors in preferences for route characteristics, ensuring realistic route choice predictions. Application Context Article Information Title : An activity-based synthetic population of Gothenburg, Sweden: Dataset of residents in neighbourhoods Authors : Sanjay Somanath*, Liane Thuvander, Alexander Hollberg Affiliations : Chalmers University of Technology, Department of Architecture and Civil Engineering, Sweden Keywords : Mobility, activity, energy, neighbourhood-planning, demand-modelling, accessibility, equity Abstract The paper presents an end-to-end model for generating a synthetic population of Gothenburg residents, complete with activity schedules and mobility patterns. This model supports neighbourhood planning and integrates primary datasets to create synthetic individuals, households, and activity chains. The model is designed to capture the nuances of a neighbourhood\u2019s built environment and demographic composition. Specifications Data Type : SQL database with multiple linked tables for each neighbourhood Data Sources : Statistics Sweden (SCB), National Household Travel Survey (NHTS), Swedish cadastral agency (Lantm\u00e4teriet), OpenStreetMap, and City of Gothenburg data Accessibility : Available on Zenodo ( 10.5281/zenodo.10801935 ) Value of the Data Agent-Based Models : Provides a high-quality synthetic population for agent-based models. Urban and Neighbourhood Planning : Assists in assessing the impacts of planning strategies. Energy Demand Modelling : Helps in evaluating the effects of different energy policies. Behavioural Studies : Facilitates neighbourhood-level behavioural studies. Digital Twinning and Urban Simulation : Supports the creation of digital twins and comprehensive simulations. Getting Started To begin using TripSender, install the library and explore its core modules. The documentation offers detailed instructions, examples, and best practices to help you utilize the library's full potential. Note: This package is still a Work In Progress. Please contact the authors for access to the raw data required for population synthesis or on suggestions to setup the data pipelines yourself. We hope TripSender enhances your neighbourhood modeling projects and contributes to efficient and sustainable neighbourhood planning. For detailed guidance on each module, please refer to the respective sections of the documentation. Happy modeling! API Documentation Activity Building House Household IO Location Assignment NHTS OD Person Population Routing Sampler Synthpop Utils","title":"Welcome to tripsender"},{"location":"#introduction-to-gapsim","text":"GAPSIM (Gothenburg Activity-based Population Simulator) Welcome to GAPSIM , a library designed for modelling synthetic populations for neighbourhoods in Gothenburg, Sweden. This documentation provides an overview of GAPSIM's core functionalities.","title":"Introduction to GAPSIM"},{"location":"#key-features","text":"","title":"Key Features"},{"location":"#1-population-synthesis","text":"This module generates a synthetic population reflecting real-world demographics. It includes: - Person Generation : Creates individuals based on age, household type, and sex distribution. - Household Formation : Groups individuals into households considering various compositions. - Attribute Assignment : Assigns socioeconomic attributes to individuals and households to match observed distributions.","title":"1. Population Synthesis"},{"location":"#2-active-mobility-route-choice","text":"This module models route choices for individuals engaged in active mobility, such as walking or cycling. It factors in preferences for route characteristics, ensuring realistic route choice predictions.","title":"2. Active Mobility Route Choice"},{"location":"#application-context","text":"","title":"Application Context"},{"location":"#article-information","text":"Title : An activity-based synthetic population of Gothenburg, Sweden: Dataset of residents in neighbourhoods Authors : Sanjay Somanath*, Liane Thuvander, Alexander Hollberg Affiliations : Chalmers University of Technology, Department of Architecture and Civil Engineering, Sweden Keywords : Mobility, activity, energy, neighbourhood-planning, demand-modelling, accessibility, equity","title":"Article Information"},{"location":"#abstract","text":"The paper presents an end-to-end model for generating a synthetic population of Gothenburg residents, complete with activity schedules and mobility patterns. This model supports neighbourhood planning and integrates primary datasets to create synthetic individuals, households, and activity chains. The model is designed to capture the nuances of a neighbourhood\u2019s built environment and demographic composition.","title":"Abstract"},{"location":"#specifications","text":"Data Type : SQL database with multiple linked tables for each neighbourhood Data Sources : Statistics Sweden (SCB), National Household Travel Survey (NHTS), Swedish cadastral agency (Lantm\u00e4teriet), OpenStreetMap, and City of Gothenburg data Accessibility : Available on Zenodo ( 10.5281/zenodo.10801935 )","title":"Specifications"},{"location":"#value-of-the-data","text":"Agent-Based Models : Provides a high-quality synthetic population for agent-based models. Urban and Neighbourhood Planning : Assists in assessing the impacts of planning strategies. Energy Demand Modelling : Helps in evaluating the effects of different energy policies. Behavioural Studies : Facilitates neighbourhood-level behavioural studies. Digital Twinning and Urban Simulation : Supports the creation of digital twins and comprehensive simulations.","title":"Value of the Data"},{"location":"#getting-started","text":"To begin using TripSender, install the library and explore its core modules. The documentation offers detailed instructions, examples, and best practices to help you utilize the library's full potential. Note: This package is still a Work In Progress. Please contact the authors for access to the raw data required for population synthesis or on suggestions to setup the data pipelines yourself. We hope TripSender enhances your neighbourhood modeling projects and contributes to efficient and sustainable neighbourhood planning. For detailed guidance on each module, please refer to the respective sections of the documentation. Happy modeling!","title":"Getting Started"},{"location":"#api-documentation","text":"Activity Building House Household IO Location Assignment NHTS OD Person Population Routing Sampler Synthpop Utils","title":"API Documentation"},{"location":"activity/","text":"Activity Represents an activity performed by an individual, based on a sampled and matched activity sequence from the National Household Travel Survey (NHTS). An activity object consists of Activity purpose Start time Duration End time Mode of travel Attributes: Name Type Description start_time time The starting time of the activity. duration_minutes int The duration of the activity in minutes. duration_timedelta timedelta The duration of the activity as a timedelta object. end_time time The ending time of the activity. purpose str The purpose of the activity (e.g., work, school, shopping). mode str The mode of transportation used for the activity (e.g., walking, driving). destination str The destination of the activity. destination_coordinates tuple The coordinates of the destination. origin str The origin of the activity. origin_coordinates tuple The coordinates of the origin. calculated_duration timedelta The calculated duration of the trip if different from the provided duration. route list The route taken for the activity, if applicable. Source code in tripsender\\activity.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class Activity : \"\"\" Represents an activity performed by an individual, based on a sampled and matched activity sequence from the National Household Travel Survey (NHTS). An activity object consists of: - Activity purpose - Start time - Duration - End time - Mode of travel Attributes: start_time (datetime.time): The starting time of the activity. duration_minutes (int): The duration of the activity in minutes. duration_timedelta (timedelta): The duration of the activity as a timedelta object. end_time (datetime.time): The ending time of the activity. purpose (str): The purpose of the activity (e.g., work, school, shopping). mode (str, optional): The mode of transportation used for the activity (e.g., walking, driving). destination (str, optional): The destination of the activity. destination_coordinates (tuple, optional): The coordinates of the destination. origin (str, optional): The origin of the activity. origin_coordinates (tuple, optional): The coordinates of the origin. calculated_duration (timedelta, optional): The calculated duration of the trip if different from the provided duration. route (list, optional): The route taken for the activity, if applicable. \"\"\" def __init__ ( self , start_time , duration_minutes , purpose , mode = None ): \"\"\" Initializes an Activity object with the given parameters. Args: start_time (str or datetime): The start time of the activity. Can be a string or a datetime object. duration_minutes (int): The duration of the activity in minutes. purpose (str): The purpose of the activity. mode (str, optional): The mode of transportation. Defaults to None. \"\"\" # Use _parse_time_input for consistent time parsing parsed_datetime = self . _parse_time_input ( start_time ) self . start_time = parsed_datetime . time () if parsed_datetime else None self . duration_minutes = duration_minutes self . duration_timedelta = self . duration () self . end_time = ( datetime . combine ( datetime . today (), self . start_time ) + timedelta ( minutes = duration_minutes )) . time () self . purpose = purpose self . mode = mode self . destination = None self . destination_coordinates = None self . origin = None self . origin_coordinates = None self . calculated_duration = None self . route = None def __repr__ ( self ): return f \" { self . start_time . strftime ( '%H:%M' ) } - { self . purpose } ( { self . duration_minutes } mins)\" def _parse_time_input ( self , time_input ): \"\"\" Parses time input into a datetime object. Args: time_input (str or datetime.time): The time input to be parsed. Returns: datetime.datetime: The parsed datetime object. example: _parse_time_input(\"1200\") -> datetime.datetime(1900, 1, 1, 12, 0) _parse_time_input(\"12:00\") -> datetime.datetime(1900, 1, 1, 12, 0) _parse_time_input(datetime.time(12, 0)) -> datetime.datetime(1900, 1, 1, 12, 0) \"\"\" if isinstance ( time_input , str ): if ':' in time_input : return datetime . strptime ( time_input , '%H:%M' ) else : return datetime . strptime ( time_input , '%H%M' ) elif isinstance ( time_input , time ): return datetime . combine ( datetime . today (), time_input ) elif isinstance ( time_input , datetime ): return time_input else : logger . error ( \"Time input must be in the format HH:MM or HHMM or datetime.time or datetime.datetime\" ) return None def __str__ ( self ): return f \"Start Time: { self . start_time } , End Time: { self . end_time } , Purpose: { self . purpose } , Mode: { self . mode } \" def duration ( self ): return timedelta ( minutes = self . duration_minutes ) __init__ ( start_time , duration_minutes , purpose , mode = None ) Initializes an Activity object with the given parameters. Parameters: Name Type Description Default start_time str or datetime The start time of the activity. Can be a string or a datetime object. required duration_minutes int The duration of the activity in minutes. required purpose str The purpose of the activity. required mode str The mode of transportation. Defaults to None. None Source code in tripsender\\activity.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def __init__ ( self , start_time , duration_minutes , purpose , mode = None ): \"\"\" Initializes an Activity object with the given parameters. Args: start_time (str or datetime): The start time of the activity. Can be a string or a datetime object. duration_minutes (int): The duration of the activity in minutes. purpose (str): The purpose of the activity. mode (str, optional): The mode of transportation. Defaults to None. \"\"\" # Use _parse_time_input for consistent time parsing parsed_datetime = self . _parse_time_input ( start_time ) self . start_time = parsed_datetime . time () if parsed_datetime else None self . duration_minutes = duration_minutes self . duration_timedelta = self . duration () self . end_time = ( datetime . combine ( datetime . today (), self . start_time ) + timedelta ( minutes = duration_minutes )) . time () self . purpose = purpose self . mode = mode self . destination = None self . destination_coordinates = None self . origin = None self . origin_coordinates = None self . calculated_duration = None self . route = None ActivitySequence Source code in tripsender\\activity.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 class ActivitySequence : instances : List [ 'ActivitySequence' ] = [] samples : List [ 'ActivitySequence' ] = [] def __init__ ( self ): self . person = None self . activities = [] self . disruptions = 0 # Number of disruptions in the sequence @classmethod def return_person_df ( cls ): list_of_person_dicts = [] for activity_sequence in cls . samples : list_of_person_dicts . append ( activity_sequence . sampled_person ) df = pd . DataFrame ( list_of_person_dicts ) # Create a column called ActivitySequence that contains the ActivitySequence instance df [ 'ActivitySequence' ] = cls . samples return df @classmethod def clear_instances ( cls ): cls . instances = [] @classmethod def clear_samples ( cls ): cls . samples = [] def __repr__ ( self ): return \" \\n \" . join ( repr ( activity ) for activity in self . activities ) def total_duration ( self ): return sum ([ activity . duration () for activity in self . activities ], datetime . timedelta ()) def __str__ ( self ): return ' \\n ' . join ( str ( activity ) for activity in self . activities ) def return_gdf ( self ): gdf_data = [] activity_sequence = self for activity in activity_sequence . activities : if activity . purpose == \"Transit\" : next_activity = activity_sequence . activities [ activity_sequence . activities . index ( activity ) + 1 ] # The below check seems deprecated # if isinstance(activity.destination, Point): if activity . destination != \"Travel\" : gdf_dict = { 'geometry' : activity . route , 'mode' : activity . mode , 'origin' : activity . origin_coordinates , 'destination' : activity . destination_coordinates , 'sampled_duration' : activity . duration_minutes , 'calculated_duration' : activity . calculated_duration , 'start_time' : activity . start_time , 'purpose' : next_activity . purpose } # Append dictionary to list gdf_data . append ( gdf_dict ) elif activity . destination == \"Travel\" : # If the destination says \"Travel\", then it's a travel activity and we don't have a destination # So we just plot a point at the origin of the travel activity gdf_dict = { 'geometry' : activity . origin_coordinates , 'mode' : activity . mode , 'origin' : activity . origin_coordinates , 'destination' : activity . destination_coordinates , 'sampled_duration' : activity . duration_minutes , 'calculated_duration' : activity . calculated_duration , 'start_time' : activity . start_time , 'purpose' : activity . purpose } # Append dictionary to list gdf_data . append ( gdf_dict ) else : logger . error ( \"Destination is not a Point or 'Travel'\" ) # Create GeoDataFrame from collected data gdf = gpd . GeoDataFrame ( gdf_data ) return gdf def plot ( self , plot_type = '2d' ): gdf = self . return_gdf () home = gdf . iloc [ 0 ][ 'origin' ] # Identify unique modes of transport unique_modes = set ( row [ 'mode' ] for index , row in gdf . iterrows ()) # Create a color map for the modes colors = plt . cm . get_cmap ( 'viridis' , len ( unique_modes )) mode_colors = { mode : colors ( i ) for i , mode in enumerate ( unique_modes )} # Check if gdf is not empty before proceeding if not gdf . empty : # Set geometry column explicitly in case it's not automatically recognized gdf = gdf . set_geometry ( 'geometry' ) # Set CRS to EPSG:3006 gdf . crs = \"epsg:3006\" if plot_type == '2d' : # 2D Plot ax = gdf . plot ( column = 'mode' , legend = True , figsize = ( 10 , 10 )) ax . set_title ( \"Activity Routes by Mode\" ) ax . set_xlabel ( \"Longitude\" ) ax . set_ylabel ( \"Latitude\" ) # Add home location ax . scatter ( home . x , home . y , color = 'red' , marker = '*' , s = 100 , label = 'Home' ) elif plot_type == 'spacetimecube_static' : # Static Space-Time Cube fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( 111 , projection = '3d' ) # Convert start_time to total seconds from the start of the day and then to hours gdf [ 'time_hours' ] = gdf [ 'start_time' ] . apply ( lambda x : pd . Timedelta ( str ( x )) . total_seconds () / 3600 ) for index , row in gdf . iterrows (): x , y = zip ( * [( point [ 0 ], point [ 1 ]) for point in list ( row [ 'geometry' ] . coords )]) z = [ row [ 'time_hours' ]] * len ( x ) mode_color = mode_colors [ row [ 'mode' ]] ax . plot ( x , y , z , linestyle = '-' , marker = '' , color = mode_color ) # Use color mapped to mode # Place a text label near the start of the activity label_pos = 0 ax . text ( x [ label_pos ], y [ label_pos ], z [ label_pos ], f \" { row [ 'purpose' ] } \" , color = 'black' , fontsize = 8 , ha = 'right' ) if index < len ( gdf ) - 1 : next_row = gdf . iloc [ index + 1 ] ax . plot ([ x [ - 1 ], x [ - 1 ]], [ y [ - 1 ], y [ - 1 ]], [ row [ 'time_hours' ], next_row [ 'time_hours' ]], 'k:' , linewidth = 1 ) # After iterating through all rows, get the last activity's coordinates and time last_activity = gdf . iloc [ - 1 ] last_coords = list ( last_activity [ 'geometry' ] . coords ) # Convert coordinates to a list last_x , last_y = last_coords [ - 1 ] # Take the last point of the last activity last_z = last_activity [ 'time_hours' ] # Connect the last activity to home with a vertical dotted line back to the start of the day ax . plot ([ last_x , home . x ], [ last_y , home . y ], [ last_z , 0 ], 'k:' , linewidth = 1 , ) ax . set_xlabel ( '' ) ax . set_ylabel ( '' ) ax . set_zlabel ( 'Time (Hours from start of day)' ) ax . set_zticks ( range ( 0 , 24 , 3 )) # Set z-axis to display each hour ax . set_zticklabels ([ f \" { i } h\" for i in range ( 0 , 24 , 3 )]) # Label each tick with the hour # Get the current xlim and ylim xmin , xmax = ax . get_xlim () ymin , ymax = ax . get_ylim () # Calculate the range of the x and y axis xrange = xmax - xmin yrange = ymax - ymin # Set the x and y ticks to display relative distances # Define the number of ticks you want num_ticks = 5 # Example: 5 ticks # Set x and y ticks ax . set_xticks ([ xmin + i * ( xrange / ( num_ticks - 1 )) for i in range ( num_ticks )]) ax . set_yticks ([ ymin + i * ( yrange / ( num_ticks - 1 )) for i in range ( num_ticks )]) # Set x and y tick labels ax . set_xticklabels ([ f \" { int ( i * ( xrange / ( num_ticks - 1 ))) } m\" for i in range ( num_ticks )]) ax . set_yticklabels ([ f \" { int ( i * ( yrange / ( num_ticks - 1 ))) } m\" for i in range ( num_ticks )]) # Reduce the grid lineweight ax . xaxis . _axinfo [ 'grid' ] . update ( linewidth = 0.1 ) ax . yaxis . _axinfo [ 'grid' ] . update ( linewidth = 0.1 ) ax . zaxis . _axinfo [ 'grid' ] . update ( linewidth = 0.1 ) # Add home location at the start of the day with a green marker ax . scatter ( home . x , home . y , 0 , color = 'green' , marker = \"v\" , s = 100 , label = 'Start Home' ) # Add home location at the end of the day with a red marker ax . scatter ( home . x , home . y , last_z , color = 'red' , marker = \"v\" , s = 100 , label = 'End Home' ) # Reduce the thickness of the text ax . xaxis . label . set_size ( 8 ) ax . yaxis . label . set_size ( 8 ) ax . zaxis . label . set_size ( 8 ) # Ticks ax . xaxis . set_tick_params ( labelsize = 8 ) ax . yaxis . set_tick_params ( labelsize = 8 ) ax . zaxis . set_tick_params ( labelsize = 8 ) # Prepare legend entries for modes of transport legend_entries = [ Line2D ([ 0 ], [ 0 ], color = mode_colors [ mode ], lw = 4 , label = mode ) for mode in unique_modes ] # Add home markers to the legend legend_entries . append ( Line2D ([ 0 ], [ 0 ], marker = 'v' , color = 'green' , label = 'Start Home' , markersize = 10 , linestyle = 'None' )) legend_entries . append ( Line2D ([ 0 ], [ 0 ], marker = 'v' , color = 'red' , label = 'End Home' , markersize = 10 , linestyle = 'None' )) # Set the legend with the mode entries ax . legend ( handles = legend_entries ) plt . show () elif plot_type == 'spacetimecube_interactive' : # Interactive Space-Time Cube traces = [] legend_added = {} # To track which modes have been added to the legend # Color map for modes of transport unique_modes = list ( set ( row [ 'mode' ] for index , row in gdf . iterrows ())) colors = plt . cm . get_cmap ( 'viridis' , len ( unique_modes )) mode_colors = { mode : f 'rgb { colors ( i )[: 3 ] } ' for i , mode in enumerate ( unique_modes )} # Determine the range for x and y axis based on the geometry all_coords = [ coord for row in gdf [ 'geometry' ] for coord in list ( row . coords )] all_x , all_y = zip ( * all_coords ) xmin , xmax = min ( all_x ), max ( all_x ) ymin , ymax = min ( all_y ), max ( all_y ) # Adjust the range if you want to start from 0 xrange = xmax - xmin yrange = ymax - ymin # Plot each activity segment with transitions for index , row in gdf . iterrows (): x , y = zip ( * [( coord [ 0 ] - xmin , coord [ 1 ] - ymin ) for coord in list ( row [ 'geometry' ] . coords )]) # Adjusted coordinates z = [ pd . Timedelta ( str ( row [ 'start_time' ])) . total_seconds () / 3600 ] * len ( x ) # Time in hours mode_color = mode_colors [ row [ 'mode' ]] # Check if the mode is already added to legend show_legend = row [ 'mode' ] not in legend_added legend_added [ row [ 'mode' ]] = True # Activity trace trace = go . Scatter3d ( x = x , y = y , z = z , mode = 'lines' , name = row [ 'mode' ], line = dict ( color = mode_color , width = 4 ), hoverinfo = 'text' , text = f \"Mode: { row [ 'mode' ] } , Duration: { row [ 'sampled_duration' ] } mins, Purpose: { row [ 'purpose' ] } \" , showlegend = show_legend ) traces . append ( trace ) # Transition to next activity or home with a dotted line if index < len ( gdf ) - 1 : next_row = gdf . iloc [ index + 1 ] next_x , next_y = next_row [ 'origin' ] . x - xmin , next_row [ 'origin' ] . y - ymin # Adjusted coordinates next_z = pd . Timedelta ( str ( next_row [ 'start_time' ])) . total_seconds () / 3600 traces . append ( go . Scatter3d ( x = [ x [ - 1 ], next_x ], y = [ y [ - 1 ], next_y ], z = [ z [ - 1 ], next_z ], mode = 'lines' , line = dict ( color = 'black' , width = 2 , dash = 'dot' ), showlegend = False # Hide these transitions from legend )) # Calculate home coordinates adjusted for the plot home_x , home_y = home . x - xmin , home . y - ymin # Adjusted coordinates home_start_z = 0 # Start of the day in hours home_end_z = pd . Timedelta ( str ( gdf . iloc [ - 1 ][ 'start_time' ])) . total_seconds () / 3600 # End of the last activity in hours # Home location at the start of the day (green marker) traces . append ( go . Scatter3d ( x = [ home_x ], y = [ home_y ], z = [ home_start_z ], mode = 'markers' , marker = dict ( size = 10 , color = 'green' ), name = 'Start Home' , hoverinfo = 'text' , text = 'Start Home' )) # Transition from home to the first activity (dotted line) if len ( gdf ) > 0 : first_activity = gdf . iloc [ 0 ] first_coords = list ( first_activity [ 'geometry' ] . coords ) first_x , first_y = first_coords [ 0 ][ 0 ] - xmin , first_coords [ 0 ][ 1 ] - ymin # Adjusted coordinates of the first point of the first activity first_z = pd . Timedelta ( str ( first_activity [ 'start_time' ])) . total_seconds () / 3600 # Start time of the first activity in hours # Transition from home to the first activity (dotted line) traces . append ( go . Scatter3d ( x = [ home_x , first_x ], y = [ home_y , first_y ], z = [ home_start_z , first_z ], mode = 'lines' , line = dict ( color = 'black' , width = 2 , dash = 'dot' ), showlegend = False # This transition should not appear in the legend )) # Transition from the last activity back to home (dotted line) if len ( gdf ) > 0 : last_activity = gdf . iloc [ - 1 ] last_coords = list ( last_activity [ 'geometry' ] . coords ) last_x , last_y = last_coords [ - 1 ][ 0 ] - xmin , last_coords [ - 1 ][ 1 ] - ymin # Adjusted coordinates traces . append ( go . Scatter3d ( x = [ last_x , home_x ], y = [ last_y , home_y ], z = [ home_end_z , home_end_z ], mode = 'lines' , line = dict ( color = 'black' , width = 2 , dash = 'dot' ), showlegend = False )) # Home location at the end of the day (red marker) traces . append ( go . Scatter3d ( x = [ home_x ], y = [ home_y ], z = [ home_end_z ], mode = 'markers' , marker = dict ( size = 10 , color = 'red' ), name = 'End Home' , hoverinfo = 'text' , text = 'End Home' )) # Layout configuration, including x and y axis ticks and labels layout = go . Layout ( title = \"Space-Time Cube Visualization\" , scene = dict ( # Axis configurations (as in the previous code) ), margin = dict ( r = 0 , l = 0 , b = 0 , t = 50 ) ) # Create figure with traces and layout fig = go . Figure ( data = traces , layout = layout ) # Display the interactive plot fig . show () else : print ( \"No routes available for plotting.\" ) return gdf def from_nhts ( self , df ): \"\"\" Create an ActivitySequence object from a sampled and matched activity sequence from the National Household Travel Survey (NHTS). Attributes: df (pandas.DataFrame): A DataFrame containing the sampled and matched activity sequence from the NHTS. Returns: ActivitySequence: An ActivitySequence object representing the activity sequence. \"\"\" current_date = datetime . now () . date () start_of_day = datetime . combine ( current_date , time ( 3 , 0 )) end_of_day = start_of_day + timedelta ( days = 1 ) # Some df checks to make sure that df makes sense # If activity duration is 0 days 00:00:00 remove the row #df = df[df['activity_duration_minutes'] != pd.Timedelta(seconds=0)] # Reset index, drop means that the old index is not added as a column # If the last trip of the day is not Home, then get the duration of the last activity based on sampled activity duration # And add a travel activity to get home that starts after the sampled duration of the last activity last_row = df . iloc [ - 1 ] if last_row [ 'purpose' ] != 'Home' : df = add_travel_home_activity ( df ) #df = df.reset_index(drop=False) #logger.info('Number of activities in df: {}'.format(len(df))) #logger.info(\" Starting day from Home...\") # Add a column called is_worker to the dataframe #df['is_worker'] = False #.loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = False is_worker = False for index , row in df . iterrows (): #logger.info(\" Traveling to activity {}\".format(row['purpose'])) # Travel to activity travel_duration = calculate_duration ( row [ 'start_time' ] - row [ 'travel_duration_minutes' ], row [ 'start_time' ]) t_time = row [ 'start_time' ] t_duration = travel_duration # What if we call this \"Transit\" instead of \"Travel\"? t_purpose = 'Transit' t_mode = row [ 'mode' ] transit_activity = Activity ( t_time , t_duration , t_purpose , t_mode ) transit_activity . destination = row [ 'purpose' ] self . activities . append ( transit_activity ) # Activity itself #logger.info(\" Current activity {}\".format(row['purpose'])) #logger.info(\" Duration of activity {}: {}\".format(row['purpose'], row['activity_duration_minutes'])) if pd . isna ( row [ 'activity_duration_minutes' ]): # If there is no next activity, then the activity duration is the time until the end of the day a_duration = 0 else : a_duration = calculate_duration ( row [ 'end_time' ] - row [ 'activity_duration_minutes' ], row [ 'end_time' ]) # Only add activity if it has a duration greater than 0 or if it is the last activity of the day if a_duration > 0 or index < len ( df ) - 1 or row [ \"purpose\" ] == \"Pickup/Dropoff child\" : a_time = row [ 'end_time' ] a_purpose = row [ 'purpose' ] if a_purpose == 'Work' : is_worker = True if a_purpose != 'Travel' : # Sometimes the activity itself is a travel activity a_mode = None else : a_mode = row [ 'mode' ] self . activities . append ( Activity ( a_time , a_duration , a_purpose , a_mode )) # Handle initial home activity # If the first activity of the day is not at 3:00, then there must be an initial home activity if df . iloc [ 0 ][ 'start_time' ] > start_of_day : # Calculate duration of initial home activity - from 3:00 to start of first activity h_time = start_of_day h_duration = calculate_duration ( start_of_day , df . iloc [ 0 ][ 'start_time' ]) h_purpose = 'Home' h_mode = None self . activities . insert ( 0 , Activity ( h_time , h_duration , h_purpose , h_mode )) # Handle final home activity # If the last activity of the day is not at 3:00, then there must be a final home activity last_activity = self . activities [ - 1 ] last_activity_end_time = datetime . combine ( current_date , last_activity . start_time ) # Extract minutes from the timedelta object last_activity_duration_minutes = last_activity . duration () . total_seconds () / 60 last_activity_end_time += timedelta ( minutes = last_activity_duration_minutes ) if last_activity_end_time < end_of_day : fh_time = last_activity_end_time fh_duration = calculate_duration ( last_activity_end_time , end_of_day ) fh_purpose = 'Home' fh_mode = None self . activities . append ( Activity ( fh_time , fh_duration , fh_purpose , fh_mode )) #logger.info(\" Heading home...\") # Update the is_worker column #df['is_worker'] = is_worker # .loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = is_worker # Extract person attributes self . sampled_person = df . iloc [ 0 ][[ 'id' , 'sex' , 'age_group' , 'house_type' , 'child_count' , 'adult_count' , 'household_type' , 'car_count' , 'is_worker' ]] . to_dict () # Validate ActivitySequence object and add it to the list of instances if valid if not self . is_valid (): #logger.error(\"ActivitySequence is not valid\") return False # Add ActivitySequence object to the list of instances self . samples . append ( self ) return self def is_valid ( self ): \"\"\" Validates the ActivitySequence object. Specifically, it checks the following: - Start time is before end time for each activity - Duration of each activity is positive - Activities are in increasing order of start time - Activities do not overlap - Sum of activity durations is 24 hours - There is a \"Transit\" activity - Mode and purpose are provided for each activity Returns: bool: True if the ActivitySequence is valid, False otherwise. \"\"\" # Check if there are any activities to validate if not self . activities : return False # Check if start time of an activity is before its end time for activity in self . activities : if activity . start_time >= activity . end_time : # Check for the HOME exception if activity . purpose == 'Home' and activity . end_time <= time ( 12 , 0 ): # Assuming HOME can only go till noon of the next day continue elif activity . purpose == \"Pickup/Dropoff child\" : continue else : #logger.error(f\"Start time is not before end time for activity: {activity}\") return False # Check if any activity has a negative duration for activity in self . activities : if activity . duration_minutes <= 0 and activity . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Negative or zero duration for activity: {activity}\") return False # Check if activities are in increasing order of start time for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . start_time >= self . activities [ i + 1 ] . start_time and self . activities [ i ] . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Activities are not in increasing order of start time: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't overlap for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . end_time > self . activities [ i + 1 ] . start_time : #logger.error(f\"Activities overlap: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't exceed 24 hours, except for HOME if self . activities [ - 1 ] . purpose != 'Home' and self . activities [ - 1 ] . end_time > time ( 23 , 59 ): #logger.error(f\"Activity sequence exceeds 24 hours: {self.activities[-1]}\") return False # Check the mode and purpose for each activity for activity in self . activities : if activity . purpose in [ \"Travel\" ]: if not activity . mode or not activity . purpose : #logger.error(f\"Missing mode or purpose for activity: {activity}\") return False # Check if sum of activity durations is 24 hours if sum ([ activity . duration_minutes for activity in self . activities ]) != 1440 : #logger.error(\"Sum of activity durations is not 24 hours\") return False # Check if there is a \"Transit\" activity before every non-\"Transit\" activity (except for the first activity) for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose != 'Transit' and self . activities [ i - 1 ] . purpose != 'Transit' : #logger.error(f\"No transit activity before non-transit activity: {self.activities[i]}\") return False # Make sure that there are no two consecutive \"Transit\" activities for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose == 'Transit' and self . activities [ i - 1 ] . purpose == 'Transit' : #logger.error(f\"Two consecutive transit activities: {self.activities[i]}\") return False return True from_nhts ( df ) Create an ActivitySequence object from a sampled and matched activity sequence from the National Household Travel Survey (NHTS). Attributes: Name Type Description df DataFrame A DataFrame containing the sampled and matched activity sequence from the NHTS. Returns: Name Type Description ActivitySequence An ActivitySequence object representing the activity sequence. Source code in tripsender\\activity.py 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 def from_nhts ( self , df ): \"\"\" Create an ActivitySequence object from a sampled and matched activity sequence from the National Household Travel Survey (NHTS). Attributes: df (pandas.DataFrame): A DataFrame containing the sampled and matched activity sequence from the NHTS. Returns: ActivitySequence: An ActivitySequence object representing the activity sequence. \"\"\" current_date = datetime . now () . date () start_of_day = datetime . combine ( current_date , time ( 3 , 0 )) end_of_day = start_of_day + timedelta ( days = 1 ) # Some df checks to make sure that df makes sense # If activity duration is 0 days 00:00:00 remove the row #df = df[df['activity_duration_minutes'] != pd.Timedelta(seconds=0)] # Reset index, drop means that the old index is not added as a column # If the last trip of the day is not Home, then get the duration of the last activity based on sampled activity duration # And add a travel activity to get home that starts after the sampled duration of the last activity last_row = df . iloc [ - 1 ] if last_row [ 'purpose' ] != 'Home' : df = add_travel_home_activity ( df ) #df = df.reset_index(drop=False) #logger.info('Number of activities in df: {}'.format(len(df))) #logger.info(\" Starting day from Home...\") # Add a column called is_worker to the dataframe #df['is_worker'] = False #.loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = False is_worker = False for index , row in df . iterrows (): #logger.info(\" Traveling to activity {}\".format(row['purpose'])) # Travel to activity travel_duration = calculate_duration ( row [ 'start_time' ] - row [ 'travel_duration_minutes' ], row [ 'start_time' ]) t_time = row [ 'start_time' ] t_duration = travel_duration # What if we call this \"Transit\" instead of \"Travel\"? t_purpose = 'Transit' t_mode = row [ 'mode' ] transit_activity = Activity ( t_time , t_duration , t_purpose , t_mode ) transit_activity . destination = row [ 'purpose' ] self . activities . append ( transit_activity ) # Activity itself #logger.info(\" Current activity {}\".format(row['purpose'])) #logger.info(\" Duration of activity {}: {}\".format(row['purpose'], row['activity_duration_minutes'])) if pd . isna ( row [ 'activity_duration_minutes' ]): # If there is no next activity, then the activity duration is the time until the end of the day a_duration = 0 else : a_duration = calculate_duration ( row [ 'end_time' ] - row [ 'activity_duration_minutes' ], row [ 'end_time' ]) # Only add activity if it has a duration greater than 0 or if it is the last activity of the day if a_duration > 0 or index < len ( df ) - 1 or row [ \"purpose\" ] == \"Pickup/Dropoff child\" : a_time = row [ 'end_time' ] a_purpose = row [ 'purpose' ] if a_purpose == 'Work' : is_worker = True if a_purpose != 'Travel' : # Sometimes the activity itself is a travel activity a_mode = None else : a_mode = row [ 'mode' ] self . activities . append ( Activity ( a_time , a_duration , a_purpose , a_mode )) # Handle initial home activity # If the first activity of the day is not at 3:00, then there must be an initial home activity if df . iloc [ 0 ][ 'start_time' ] > start_of_day : # Calculate duration of initial home activity - from 3:00 to start of first activity h_time = start_of_day h_duration = calculate_duration ( start_of_day , df . iloc [ 0 ][ 'start_time' ]) h_purpose = 'Home' h_mode = None self . activities . insert ( 0 , Activity ( h_time , h_duration , h_purpose , h_mode )) # Handle final home activity # If the last activity of the day is not at 3:00, then there must be a final home activity last_activity = self . activities [ - 1 ] last_activity_end_time = datetime . combine ( current_date , last_activity . start_time ) # Extract minutes from the timedelta object last_activity_duration_minutes = last_activity . duration () . total_seconds () / 60 last_activity_end_time += timedelta ( minutes = last_activity_duration_minutes ) if last_activity_end_time < end_of_day : fh_time = last_activity_end_time fh_duration = calculate_duration ( last_activity_end_time , end_of_day ) fh_purpose = 'Home' fh_mode = None self . activities . append ( Activity ( fh_time , fh_duration , fh_purpose , fh_mode )) #logger.info(\" Heading home...\") # Update the is_worker column #df['is_worker'] = is_worker # .loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = is_worker # Extract person attributes self . sampled_person = df . iloc [ 0 ][[ 'id' , 'sex' , 'age_group' , 'house_type' , 'child_count' , 'adult_count' , 'household_type' , 'car_count' , 'is_worker' ]] . to_dict () # Validate ActivitySequence object and add it to the list of instances if valid if not self . is_valid (): #logger.error(\"ActivitySequence is not valid\") return False # Add ActivitySequence object to the list of instances self . samples . append ( self ) return self is_valid () Validates the ActivitySequence object. Specifically, it checks the following: - Start time is before end time for each activity - Duration of each activity is positive - Activities are in increasing order of start time - Activities do not overlap - Sum of activity durations is 24 hours - There is a \"Transit\" activity - Mode and purpose are provided for each activity Returns: bool: True if the ActivitySequence is valid, False otherwise. Source code in tripsender\\activity.py 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 def is_valid ( self ): \"\"\" Validates the ActivitySequence object. Specifically, it checks the following: - Start time is before end time for each activity - Duration of each activity is positive - Activities are in increasing order of start time - Activities do not overlap - Sum of activity durations is 24 hours - There is a \"Transit\" activity - Mode and purpose are provided for each activity Returns: bool: True if the ActivitySequence is valid, False otherwise. \"\"\" # Check if there are any activities to validate if not self . activities : return False # Check if start time of an activity is before its end time for activity in self . activities : if activity . start_time >= activity . end_time : # Check for the HOME exception if activity . purpose == 'Home' and activity . end_time <= time ( 12 , 0 ): # Assuming HOME can only go till noon of the next day continue elif activity . purpose == \"Pickup/Dropoff child\" : continue else : #logger.error(f\"Start time is not before end time for activity: {activity}\") return False # Check if any activity has a negative duration for activity in self . activities : if activity . duration_minutes <= 0 and activity . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Negative or zero duration for activity: {activity}\") return False # Check if activities are in increasing order of start time for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . start_time >= self . activities [ i + 1 ] . start_time and self . activities [ i ] . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Activities are not in increasing order of start time: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't overlap for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . end_time > self . activities [ i + 1 ] . start_time : #logger.error(f\"Activities overlap: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't exceed 24 hours, except for HOME if self . activities [ - 1 ] . purpose != 'Home' and self . activities [ - 1 ] . end_time > time ( 23 , 59 ): #logger.error(f\"Activity sequence exceeds 24 hours: {self.activities[-1]}\") return False # Check the mode and purpose for each activity for activity in self . activities : if activity . purpose in [ \"Travel\" ]: if not activity . mode or not activity . purpose : #logger.error(f\"Missing mode or purpose for activity: {activity}\") return False # Check if sum of activity durations is 24 hours if sum ([ activity . duration_minutes for activity in self . activities ]) != 1440 : #logger.error(\"Sum of activity durations is not 24 hours\") return False # Check if there is a \"Transit\" activity before every non-\"Transit\" activity (except for the first activity) for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose != 'Transit' and self . activities [ i - 1 ] . purpose != 'Transit' : #logger.error(f\"No transit activity before non-transit activity: {self.activities[i]}\") return False # Make sure that there are no two consecutive \"Transit\" activities for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose == 'Transit' and self . activities [ i - 1 ] . purpose == 'Transit' : #logger.error(f\"Two consecutive transit activities: {self.activities[i]}\") return False return True Location Represents a location in the simulation, such as a home, work, school, or other destination. Attributes: Name Type Description location_type str The type of location (e.g., home, work, school). location_name str The name of the location. location_coordinates Point The coordinates of the location. location_amenity str The amenity of the location (e.g., hospital, park). route_car Route The route to the location by car. route_walk Route The route to the location by walking. route_bike Route The route to the location by biking. Source code in tripsender\\activity.py 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 class Location : \"\"\" Represents a location in the simulation, such as a home, work, school, or other destination. Attributes: location_type (str): The type of location (e.g., home, work, school). location_name (str): The name of the location. location_coordinates (Point): The coordinates of the location. location_amenity (str, optional): The amenity of the location (e.g., hospital, park). route_car (Route, optional): The route to the location by car. route_walk (Route, optional): The route to the location by walking. route_bike (Route, optional): The route to the location by biking. \"\"\" def __init__ ( self , location_type : str , location_name : str , location_coordinates : Point , location_amenity : str = None ): self . location_type = location_type self . location_name = location_name self . location_coordinates = location_coordinates self . location_amenity = location_amenity # Routes are stored on OD Matrix, therefore the following are not used self . route_car : Route = None self . route_walk : Route = None self . route_bike : Route = None def __repr__ ( self ): return f \" { self . location_type } ( { self . location_amenity } ) - { self . location_name } @ { self . location_coordinates } \" Route Represents a route between two locations, such as a home-to-work commute or a trip to a grocery store. Attributes: Name Type Description route_type str The type of route (e.g., car, walk, bike). route_path MultiLineString The path of the route as a MultiLineString. route_speed_kph int The speed of travel along the route in kilometers per hour. route_distance float The distance of the route in kilometers. route_travel_time_minutes int The travel time along the route in minutes. Source code in tripsender\\activity.py 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 class Route : \"\"\" Represents a route between two locations, such as a home-to-work commute or a trip to a grocery store. Attributes: route_type (str): The type of route (e.g., car, walk, bike). route_path (MultiLineString): The path of the route as a MultiLineString. route_speed_kph (int): The speed of travel along the route in kilometers per hour. route_distance (float): The distance of the route in kilometers. route_travel_time_minutes (int): The travel time along the route in minutes. \"\"\" def __init__ ( self , route_type : str , route_path : MultiLineString , route_speed_kph : int ): self . route_type = route_type self . route_path = route_path self . route_speed_kph = route_speed_kph self . route_distance = route_path . length self . route_travel_time_minutes = int ( self . route_distance / self . route_speed_kph * 60 ) def __repr__ ( self ): return f \" { self . route_type } - { self . route_distance } km @ { self . route_speed_kph } kph\" def plot ( self ): logger . info ( f \"Plotting not defined\" ) add_travel_home_activity ( df ) Add a travel activity to get home after the last activity of the day. Source code in tripsender\\activity.py 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 def add_travel_home_activity ( df ): \"\"\" Add a travel activity to get home after the last activity of the day. \"\"\" # Create a sampler object s = sampler . DurationSampler ( DURATION_DIST ) last_row = df . iloc [ - 1 ] last_purpose = last_row [ 'purpose' ] last_end_time = last_row [ 'end_time' ] last_mode = last_row [ 'mode' ] # Get the longest duration from all activities average_duration = df [ 'travel_duration_minutes' ] . mean () #logger.info(\"Last activity is not Home, adding a travel activity to get home...\") # Try to sample the duration of the last activity from the distribution # If the sampled duration is None then try again till a valid duration is sampled if last_purpose == \"Pickup/Dropoff child\" : duration_minutes_float = 0 else : duration_minutes_float = None while duration_minutes_float is None : duration_minutes_float = s . sample_duration ( last_purpose ) if duration_minutes_float is None : logger . error ( \"Sampled duration is None, trying again...\" ) # Convert duration to a timedelta object duration_minutes = pd . Timedelta ( minutes = duration_minutes_float ) # Calculate the start time of the return to home trip return_start_time = last_end_time + duration_minutes # Update activity_duration_minutes for the last row #df.loc[df.index[-1], 'activity_duration_minutes'] = duration_minutes df . at [ df . index [ - 1 ], 'activity_duration_minutes' ] = duration_minutes new_row = { 'start_time' : return_start_time , 'purpose' : 'Home' , 'mode' : last_mode , 'end_time' : return_start_time + average_duration , 'distance_km' : None , 'activity_sequence' : len ( df ) + 1 , 'travel_duration_minutes' : average_duration , 'activity_duration_minutes' : None , # Since it's the last activity 'next_travel_start_time' : None } df = df . append ( new_row , ignore_index = True ) # Reset the index df . reset_index ( drop = True , inplace = True ) return df calculate_duration ( start_time , end_time ) A helper function that calculates duration in minutes between two datetime objects. Source code in tripsender\\activity.py 725 726 727 728 729 def calculate_duration ( start_time , end_time ): \"\"\"A helper function that calculates duration in minutes between two datetime objects. \"\"\" duration = end_time - start_time return duration . total_seconds () / 60 create_color_palette ( cmap , activity_labels ) Generate a color palette dictionary based on a colormap and activity labels. Parameters: Name Type Description Default cmap str or Colormap The colormap to use. required activity_labels list List of activity labels. required Returns: Name Type Description dict Color palette dictionary mapping activity labels to colors. Source code in tripsender\\activity.py 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 def create_color_palette ( cmap , activity_labels ): \"\"\" Generate a color palette dictionary based on a colormap and activity labels. Args: cmap (str or matplotlib.colors.Colormap): The colormap to use. activity_labels (list): List of activity labels. Returns: dict: Color palette dictionary mapping activity labels to colors. \"\"\" # Create a colormap object if cmap is a string if isinstance ( cmap , str ): cmap = plt . get_cmap ( cmap ) # Generate equidistant color values from the colormap num_colors = len ( activity_labels ) color_values = [ cmap ( i / ( num_colors - 1 )) for i in range ( num_colors )] # Convert color values to hexadecimal strings color_palette = { label : rgb_to_hex ( color ) for label , color in zip ( activity_labels , color_values )} return color_palette get_bin_index ( time , bins ) Get the bin index for a given time. Source code in tripsender\\activity.py 805 806 807 def get_bin_index ( time , bins ): \"\"\"Get the bin index for a given time.\"\"\" return ( time . hour * bins ) // 24 rgb_to_hex ( rgb_color ) Convert an RGB color tuple to a hexadecimal color string. Parameters: Name Type Description Default rgb_color tuple RGB color tuple (e.g., (0.1, 0.2, 0.3)). required Returns: Name Type Description str Hexadecimal color string (e.g., '#1a3456'). Source code in tripsender\\activity.py 947 948 949 950 951 952 953 954 955 956 957 958 959 def rgb_to_hex ( rgb_color ): \"\"\" Convert an RGB color tuple to a hexadecimal color string. Args: rgb_color (tuple): RGB color tuple (e.g., (0.1, 0.2, 0.3)). Returns: str: Hexadecimal color string (e.g., '#1a3456'). \"\"\" r , g , b , _ = rgb_color hex_color = \"# {:02x}{:02x}{:02x} \" . format ( int ( r * 255 ), int ( g * 255 ), int ( b * 255 )) return hex_color","title":"activity"},{"location":"activity/#tripsender.activity.Activity","text":"Represents an activity performed by an individual, based on a sampled and matched activity sequence from the National Household Travel Survey (NHTS). An activity object consists of Activity purpose Start time Duration End time Mode of travel Attributes: Name Type Description start_time time The starting time of the activity. duration_minutes int The duration of the activity in minutes. duration_timedelta timedelta The duration of the activity as a timedelta object. end_time time The ending time of the activity. purpose str The purpose of the activity (e.g., work, school, shopping). mode str The mode of transportation used for the activity (e.g., walking, driving). destination str The destination of the activity. destination_coordinates tuple The coordinates of the destination. origin str The origin of the activity. origin_coordinates tuple The coordinates of the origin. calculated_duration timedelta The calculated duration of the trip if different from the provided duration. route list The route taken for the activity, if applicable. Source code in tripsender\\activity.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class Activity : \"\"\" Represents an activity performed by an individual, based on a sampled and matched activity sequence from the National Household Travel Survey (NHTS). An activity object consists of: - Activity purpose - Start time - Duration - End time - Mode of travel Attributes: start_time (datetime.time): The starting time of the activity. duration_minutes (int): The duration of the activity in minutes. duration_timedelta (timedelta): The duration of the activity as a timedelta object. end_time (datetime.time): The ending time of the activity. purpose (str): The purpose of the activity (e.g., work, school, shopping). mode (str, optional): The mode of transportation used for the activity (e.g., walking, driving). destination (str, optional): The destination of the activity. destination_coordinates (tuple, optional): The coordinates of the destination. origin (str, optional): The origin of the activity. origin_coordinates (tuple, optional): The coordinates of the origin. calculated_duration (timedelta, optional): The calculated duration of the trip if different from the provided duration. route (list, optional): The route taken for the activity, if applicable. \"\"\" def __init__ ( self , start_time , duration_minutes , purpose , mode = None ): \"\"\" Initializes an Activity object with the given parameters. Args: start_time (str or datetime): The start time of the activity. Can be a string or a datetime object. duration_minutes (int): The duration of the activity in minutes. purpose (str): The purpose of the activity. mode (str, optional): The mode of transportation. Defaults to None. \"\"\" # Use _parse_time_input for consistent time parsing parsed_datetime = self . _parse_time_input ( start_time ) self . start_time = parsed_datetime . time () if parsed_datetime else None self . duration_minutes = duration_minutes self . duration_timedelta = self . duration () self . end_time = ( datetime . combine ( datetime . today (), self . start_time ) + timedelta ( minutes = duration_minutes )) . time () self . purpose = purpose self . mode = mode self . destination = None self . destination_coordinates = None self . origin = None self . origin_coordinates = None self . calculated_duration = None self . route = None def __repr__ ( self ): return f \" { self . start_time . strftime ( '%H:%M' ) } - { self . purpose } ( { self . duration_minutes } mins)\" def _parse_time_input ( self , time_input ): \"\"\" Parses time input into a datetime object. Args: time_input (str or datetime.time): The time input to be parsed. Returns: datetime.datetime: The parsed datetime object. example: _parse_time_input(\"1200\") -> datetime.datetime(1900, 1, 1, 12, 0) _parse_time_input(\"12:00\") -> datetime.datetime(1900, 1, 1, 12, 0) _parse_time_input(datetime.time(12, 0)) -> datetime.datetime(1900, 1, 1, 12, 0) \"\"\" if isinstance ( time_input , str ): if ':' in time_input : return datetime . strptime ( time_input , '%H:%M' ) else : return datetime . strptime ( time_input , '%H%M' ) elif isinstance ( time_input , time ): return datetime . combine ( datetime . today (), time_input ) elif isinstance ( time_input , datetime ): return time_input else : logger . error ( \"Time input must be in the format HH:MM or HHMM or datetime.time or datetime.datetime\" ) return None def __str__ ( self ): return f \"Start Time: { self . start_time } , End Time: { self . end_time } , Purpose: { self . purpose } , Mode: { self . mode } \" def duration ( self ): return timedelta ( minutes = self . duration_minutes )","title":"Activity"},{"location":"activity/#tripsender.activity.Activity.__init__","text":"Initializes an Activity object with the given parameters. Parameters: Name Type Description Default start_time str or datetime The start time of the activity. Can be a string or a datetime object. required duration_minutes int The duration of the activity in minutes. required purpose str The purpose of the activity. required mode str The mode of transportation. Defaults to None. None Source code in tripsender\\activity.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def __init__ ( self , start_time , duration_minutes , purpose , mode = None ): \"\"\" Initializes an Activity object with the given parameters. Args: start_time (str or datetime): The start time of the activity. Can be a string or a datetime object. duration_minutes (int): The duration of the activity in minutes. purpose (str): The purpose of the activity. mode (str, optional): The mode of transportation. Defaults to None. \"\"\" # Use _parse_time_input for consistent time parsing parsed_datetime = self . _parse_time_input ( start_time ) self . start_time = parsed_datetime . time () if parsed_datetime else None self . duration_minutes = duration_minutes self . duration_timedelta = self . duration () self . end_time = ( datetime . combine ( datetime . today (), self . start_time ) + timedelta ( minutes = duration_minutes )) . time () self . purpose = purpose self . mode = mode self . destination = None self . destination_coordinates = None self . origin = None self . origin_coordinates = None self . calculated_duration = None self . route = None","title":"__init__"},{"location":"activity/#tripsender.activity.ActivitySequence","text":"Source code in tripsender\\activity.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 class ActivitySequence : instances : List [ 'ActivitySequence' ] = [] samples : List [ 'ActivitySequence' ] = [] def __init__ ( self ): self . person = None self . activities = [] self . disruptions = 0 # Number of disruptions in the sequence @classmethod def return_person_df ( cls ): list_of_person_dicts = [] for activity_sequence in cls . samples : list_of_person_dicts . append ( activity_sequence . sampled_person ) df = pd . DataFrame ( list_of_person_dicts ) # Create a column called ActivitySequence that contains the ActivitySequence instance df [ 'ActivitySequence' ] = cls . samples return df @classmethod def clear_instances ( cls ): cls . instances = [] @classmethod def clear_samples ( cls ): cls . samples = [] def __repr__ ( self ): return \" \\n \" . join ( repr ( activity ) for activity in self . activities ) def total_duration ( self ): return sum ([ activity . duration () for activity in self . activities ], datetime . timedelta ()) def __str__ ( self ): return ' \\n ' . join ( str ( activity ) for activity in self . activities ) def return_gdf ( self ): gdf_data = [] activity_sequence = self for activity in activity_sequence . activities : if activity . purpose == \"Transit\" : next_activity = activity_sequence . activities [ activity_sequence . activities . index ( activity ) + 1 ] # The below check seems deprecated # if isinstance(activity.destination, Point): if activity . destination != \"Travel\" : gdf_dict = { 'geometry' : activity . route , 'mode' : activity . mode , 'origin' : activity . origin_coordinates , 'destination' : activity . destination_coordinates , 'sampled_duration' : activity . duration_minutes , 'calculated_duration' : activity . calculated_duration , 'start_time' : activity . start_time , 'purpose' : next_activity . purpose } # Append dictionary to list gdf_data . append ( gdf_dict ) elif activity . destination == \"Travel\" : # If the destination says \"Travel\", then it's a travel activity and we don't have a destination # So we just plot a point at the origin of the travel activity gdf_dict = { 'geometry' : activity . origin_coordinates , 'mode' : activity . mode , 'origin' : activity . origin_coordinates , 'destination' : activity . destination_coordinates , 'sampled_duration' : activity . duration_minutes , 'calculated_duration' : activity . calculated_duration , 'start_time' : activity . start_time , 'purpose' : activity . purpose } # Append dictionary to list gdf_data . append ( gdf_dict ) else : logger . error ( \"Destination is not a Point or 'Travel'\" ) # Create GeoDataFrame from collected data gdf = gpd . GeoDataFrame ( gdf_data ) return gdf def plot ( self , plot_type = '2d' ): gdf = self . return_gdf () home = gdf . iloc [ 0 ][ 'origin' ] # Identify unique modes of transport unique_modes = set ( row [ 'mode' ] for index , row in gdf . iterrows ()) # Create a color map for the modes colors = plt . cm . get_cmap ( 'viridis' , len ( unique_modes )) mode_colors = { mode : colors ( i ) for i , mode in enumerate ( unique_modes )} # Check if gdf is not empty before proceeding if not gdf . empty : # Set geometry column explicitly in case it's not automatically recognized gdf = gdf . set_geometry ( 'geometry' ) # Set CRS to EPSG:3006 gdf . crs = \"epsg:3006\" if plot_type == '2d' : # 2D Plot ax = gdf . plot ( column = 'mode' , legend = True , figsize = ( 10 , 10 )) ax . set_title ( \"Activity Routes by Mode\" ) ax . set_xlabel ( \"Longitude\" ) ax . set_ylabel ( \"Latitude\" ) # Add home location ax . scatter ( home . x , home . y , color = 'red' , marker = '*' , s = 100 , label = 'Home' ) elif plot_type == 'spacetimecube_static' : # Static Space-Time Cube fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( 111 , projection = '3d' ) # Convert start_time to total seconds from the start of the day and then to hours gdf [ 'time_hours' ] = gdf [ 'start_time' ] . apply ( lambda x : pd . Timedelta ( str ( x )) . total_seconds () / 3600 ) for index , row in gdf . iterrows (): x , y = zip ( * [( point [ 0 ], point [ 1 ]) for point in list ( row [ 'geometry' ] . coords )]) z = [ row [ 'time_hours' ]] * len ( x ) mode_color = mode_colors [ row [ 'mode' ]] ax . plot ( x , y , z , linestyle = '-' , marker = '' , color = mode_color ) # Use color mapped to mode # Place a text label near the start of the activity label_pos = 0 ax . text ( x [ label_pos ], y [ label_pos ], z [ label_pos ], f \" { row [ 'purpose' ] } \" , color = 'black' , fontsize = 8 , ha = 'right' ) if index < len ( gdf ) - 1 : next_row = gdf . iloc [ index + 1 ] ax . plot ([ x [ - 1 ], x [ - 1 ]], [ y [ - 1 ], y [ - 1 ]], [ row [ 'time_hours' ], next_row [ 'time_hours' ]], 'k:' , linewidth = 1 ) # After iterating through all rows, get the last activity's coordinates and time last_activity = gdf . iloc [ - 1 ] last_coords = list ( last_activity [ 'geometry' ] . coords ) # Convert coordinates to a list last_x , last_y = last_coords [ - 1 ] # Take the last point of the last activity last_z = last_activity [ 'time_hours' ] # Connect the last activity to home with a vertical dotted line back to the start of the day ax . plot ([ last_x , home . x ], [ last_y , home . y ], [ last_z , 0 ], 'k:' , linewidth = 1 , ) ax . set_xlabel ( '' ) ax . set_ylabel ( '' ) ax . set_zlabel ( 'Time (Hours from start of day)' ) ax . set_zticks ( range ( 0 , 24 , 3 )) # Set z-axis to display each hour ax . set_zticklabels ([ f \" { i } h\" for i in range ( 0 , 24 , 3 )]) # Label each tick with the hour # Get the current xlim and ylim xmin , xmax = ax . get_xlim () ymin , ymax = ax . get_ylim () # Calculate the range of the x and y axis xrange = xmax - xmin yrange = ymax - ymin # Set the x and y ticks to display relative distances # Define the number of ticks you want num_ticks = 5 # Example: 5 ticks # Set x and y ticks ax . set_xticks ([ xmin + i * ( xrange / ( num_ticks - 1 )) for i in range ( num_ticks )]) ax . set_yticks ([ ymin + i * ( yrange / ( num_ticks - 1 )) for i in range ( num_ticks )]) # Set x and y tick labels ax . set_xticklabels ([ f \" { int ( i * ( xrange / ( num_ticks - 1 ))) } m\" for i in range ( num_ticks )]) ax . set_yticklabels ([ f \" { int ( i * ( yrange / ( num_ticks - 1 ))) } m\" for i in range ( num_ticks )]) # Reduce the grid lineweight ax . xaxis . _axinfo [ 'grid' ] . update ( linewidth = 0.1 ) ax . yaxis . _axinfo [ 'grid' ] . update ( linewidth = 0.1 ) ax . zaxis . _axinfo [ 'grid' ] . update ( linewidth = 0.1 ) # Add home location at the start of the day with a green marker ax . scatter ( home . x , home . y , 0 , color = 'green' , marker = \"v\" , s = 100 , label = 'Start Home' ) # Add home location at the end of the day with a red marker ax . scatter ( home . x , home . y , last_z , color = 'red' , marker = \"v\" , s = 100 , label = 'End Home' ) # Reduce the thickness of the text ax . xaxis . label . set_size ( 8 ) ax . yaxis . label . set_size ( 8 ) ax . zaxis . label . set_size ( 8 ) # Ticks ax . xaxis . set_tick_params ( labelsize = 8 ) ax . yaxis . set_tick_params ( labelsize = 8 ) ax . zaxis . set_tick_params ( labelsize = 8 ) # Prepare legend entries for modes of transport legend_entries = [ Line2D ([ 0 ], [ 0 ], color = mode_colors [ mode ], lw = 4 , label = mode ) for mode in unique_modes ] # Add home markers to the legend legend_entries . append ( Line2D ([ 0 ], [ 0 ], marker = 'v' , color = 'green' , label = 'Start Home' , markersize = 10 , linestyle = 'None' )) legend_entries . append ( Line2D ([ 0 ], [ 0 ], marker = 'v' , color = 'red' , label = 'End Home' , markersize = 10 , linestyle = 'None' )) # Set the legend with the mode entries ax . legend ( handles = legend_entries ) plt . show () elif plot_type == 'spacetimecube_interactive' : # Interactive Space-Time Cube traces = [] legend_added = {} # To track which modes have been added to the legend # Color map for modes of transport unique_modes = list ( set ( row [ 'mode' ] for index , row in gdf . iterrows ())) colors = plt . cm . get_cmap ( 'viridis' , len ( unique_modes )) mode_colors = { mode : f 'rgb { colors ( i )[: 3 ] } ' for i , mode in enumerate ( unique_modes )} # Determine the range for x and y axis based on the geometry all_coords = [ coord for row in gdf [ 'geometry' ] for coord in list ( row . coords )] all_x , all_y = zip ( * all_coords ) xmin , xmax = min ( all_x ), max ( all_x ) ymin , ymax = min ( all_y ), max ( all_y ) # Adjust the range if you want to start from 0 xrange = xmax - xmin yrange = ymax - ymin # Plot each activity segment with transitions for index , row in gdf . iterrows (): x , y = zip ( * [( coord [ 0 ] - xmin , coord [ 1 ] - ymin ) for coord in list ( row [ 'geometry' ] . coords )]) # Adjusted coordinates z = [ pd . Timedelta ( str ( row [ 'start_time' ])) . total_seconds () / 3600 ] * len ( x ) # Time in hours mode_color = mode_colors [ row [ 'mode' ]] # Check if the mode is already added to legend show_legend = row [ 'mode' ] not in legend_added legend_added [ row [ 'mode' ]] = True # Activity trace trace = go . Scatter3d ( x = x , y = y , z = z , mode = 'lines' , name = row [ 'mode' ], line = dict ( color = mode_color , width = 4 ), hoverinfo = 'text' , text = f \"Mode: { row [ 'mode' ] } , Duration: { row [ 'sampled_duration' ] } mins, Purpose: { row [ 'purpose' ] } \" , showlegend = show_legend ) traces . append ( trace ) # Transition to next activity or home with a dotted line if index < len ( gdf ) - 1 : next_row = gdf . iloc [ index + 1 ] next_x , next_y = next_row [ 'origin' ] . x - xmin , next_row [ 'origin' ] . y - ymin # Adjusted coordinates next_z = pd . Timedelta ( str ( next_row [ 'start_time' ])) . total_seconds () / 3600 traces . append ( go . Scatter3d ( x = [ x [ - 1 ], next_x ], y = [ y [ - 1 ], next_y ], z = [ z [ - 1 ], next_z ], mode = 'lines' , line = dict ( color = 'black' , width = 2 , dash = 'dot' ), showlegend = False # Hide these transitions from legend )) # Calculate home coordinates adjusted for the plot home_x , home_y = home . x - xmin , home . y - ymin # Adjusted coordinates home_start_z = 0 # Start of the day in hours home_end_z = pd . Timedelta ( str ( gdf . iloc [ - 1 ][ 'start_time' ])) . total_seconds () / 3600 # End of the last activity in hours # Home location at the start of the day (green marker) traces . append ( go . Scatter3d ( x = [ home_x ], y = [ home_y ], z = [ home_start_z ], mode = 'markers' , marker = dict ( size = 10 , color = 'green' ), name = 'Start Home' , hoverinfo = 'text' , text = 'Start Home' )) # Transition from home to the first activity (dotted line) if len ( gdf ) > 0 : first_activity = gdf . iloc [ 0 ] first_coords = list ( first_activity [ 'geometry' ] . coords ) first_x , first_y = first_coords [ 0 ][ 0 ] - xmin , first_coords [ 0 ][ 1 ] - ymin # Adjusted coordinates of the first point of the first activity first_z = pd . Timedelta ( str ( first_activity [ 'start_time' ])) . total_seconds () / 3600 # Start time of the first activity in hours # Transition from home to the first activity (dotted line) traces . append ( go . Scatter3d ( x = [ home_x , first_x ], y = [ home_y , first_y ], z = [ home_start_z , first_z ], mode = 'lines' , line = dict ( color = 'black' , width = 2 , dash = 'dot' ), showlegend = False # This transition should not appear in the legend )) # Transition from the last activity back to home (dotted line) if len ( gdf ) > 0 : last_activity = gdf . iloc [ - 1 ] last_coords = list ( last_activity [ 'geometry' ] . coords ) last_x , last_y = last_coords [ - 1 ][ 0 ] - xmin , last_coords [ - 1 ][ 1 ] - ymin # Adjusted coordinates traces . append ( go . Scatter3d ( x = [ last_x , home_x ], y = [ last_y , home_y ], z = [ home_end_z , home_end_z ], mode = 'lines' , line = dict ( color = 'black' , width = 2 , dash = 'dot' ), showlegend = False )) # Home location at the end of the day (red marker) traces . append ( go . Scatter3d ( x = [ home_x ], y = [ home_y ], z = [ home_end_z ], mode = 'markers' , marker = dict ( size = 10 , color = 'red' ), name = 'End Home' , hoverinfo = 'text' , text = 'End Home' )) # Layout configuration, including x and y axis ticks and labels layout = go . Layout ( title = \"Space-Time Cube Visualization\" , scene = dict ( # Axis configurations (as in the previous code) ), margin = dict ( r = 0 , l = 0 , b = 0 , t = 50 ) ) # Create figure with traces and layout fig = go . Figure ( data = traces , layout = layout ) # Display the interactive plot fig . show () else : print ( \"No routes available for plotting.\" ) return gdf def from_nhts ( self , df ): \"\"\" Create an ActivitySequence object from a sampled and matched activity sequence from the National Household Travel Survey (NHTS). Attributes: df (pandas.DataFrame): A DataFrame containing the sampled and matched activity sequence from the NHTS. Returns: ActivitySequence: An ActivitySequence object representing the activity sequence. \"\"\" current_date = datetime . now () . date () start_of_day = datetime . combine ( current_date , time ( 3 , 0 )) end_of_day = start_of_day + timedelta ( days = 1 ) # Some df checks to make sure that df makes sense # If activity duration is 0 days 00:00:00 remove the row #df = df[df['activity_duration_minutes'] != pd.Timedelta(seconds=0)] # Reset index, drop means that the old index is not added as a column # If the last trip of the day is not Home, then get the duration of the last activity based on sampled activity duration # And add a travel activity to get home that starts after the sampled duration of the last activity last_row = df . iloc [ - 1 ] if last_row [ 'purpose' ] != 'Home' : df = add_travel_home_activity ( df ) #df = df.reset_index(drop=False) #logger.info('Number of activities in df: {}'.format(len(df))) #logger.info(\" Starting day from Home...\") # Add a column called is_worker to the dataframe #df['is_worker'] = False #.loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = False is_worker = False for index , row in df . iterrows (): #logger.info(\" Traveling to activity {}\".format(row['purpose'])) # Travel to activity travel_duration = calculate_duration ( row [ 'start_time' ] - row [ 'travel_duration_minutes' ], row [ 'start_time' ]) t_time = row [ 'start_time' ] t_duration = travel_duration # What if we call this \"Transit\" instead of \"Travel\"? t_purpose = 'Transit' t_mode = row [ 'mode' ] transit_activity = Activity ( t_time , t_duration , t_purpose , t_mode ) transit_activity . destination = row [ 'purpose' ] self . activities . append ( transit_activity ) # Activity itself #logger.info(\" Current activity {}\".format(row['purpose'])) #logger.info(\" Duration of activity {}: {}\".format(row['purpose'], row['activity_duration_minutes'])) if pd . isna ( row [ 'activity_duration_minutes' ]): # If there is no next activity, then the activity duration is the time until the end of the day a_duration = 0 else : a_duration = calculate_duration ( row [ 'end_time' ] - row [ 'activity_duration_minutes' ], row [ 'end_time' ]) # Only add activity if it has a duration greater than 0 or if it is the last activity of the day if a_duration > 0 or index < len ( df ) - 1 or row [ \"purpose\" ] == \"Pickup/Dropoff child\" : a_time = row [ 'end_time' ] a_purpose = row [ 'purpose' ] if a_purpose == 'Work' : is_worker = True if a_purpose != 'Travel' : # Sometimes the activity itself is a travel activity a_mode = None else : a_mode = row [ 'mode' ] self . activities . append ( Activity ( a_time , a_duration , a_purpose , a_mode )) # Handle initial home activity # If the first activity of the day is not at 3:00, then there must be an initial home activity if df . iloc [ 0 ][ 'start_time' ] > start_of_day : # Calculate duration of initial home activity - from 3:00 to start of first activity h_time = start_of_day h_duration = calculate_duration ( start_of_day , df . iloc [ 0 ][ 'start_time' ]) h_purpose = 'Home' h_mode = None self . activities . insert ( 0 , Activity ( h_time , h_duration , h_purpose , h_mode )) # Handle final home activity # If the last activity of the day is not at 3:00, then there must be a final home activity last_activity = self . activities [ - 1 ] last_activity_end_time = datetime . combine ( current_date , last_activity . start_time ) # Extract minutes from the timedelta object last_activity_duration_minutes = last_activity . duration () . total_seconds () / 60 last_activity_end_time += timedelta ( minutes = last_activity_duration_minutes ) if last_activity_end_time < end_of_day : fh_time = last_activity_end_time fh_duration = calculate_duration ( last_activity_end_time , end_of_day ) fh_purpose = 'Home' fh_mode = None self . activities . append ( Activity ( fh_time , fh_duration , fh_purpose , fh_mode )) #logger.info(\" Heading home...\") # Update the is_worker column #df['is_worker'] = is_worker # .loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = is_worker # Extract person attributes self . sampled_person = df . iloc [ 0 ][[ 'id' , 'sex' , 'age_group' , 'house_type' , 'child_count' , 'adult_count' , 'household_type' , 'car_count' , 'is_worker' ]] . to_dict () # Validate ActivitySequence object and add it to the list of instances if valid if not self . is_valid (): #logger.error(\"ActivitySequence is not valid\") return False # Add ActivitySequence object to the list of instances self . samples . append ( self ) return self def is_valid ( self ): \"\"\" Validates the ActivitySequence object. Specifically, it checks the following: - Start time is before end time for each activity - Duration of each activity is positive - Activities are in increasing order of start time - Activities do not overlap - Sum of activity durations is 24 hours - There is a \"Transit\" activity - Mode and purpose are provided for each activity Returns: bool: True if the ActivitySequence is valid, False otherwise. \"\"\" # Check if there are any activities to validate if not self . activities : return False # Check if start time of an activity is before its end time for activity in self . activities : if activity . start_time >= activity . end_time : # Check for the HOME exception if activity . purpose == 'Home' and activity . end_time <= time ( 12 , 0 ): # Assuming HOME can only go till noon of the next day continue elif activity . purpose == \"Pickup/Dropoff child\" : continue else : #logger.error(f\"Start time is not before end time for activity: {activity}\") return False # Check if any activity has a negative duration for activity in self . activities : if activity . duration_minutes <= 0 and activity . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Negative or zero duration for activity: {activity}\") return False # Check if activities are in increasing order of start time for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . start_time >= self . activities [ i + 1 ] . start_time and self . activities [ i ] . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Activities are not in increasing order of start time: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't overlap for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . end_time > self . activities [ i + 1 ] . start_time : #logger.error(f\"Activities overlap: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't exceed 24 hours, except for HOME if self . activities [ - 1 ] . purpose != 'Home' and self . activities [ - 1 ] . end_time > time ( 23 , 59 ): #logger.error(f\"Activity sequence exceeds 24 hours: {self.activities[-1]}\") return False # Check the mode and purpose for each activity for activity in self . activities : if activity . purpose in [ \"Travel\" ]: if not activity . mode or not activity . purpose : #logger.error(f\"Missing mode or purpose for activity: {activity}\") return False # Check if sum of activity durations is 24 hours if sum ([ activity . duration_minutes for activity in self . activities ]) != 1440 : #logger.error(\"Sum of activity durations is not 24 hours\") return False # Check if there is a \"Transit\" activity before every non-\"Transit\" activity (except for the first activity) for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose != 'Transit' and self . activities [ i - 1 ] . purpose != 'Transit' : #logger.error(f\"No transit activity before non-transit activity: {self.activities[i]}\") return False # Make sure that there are no two consecutive \"Transit\" activities for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose == 'Transit' and self . activities [ i - 1 ] . purpose == 'Transit' : #logger.error(f\"Two consecutive transit activities: {self.activities[i]}\") return False return True","title":"ActivitySequence"},{"location":"activity/#tripsender.activity.ActivitySequence.from_nhts","text":"Create an ActivitySequence object from a sampled and matched activity sequence from the National Household Travel Survey (NHTS). Attributes: Name Type Description df DataFrame A DataFrame containing the sampled and matched activity sequence from the NHTS. Returns: Name Type Description ActivitySequence An ActivitySequence object representing the activity sequence. Source code in tripsender\\activity.py 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 def from_nhts ( self , df ): \"\"\" Create an ActivitySequence object from a sampled and matched activity sequence from the National Household Travel Survey (NHTS). Attributes: df (pandas.DataFrame): A DataFrame containing the sampled and matched activity sequence from the NHTS. Returns: ActivitySequence: An ActivitySequence object representing the activity sequence. \"\"\" current_date = datetime . now () . date () start_of_day = datetime . combine ( current_date , time ( 3 , 0 )) end_of_day = start_of_day + timedelta ( days = 1 ) # Some df checks to make sure that df makes sense # If activity duration is 0 days 00:00:00 remove the row #df = df[df['activity_duration_minutes'] != pd.Timedelta(seconds=0)] # Reset index, drop means that the old index is not added as a column # If the last trip of the day is not Home, then get the duration of the last activity based on sampled activity duration # And add a travel activity to get home that starts after the sampled duration of the last activity last_row = df . iloc [ - 1 ] if last_row [ 'purpose' ] != 'Home' : df = add_travel_home_activity ( df ) #df = df.reset_index(drop=False) #logger.info('Number of activities in df: {}'.format(len(df))) #logger.info(\" Starting day from Home...\") # Add a column called is_worker to the dataframe #df['is_worker'] = False #.loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = False is_worker = False for index , row in df . iterrows (): #logger.info(\" Traveling to activity {}\".format(row['purpose'])) # Travel to activity travel_duration = calculate_duration ( row [ 'start_time' ] - row [ 'travel_duration_minutes' ], row [ 'start_time' ]) t_time = row [ 'start_time' ] t_duration = travel_duration # What if we call this \"Transit\" instead of \"Travel\"? t_purpose = 'Transit' t_mode = row [ 'mode' ] transit_activity = Activity ( t_time , t_duration , t_purpose , t_mode ) transit_activity . destination = row [ 'purpose' ] self . activities . append ( transit_activity ) # Activity itself #logger.info(\" Current activity {}\".format(row['purpose'])) #logger.info(\" Duration of activity {}: {}\".format(row['purpose'], row['activity_duration_minutes'])) if pd . isna ( row [ 'activity_duration_minutes' ]): # If there is no next activity, then the activity duration is the time until the end of the day a_duration = 0 else : a_duration = calculate_duration ( row [ 'end_time' ] - row [ 'activity_duration_minutes' ], row [ 'end_time' ]) # Only add activity if it has a duration greater than 0 or if it is the last activity of the day if a_duration > 0 or index < len ( df ) - 1 or row [ \"purpose\" ] == \"Pickup/Dropoff child\" : a_time = row [ 'end_time' ] a_purpose = row [ 'purpose' ] if a_purpose == 'Work' : is_worker = True if a_purpose != 'Travel' : # Sometimes the activity itself is a travel activity a_mode = None else : a_mode = row [ 'mode' ] self . activities . append ( Activity ( a_time , a_duration , a_purpose , a_mode )) # Handle initial home activity # If the first activity of the day is not at 3:00, then there must be an initial home activity if df . iloc [ 0 ][ 'start_time' ] > start_of_day : # Calculate duration of initial home activity - from 3:00 to start of first activity h_time = start_of_day h_duration = calculate_duration ( start_of_day , df . iloc [ 0 ][ 'start_time' ]) h_purpose = 'Home' h_mode = None self . activities . insert ( 0 , Activity ( h_time , h_duration , h_purpose , h_mode )) # Handle final home activity # If the last activity of the day is not at 3:00, then there must be a final home activity last_activity = self . activities [ - 1 ] last_activity_end_time = datetime . combine ( current_date , last_activity . start_time ) # Extract minutes from the timedelta object last_activity_duration_minutes = last_activity . duration () . total_seconds () / 60 last_activity_end_time += timedelta ( minutes = last_activity_duration_minutes ) if last_activity_end_time < end_of_day : fh_time = last_activity_end_time fh_duration = calculate_duration ( last_activity_end_time , end_of_day ) fh_purpose = 'Home' fh_mode = None self . activities . append ( Activity ( fh_time , fh_duration , fh_purpose , fh_mode )) #logger.info(\" Heading home...\") # Update the is_worker column #df['is_worker'] = is_worker # .loc[row_indexer,col_indexer] = value instead df . loc [ df . index , 'is_worker' ] = is_worker # Extract person attributes self . sampled_person = df . iloc [ 0 ][[ 'id' , 'sex' , 'age_group' , 'house_type' , 'child_count' , 'adult_count' , 'household_type' , 'car_count' , 'is_worker' ]] . to_dict () # Validate ActivitySequence object and add it to the list of instances if valid if not self . is_valid (): #logger.error(\"ActivitySequence is not valid\") return False # Add ActivitySequence object to the list of instances self . samples . append ( self ) return self","title":"from_nhts"},{"location":"activity/#tripsender.activity.ActivitySequence.is_valid","text":"Validates the ActivitySequence object. Specifically, it checks the following: - Start time is before end time for each activity - Duration of each activity is positive - Activities are in increasing order of start time - Activities do not overlap - Sum of activity durations is 24 hours - There is a \"Transit\" activity - Mode and purpose are provided for each activity Returns: bool: True if the ActivitySequence is valid, False otherwise. Source code in tripsender\\activity.py 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 def is_valid ( self ): \"\"\" Validates the ActivitySequence object. Specifically, it checks the following: - Start time is before end time for each activity - Duration of each activity is positive - Activities are in increasing order of start time - Activities do not overlap - Sum of activity durations is 24 hours - There is a \"Transit\" activity - Mode and purpose are provided for each activity Returns: bool: True if the ActivitySequence is valid, False otherwise. \"\"\" # Check if there are any activities to validate if not self . activities : return False # Check if start time of an activity is before its end time for activity in self . activities : if activity . start_time >= activity . end_time : # Check for the HOME exception if activity . purpose == 'Home' and activity . end_time <= time ( 12 , 0 ): # Assuming HOME can only go till noon of the next day continue elif activity . purpose == \"Pickup/Dropoff child\" : continue else : #logger.error(f\"Start time is not before end time for activity: {activity}\") return False # Check if any activity has a negative duration for activity in self . activities : if activity . duration_minutes <= 0 and activity . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Negative or zero duration for activity: {activity}\") return False # Check if activities are in increasing order of start time for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . start_time >= self . activities [ i + 1 ] . start_time and self . activities [ i ] . purpose != \"Pickup/Dropoff child\" : #logger.error(f\"Activities are not in increasing order of start time: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't overlap for i in range ( len ( self . activities ) - 1 ): if self . activities [ i ] . end_time > self . activities [ i + 1 ] . start_time : #logger.error(f\"Activities overlap: {self.activities[i]} and {self.activities[i+1]}\") return False # Ensure activities don't exceed 24 hours, except for HOME if self . activities [ - 1 ] . purpose != 'Home' and self . activities [ - 1 ] . end_time > time ( 23 , 59 ): #logger.error(f\"Activity sequence exceeds 24 hours: {self.activities[-1]}\") return False # Check the mode and purpose for each activity for activity in self . activities : if activity . purpose in [ \"Travel\" ]: if not activity . mode or not activity . purpose : #logger.error(f\"Missing mode or purpose for activity: {activity}\") return False # Check if sum of activity durations is 24 hours if sum ([ activity . duration_minutes for activity in self . activities ]) != 1440 : #logger.error(\"Sum of activity durations is not 24 hours\") return False # Check if there is a \"Transit\" activity before every non-\"Transit\" activity (except for the first activity) for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose != 'Transit' and self . activities [ i - 1 ] . purpose != 'Transit' : #logger.error(f\"No transit activity before non-transit activity: {self.activities[i]}\") return False # Make sure that there are no two consecutive \"Transit\" activities for i in range ( 1 , len ( self . activities )): if self . activities [ i ] . purpose == 'Transit' and self . activities [ i - 1 ] . purpose == 'Transit' : #logger.error(f\"Two consecutive transit activities: {self.activities[i]}\") return False return True","title":"is_valid"},{"location":"activity/#tripsender.activity.Location","text":"Represents a location in the simulation, such as a home, work, school, or other destination. Attributes: Name Type Description location_type str The type of location (e.g., home, work, school). location_name str The name of the location. location_coordinates Point The coordinates of the location. location_amenity str The amenity of the location (e.g., hospital, park). route_car Route The route to the location by car. route_walk Route The route to the location by walking. route_bike Route The route to the location by biking. Source code in tripsender\\activity.py 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 class Location : \"\"\" Represents a location in the simulation, such as a home, work, school, or other destination. Attributes: location_type (str): The type of location (e.g., home, work, school). location_name (str): The name of the location. location_coordinates (Point): The coordinates of the location. location_amenity (str, optional): The amenity of the location (e.g., hospital, park). route_car (Route, optional): The route to the location by car. route_walk (Route, optional): The route to the location by walking. route_bike (Route, optional): The route to the location by biking. \"\"\" def __init__ ( self , location_type : str , location_name : str , location_coordinates : Point , location_amenity : str = None ): self . location_type = location_type self . location_name = location_name self . location_coordinates = location_coordinates self . location_amenity = location_amenity # Routes are stored on OD Matrix, therefore the following are not used self . route_car : Route = None self . route_walk : Route = None self . route_bike : Route = None def __repr__ ( self ): return f \" { self . location_type } ( { self . location_amenity } ) - { self . location_name } @ { self . location_coordinates } \"","title":"Location"},{"location":"activity/#tripsender.activity.Route","text":"Represents a route between two locations, such as a home-to-work commute or a trip to a grocery store. Attributes: Name Type Description route_type str The type of route (e.g., car, walk, bike). route_path MultiLineString The path of the route as a MultiLineString. route_speed_kph int The speed of travel along the route in kilometers per hour. route_distance float The distance of the route in kilometers. route_travel_time_minutes int The travel time along the route in minutes. Source code in tripsender\\activity.py 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 class Route : \"\"\" Represents a route between two locations, such as a home-to-work commute or a trip to a grocery store. Attributes: route_type (str): The type of route (e.g., car, walk, bike). route_path (MultiLineString): The path of the route as a MultiLineString. route_speed_kph (int): The speed of travel along the route in kilometers per hour. route_distance (float): The distance of the route in kilometers. route_travel_time_minutes (int): The travel time along the route in minutes. \"\"\" def __init__ ( self , route_type : str , route_path : MultiLineString , route_speed_kph : int ): self . route_type = route_type self . route_path = route_path self . route_speed_kph = route_speed_kph self . route_distance = route_path . length self . route_travel_time_minutes = int ( self . route_distance / self . route_speed_kph * 60 ) def __repr__ ( self ): return f \" { self . route_type } - { self . route_distance } km @ { self . route_speed_kph } kph\" def plot ( self ): logger . info ( f \"Plotting not defined\" )","title":"Route"},{"location":"activity/#tripsender.activity.add_travel_home_activity","text":"Add a travel activity to get home after the last activity of the day. Source code in tripsender\\activity.py 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 def add_travel_home_activity ( df ): \"\"\" Add a travel activity to get home after the last activity of the day. \"\"\" # Create a sampler object s = sampler . DurationSampler ( DURATION_DIST ) last_row = df . iloc [ - 1 ] last_purpose = last_row [ 'purpose' ] last_end_time = last_row [ 'end_time' ] last_mode = last_row [ 'mode' ] # Get the longest duration from all activities average_duration = df [ 'travel_duration_minutes' ] . mean () #logger.info(\"Last activity is not Home, adding a travel activity to get home...\") # Try to sample the duration of the last activity from the distribution # If the sampled duration is None then try again till a valid duration is sampled if last_purpose == \"Pickup/Dropoff child\" : duration_minutes_float = 0 else : duration_minutes_float = None while duration_minutes_float is None : duration_minutes_float = s . sample_duration ( last_purpose ) if duration_minutes_float is None : logger . error ( \"Sampled duration is None, trying again...\" ) # Convert duration to a timedelta object duration_minutes = pd . Timedelta ( minutes = duration_minutes_float ) # Calculate the start time of the return to home trip return_start_time = last_end_time + duration_minutes # Update activity_duration_minutes for the last row #df.loc[df.index[-1], 'activity_duration_minutes'] = duration_minutes df . at [ df . index [ - 1 ], 'activity_duration_minutes' ] = duration_minutes new_row = { 'start_time' : return_start_time , 'purpose' : 'Home' , 'mode' : last_mode , 'end_time' : return_start_time + average_duration , 'distance_km' : None , 'activity_sequence' : len ( df ) + 1 , 'travel_duration_minutes' : average_duration , 'activity_duration_minutes' : None , # Since it's the last activity 'next_travel_start_time' : None } df = df . append ( new_row , ignore_index = True ) # Reset the index df . reset_index ( drop = True , inplace = True ) return df","title":"add_travel_home_activity"},{"location":"activity/#tripsender.activity.calculate_duration","text":"A helper function that calculates duration in minutes between two datetime objects. Source code in tripsender\\activity.py 725 726 727 728 729 def calculate_duration ( start_time , end_time ): \"\"\"A helper function that calculates duration in minutes between two datetime objects. \"\"\" duration = end_time - start_time return duration . total_seconds () / 60","title":"calculate_duration"},{"location":"activity/#tripsender.activity.create_color_palette","text":"Generate a color palette dictionary based on a colormap and activity labels. Parameters: Name Type Description Default cmap str or Colormap The colormap to use. required activity_labels list List of activity labels. required Returns: Name Type Description dict Color palette dictionary mapping activity labels to colors. Source code in tripsender\\activity.py 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 def create_color_palette ( cmap , activity_labels ): \"\"\" Generate a color palette dictionary based on a colormap and activity labels. Args: cmap (str or matplotlib.colors.Colormap): The colormap to use. activity_labels (list): List of activity labels. Returns: dict: Color palette dictionary mapping activity labels to colors. \"\"\" # Create a colormap object if cmap is a string if isinstance ( cmap , str ): cmap = plt . get_cmap ( cmap ) # Generate equidistant color values from the colormap num_colors = len ( activity_labels ) color_values = [ cmap ( i / ( num_colors - 1 )) for i in range ( num_colors )] # Convert color values to hexadecimal strings color_palette = { label : rgb_to_hex ( color ) for label , color in zip ( activity_labels , color_values )} return color_palette","title":"create_color_palette"},{"location":"activity/#tripsender.activity.get_bin_index","text":"Get the bin index for a given time. Source code in tripsender\\activity.py 805 806 807 def get_bin_index ( time , bins ): \"\"\"Get the bin index for a given time.\"\"\" return ( time . hour * bins ) // 24","title":"get_bin_index"},{"location":"activity/#tripsender.activity.rgb_to_hex","text":"Convert an RGB color tuple to a hexadecimal color string. Parameters: Name Type Description Default rgb_color tuple RGB color tuple (e.g., (0.1, 0.2, 0.3)). required Returns: Name Type Description str Hexadecimal color string (e.g., '#1a3456'). Source code in tripsender\\activity.py 947 948 949 950 951 952 953 954 955 956 957 958 959 def rgb_to_hex ( rgb_color ): \"\"\" Convert an RGB color tuple to a hexadecimal color string. Args: rgb_color (tuple): RGB color tuple (e.g., (0.1, 0.2, 0.3)). Returns: str: Hexadecimal color string (e.g., '#1a3456'). \"\"\" r , g , b , _ = rgb_color hex_color = \"# {:02x}{:02x}{:02x} \" . format ( int ( r * 255 ), int ( g * 255 ), int ( b * 255 )) return hex_color","title":"rgb_to_hex"},{"location":"building/","text":"Building Represents a building in Gothenburg, including its physical attributes and population data. A building object refers to an existing building and includes Footprint area Total built-up area Coordinates (in EPSG:3006 coordinate reference system) Height of the building (calculated from laser point-cloud data) Population per floor Total feasible population for the building Unique identifier List of house objects contained within it List of all people living in the building Attributes: Name Type Description uuid UUID Unique identifier for the building. type str Type of the building (e.g., residential, commercial). area float Total area of the building. height float Height of the building. floors int Number of floors in the building. footprint Polygon Footprint area of the building. population_per_floor int Population per floor in the building. population_total int Total population in the building. built_up_area float Total built-up area of the building. houses List List of house objects contained within the building. workers int Number of workers in the building. worker_list List List of workers in the building. coord Point Coordinates of the building's centroid. preferred_locations Optional [ PreferredLocations ] Preferred locations for the building. Source code in tripsender\\building.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 class Building : \"\"\" Represents a building in Gothenburg, including its physical attributes and population data. A building object refers to an existing building and includes: - Footprint area - Total built-up area - Coordinates (in EPSG:3006 coordinate reference system) - Height of the building (calculated from laser point-cloud data) - Population per floor - Total feasible population for the building - Unique identifier - List of house objects contained within it - List of all people living in the building Attributes: uuid (UUID): Unique identifier for the building. type (str): Type of the building (e.g., residential, commercial). area (float): Total area of the building. height (float): Height of the building. floors (int): Number of floors in the building. footprint (Polygon): Footprint area of the building. population_per_floor (int): Population per floor in the building. population_total (int): Total population in the building. built_up_area (float): Total built-up area of the building. houses (List): List of house objects contained within the building. workers (int): Number of workers in the building. worker_list (List): List of workers in the building. coord (Point): Coordinates of the building's centroid. preferred_locations (Optional[PreferredLocations]): Preferred locations for the building. \"\"\" instances = [] def __init__ ( self , building_type , building_area , building_height , building_floors , footprint , population_per_floor , built_up_area ): if footprint == None : raise ValueError ( \"Building footprint is None.\" ) self . uuid = uuid . uuid4 () self . type = building_type self . area = building_area self . height = building_height self . floors = building_floors self . footprint = footprint self . population_per_floor = population_per_floor self . population_total = 0 self . built_up_area = built_up_area self . houses = [] self . instances . append ( self ) self . workers : int = 0 self . worker_list : List = [] #self.isEmpty = True self . coord = footprint . centroid # Initialize the preferred locations for this building self . preferred_locations : Optional ( PreferredLocations ) = None @property def is_empty ( self ): return len ( self . houses ) == 0 @classmethod def clear_instances ( cls ): cls . instances = [] def __repr__ ( self ): return f \"A { self . type } building with { self . floors } floors and { self . population_total } people.\" def info ( self ): \"\"\"Returns a dictionary with information about the building.\"\"\" return { \"Building UUID\" : self . uuid , \"Building Type\" : self . type , \"Building Area\" : self . area , \"Building Height\" : self . height , \"Building Floors\" : self . floors , \"Building Footprint\" : self . footprint , \"Population per Floor\" : self . population_per_floor , \"Population Total\" : self . population_total , \"Houses in Building\" : [ house . info () for house in self . houses ], \"Built up Area\" : self . built_up_area , \"Is building empty\" : self . isEmpty , \"Number of workers\" : self . workers , } @classmethod def instantiate_buildings ( cls , gdf_residential : gpd . GeoDataFrame ): \"\"\"Instantiate building objects based on input data.\"\"\" cls . clear_instances () for _ , row in gdf_residential . iterrows (): Building ( row [ 'byggnadsundergrupp' ], row [ 'area' ], row [ 'height' ], row [ 'floors' ], row [ 'geom' ], row [ 'population_per_floor' ], row [ 'BTA' ] ) if len ( cls . instances ) == 0 : raise ValueError ( \"Unable to instantiate buildings.\" ) def add_houses ( self , house ): self . houses . append ( house ) house . building = self self . population_total += len ( house . household . members ) #self.isEmpty = False house . building_uuid = self . uuid @classmethod def return_gdf ( cls ): \"\"\"Returns a GeoDataFrame with all buildings.\"\"\" gdf = gpd . GeoDataFrame () gdf [ 'uuid' ] = [ building . uuid for building in cls . instances ] gdf [ 'type' ] = [ building . type for building in cls . instances ] gdf [ 'area' ] = [ building . area for building in cls . instances ] gdf [ 'height' ] = [ building . height for building in cls . instances ] gdf [ 'floors' ] = [ building . floors for building in cls . instances ] gdf [ 'footprint' ] = [ building . footprint for building in cls . instances ] gdf [ 'population_per_floor' ] = [ building . population_per_floor for building in cls . instances ] gdf [ 'population_total' ] = [ building . population_total for building in cls . instances ] gdf [ 'built_up_area' ] = [ building . built_up_area for building in cls . instances ] gdf [ 'workers' ] = [ building . workers for building in cls . instances ] gdf [ 'is_empty' ] = [ building . is_empty for building in cls . instances ] gdf [ 'building' ] = [ building for building in cls . instances ] gdf [ 'coord' ] = [ building . coord for building in cls . instances ] gdf [ 'preferred_locations' ] = [ building . preferred_locations for building in cls . instances ] # Set geometry to footprint gdf = gdf . set_geometry ( 'footprint' ) # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" # If there are no buildings raise an error if len ( gdf ) == 0 : raise ValueError ( \"There are no buildings in the simulation.\" ) return gdf import contextily as ctx def plot ( self ): \"\"\" Plots the building footprint on a map with a basemap using contextily. \"\"\" # Create a GeoDataFrame gdf = gpd . GeoDataFrame ({ 'geometry' : [ self . footprint ]}, crs = \"EPSG:3006\" ) # Convert the GeoDataFrame to the Web Mercator projection (used by most contextily basemaps) gdf = gdf . to_crs ( epsg = 3857 ) # Plotting fig , ax = plt . subplots ( figsize = ( 10 , 10 )) gdf . plot ( ax = ax , alpha = 0.5 , color = 'blue' ) # Adjust alpha and color to your preference # Add basemap with contextily ctx . add_basemap ( ax ) # Optionally set bounds ax . set_xlim ([ gdf . total_bounds [ 0 ] - 1000 , gdf . total_bounds [ 2 ] + 1000 ]) ax . set_ylim ([ gdf . total_bounds [ 1 ] - 1000 , gdf . total_bounds [ 3 ] + 1000 ]) ax . axis ( 'off' ) # Turn off axis plt . show () info () Returns a dictionary with information about the building. Source code in tripsender\\building.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def info ( self ): \"\"\"Returns a dictionary with information about the building.\"\"\" return { \"Building UUID\" : self . uuid , \"Building Type\" : self . type , \"Building Area\" : self . area , \"Building Height\" : self . height , \"Building Floors\" : self . floors , \"Building Footprint\" : self . footprint , \"Population per Floor\" : self . population_per_floor , \"Population Total\" : self . population_total , \"Houses in Building\" : [ house . info () for house in self . houses ], \"Built up Area\" : self . built_up_area , \"Is building empty\" : self . isEmpty , \"Number of workers\" : self . workers , } instantiate_buildings ( gdf_residential ) classmethod Instantiate building objects based on input data. Source code in tripsender\\building.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @classmethod def instantiate_buildings ( cls , gdf_residential : gpd . GeoDataFrame ): \"\"\"Instantiate building objects based on input data.\"\"\" cls . clear_instances () for _ , row in gdf_residential . iterrows (): Building ( row [ 'byggnadsundergrupp' ], row [ 'area' ], row [ 'height' ], row [ 'floors' ], row [ 'geom' ], row [ 'population_per_floor' ], row [ 'BTA' ] ) if len ( cls . instances ) == 0 : raise ValueError ( \"Unable to instantiate buildings.\" ) plot () Plots the building footprint on a map with a basemap using contextily. Source code in tripsender\\building.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 def plot ( self ): \"\"\" Plots the building footprint on a map with a basemap using contextily. \"\"\" # Create a GeoDataFrame gdf = gpd . GeoDataFrame ({ 'geometry' : [ self . footprint ]}, crs = \"EPSG:3006\" ) # Convert the GeoDataFrame to the Web Mercator projection (used by most contextily basemaps) gdf = gdf . to_crs ( epsg = 3857 ) # Plotting fig , ax = plt . subplots ( figsize = ( 10 , 10 )) gdf . plot ( ax = ax , alpha = 0.5 , color = 'blue' ) # Adjust alpha and color to your preference # Add basemap with contextily ctx . add_basemap ( ax ) # Optionally set bounds ax . set_xlim ([ gdf . total_bounds [ 0 ] - 1000 , gdf . total_bounds [ 2 ] + 1000 ]) ax . set_ylim ([ gdf . total_bounds [ 1 ] - 1000 , gdf . total_bounds [ 3 ] + 1000 ]) ax . axis ( 'off' ) # Turn off axis plt . show () return_gdf () classmethod Returns a GeoDataFrame with all buildings. Source code in tripsender\\building.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 @classmethod def return_gdf ( cls ): \"\"\"Returns a GeoDataFrame with all buildings.\"\"\" gdf = gpd . GeoDataFrame () gdf [ 'uuid' ] = [ building . uuid for building in cls . instances ] gdf [ 'type' ] = [ building . type for building in cls . instances ] gdf [ 'area' ] = [ building . area for building in cls . instances ] gdf [ 'height' ] = [ building . height for building in cls . instances ] gdf [ 'floors' ] = [ building . floors for building in cls . instances ] gdf [ 'footprint' ] = [ building . footprint for building in cls . instances ] gdf [ 'population_per_floor' ] = [ building . population_per_floor for building in cls . instances ] gdf [ 'population_total' ] = [ building . population_total for building in cls . instances ] gdf [ 'built_up_area' ] = [ building . built_up_area for building in cls . instances ] gdf [ 'workers' ] = [ building . workers for building in cls . instances ] gdf [ 'is_empty' ] = [ building . is_empty for building in cls . instances ] gdf [ 'building' ] = [ building for building in cls . instances ] gdf [ 'coord' ] = [ building . coord for building in cls . instances ] gdf [ 'preferred_locations' ] = [ building . preferred_locations for building in cls . instances ] # Set geometry to footprint gdf = gdf . set_geometry ( 'footprint' ) # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" # If there are no buildings raise an error if len ( gdf ) == 0 : raise ValueError ( \"There are no buildings in the simulation.\" ) return gdf PreferredLocations Represents a collection of preferred locations categorized by type. Each attribute in this class represents a different type of preferred location. While some locations have only one preferred spot (e.g., schools), others can have multiple preferred spots (e.g., leisure locations). Source code in tripsender\\building.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 class PreferredLocations : \"\"\" Represents a collection of preferred locations categorized by type. Each attribute in this class represents a different type of preferred location. While some locations have only one preferred spot (e.g., schools), others can have multiple preferred spots (e.g., leisure locations). \"\"\" instances = [] all_locations_coords = [] # Class-level list to store coordinates def __init__ ( self , locations : List [ Location ]): self . EDUCATION_f\u00f6rskola : Location = None self . EDUCATION_f\u00f6rskoleklass : Location = None self . EDUCATION_grundskola : Location = None self . EDUCATION_gymnasieskola : Location = None self . EDUCATION_fritidshem : Location = None self . LEISURE_sports : List [ Location ] = [] self . LEISURE_playground : List [ Location ] = [] self . EDUCATION : List [ Location ] = [] self . SHOPPING_GROCERY : List [ Location ] = [] self . SHOPPING_OTHER : List [ Location ] = [] self . LEISURE : List [ Location ] = [] self . HEALTHCARE : List [ Location ] = [] self . origin : None self . instances . append ( self ) for location in locations : self . all_locations_coords . append ( location . location_coordinates ) for location in locations : if location . location_type == \"EDUCATION_f\u00f6rskola\" : self . EDUCATION_f\u00f6rskola = location elif location . location_type == \"EDUCATION_f\u00f6rskoleklass\" : self . EDUCATION_f\u00f6rskoleklass = location elif location . location_type == \"EDUCATION_grundskola\" : self . EDUCATION_grundskola = location elif location . location_type == \"EDUCATION_gymnasieskola\" : self . EDUCATION_gymnasieskola = location elif location . location_type == \"EDUCATION_fritidshem\" : self . EDUCATION_fritidshem = location elif location . location_type == \"LEISURE_sports\" : self . LEISURE_sports . append ( location ) elif location . location_type == \"LEISURE_playground\" : self . LEISURE_playground . append ( location ) elif location . location_type == \"EDUCATION\" : self . EDUCATION . append ( location ) elif location . location_type == \"SHOPPING_OTHER\" : self . SHOPPING_OTHER . append ( location ) elif location . location_type == \"LEISURE\" : self . LEISURE . append ( location ) elif location . location_type == \"HEALTHCARE\" : self . HEALTHCARE . append ( location ) elif location . location_type == \"SHOPPING_GROCERY\" : self . SHOPPING_GROCERY . append ( location ) def __repr__ ( self ): return ( f \"Preferred locations for this household: \\n \" f \" EDUCATION_f\u00f6rskola: { self . EDUCATION_f\u00f6rskola } \\n \" f \" EDUCATION_f\u00f6rskoleklass: { self . EDUCATION_f\u00f6rskoleklass } \\n \" f \" EDUCATION_grundskola: { self . EDUCATION_grundskola } \\n \" f \" EDUCATION_gymnasieskola: { self . EDUCATION_gymnasieskola } \\n \" f \" EDUCATION_fritidshem: { self . EDUCATION_fritidshem } \\n \" f \" LEISURE_sports: { self . LEISURE_sports } \\n \" f \" LEISURE_playground: { self . LEISURE_playground } \\n \" f \" EDUCATION: { self . EDUCATION } \\n \" f \" SHOPPING_OTHER: { self . SHOPPING_OTHER } \\n \" f \" LEISURE: { self . LEISURE } \\n \" f \" HEALTHCARE: { self . HEALTHCARE } \\n \" f \" SHOPPING_GROCERY: { self . SHOPPING_GROCERY } \\n \" f \" origin: { self . origin } \\n \" ) def get_dict ( self ): dictionary = { \"EDUCATION_f\u00f6rskola\" : self . EDUCATION_f\u00f6rskola , \"EDUCATION_f\u00f6rskoleklass\" : self . EDUCATION_f\u00f6rskoleklass , \"EDUCATION_grundskola\" : self . EDUCATION_grundskola , \"EDUCATION_gymnasieskola\" : self . EDUCATION_gymnasieskola , \"EDUCATION_fritidshem\" : self . EDUCATION_fritidshem , \"LEISURE_sports\" : self . LEISURE_sports , \"LEISURE_playground\" : self . LEISURE_playground , \"EDUCATION\" : self . EDUCATION , \"SHOPPING_OTHER\" : self . SHOPPING_OTHER , \"LEISURE\" : self . LEISURE , \"HEALTHCARE\" : self . HEALTHCARE , \"SHOPPING_GROCERY\" : self . SHOPPING_GROCERY , \"origin\" : self . origin } return dictionary def random_location ( self ): \"\"\"Returns a random preferred location.\"\"\" # Extracting all locations into a flat list return random . choice ( self . all_locations_coords ) def return_gdf ( self ): \"\"\"Returns a GeoDataFrame of the preferred locations.\"\"\" # Extracting all locations into a flat list all_locations = [] origin = self . origin for attr , value in self . __dict__ . items (): # Skip origin if attr == \"origin\" : continue if isinstance ( value , list ): all_locations . extend ( value ) elif value is not None : all_locations . append ( value ) # Convert locations to GeoDataFrame gdf = gpd . GeoDataFrame ({ 'LocationType' : [ loc . location_type for loc in all_locations ], 'geometry' : [ loc . location_coordinates for loc in all_locations ] }) # Add origin (Point) to GeoDataFrame gdf . loc [ - 1 ] = [ \"Origin\" , origin ] # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" return gdf def plot ( self , figsize = ( 10 , 10 ), ax = None ): \"\"\"Plots the preferred locations using different colors for each activity type.\"\"\" gdf = self . return_gdf () # Defining colors for each location type for visualization colors = { \"EDUCATION_f\u00f6rskola\" : \"blue\" , \"EDUCATION_f\u00f6rskoleklass\" : \"cyan\" , \"EDUCATION_grundskola\" : \"green\" , \"EDUCATION_gymnasieskola\" : \"yellow\" , \"EDUCATION_fritidshem\" : \"purple\" , \"LEISURE_sports\" : \"red\" , \"LEISURE_playground\" : \"orange\" , \"EDUCATION\" : \"pink\" , \"SHOPPING_GROCERY\" : \"brown\" , \"SHOPPING_OTHER\" : \"gray\" , \"LEISURE\" : \"magenta\" , \"HEALTHCARE\" : \"black\" } # Plotting if not ax : fig , ax = plt . subplots () for location_type , color in colors . items (): gdf [ gdf [ 'LocationType' ] == location_type ] . plot ( ax = ax , color = color , label = location_type ) ax . legend ( loc = \"upper left\" ) plt . title ( \"Preferred Locations by Activity Type\" ) plt . xlabel ( \"Longitude\" ) plt . ylabel ( \"Latitude\" ) plt . grid ( True ) plt . show () @classmethod def return_convex_hull ( cls ): \"\"\"Returns the convex hull of all preferred locations.\"\"\" # Convert list of coordinates to MultiPoint #Chcekc that all_locations_coords is not empty if len ( cls . all_locations_coords ) == 0 : raise ValueError ( \"There are no preferred locations in the simulation.\" ) multi_point = MultiPoint ( cls . all_locations_coords ) # Return the convex hull return multi_point . convex_hull plot ( figsize = ( 10 , 10 ), ax = None ) Plots the preferred locations using different colors for each activity type. Source code in tripsender\\building.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 def plot ( self , figsize = ( 10 , 10 ), ax = None ): \"\"\"Plots the preferred locations using different colors for each activity type.\"\"\" gdf = self . return_gdf () # Defining colors for each location type for visualization colors = { \"EDUCATION_f\u00f6rskola\" : \"blue\" , \"EDUCATION_f\u00f6rskoleklass\" : \"cyan\" , \"EDUCATION_grundskola\" : \"green\" , \"EDUCATION_gymnasieskola\" : \"yellow\" , \"EDUCATION_fritidshem\" : \"purple\" , \"LEISURE_sports\" : \"red\" , \"LEISURE_playground\" : \"orange\" , \"EDUCATION\" : \"pink\" , \"SHOPPING_GROCERY\" : \"brown\" , \"SHOPPING_OTHER\" : \"gray\" , \"LEISURE\" : \"magenta\" , \"HEALTHCARE\" : \"black\" } # Plotting if not ax : fig , ax = plt . subplots () for location_type , color in colors . items (): gdf [ gdf [ 'LocationType' ] == location_type ] . plot ( ax = ax , color = color , label = location_type ) ax . legend ( loc = \"upper left\" ) plt . title ( \"Preferred Locations by Activity Type\" ) plt . xlabel ( \"Longitude\" ) plt . ylabel ( \"Latitude\" ) plt . grid ( True ) plt . show () random_location () Returns a random preferred location. Source code in tripsender\\building.py 291 292 293 294 def random_location ( self ): \"\"\"Returns a random preferred location.\"\"\" # Extracting all locations into a flat list return random . choice ( self . all_locations_coords ) return_convex_hull () classmethod Returns the convex hull of all preferred locations. Source code in tripsender\\building.py 359 360 361 362 363 364 365 366 367 368 369 370 371 @classmethod def return_convex_hull ( cls ): \"\"\"Returns the convex hull of all preferred locations.\"\"\" # Convert list of coordinates to MultiPoint #Chcekc that all_locations_coords is not empty if len ( cls . all_locations_coords ) == 0 : raise ValueError ( \"There are no preferred locations in the simulation.\" ) multi_point = MultiPoint ( cls . all_locations_coords ) # Return the convex hull return multi_point . convex_hull return_gdf () Returns a GeoDataFrame of the preferred locations. Source code in tripsender\\building.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 def return_gdf ( self ): \"\"\"Returns a GeoDataFrame of the preferred locations.\"\"\" # Extracting all locations into a flat list all_locations = [] origin = self . origin for attr , value in self . __dict__ . items (): # Skip origin if attr == \"origin\" : continue if isinstance ( value , list ): all_locations . extend ( value ) elif value is not None : all_locations . append ( value ) # Convert locations to GeoDataFrame gdf = gpd . GeoDataFrame ({ 'LocationType' : [ loc . location_type for loc in all_locations ], 'geometry' : [ loc . location_coordinates for loc in all_locations ] }) # Add origin (Point) to GeoDataFrame gdf . loc [ - 1 ] = [ \"Origin\" , origin ] # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" return gdf","title":"building"},{"location":"building/#tripsender.building.Building","text":"Represents a building in Gothenburg, including its physical attributes and population data. A building object refers to an existing building and includes Footprint area Total built-up area Coordinates (in EPSG:3006 coordinate reference system) Height of the building (calculated from laser point-cloud data) Population per floor Total feasible population for the building Unique identifier List of house objects contained within it List of all people living in the building Attributes: Name Type Description uuid UUID Unique identifier for the building. type str Type of the building (e.g., residential, commercial). area float Total area of the building. height float Height of the building. floors int Number of floors in the building. footprint Polygon Footprint area of the building. population_per_floor int Population per floor in the building. population_total int Total population in the building. built_up_area float Total built-up area of the building. houses List List of house objects contained within the building. workers int Number of workers in the building. worker_list List List of workers in the building. coord Point Coordinates of the building's centroid. preferred_locations Optional [ PreferredLocations ] Preferred locations for the building. Source code in tripsender\\building.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 class Building : \"\"\" Represents a building in Gothenburg, including its physical attributes and population data. A building object refers to an existing building and includes: - Footprint area - Total built-up area - Coordinates (in EPSG:3006 coordinate reference system) - Height of the building (calculated from laser point-cloud data) - Population per floor - Total feasible population for the building - Unique identifier - List of house objects contained within it - List of all people living in the building Attributes: uuid (UUID): Unique identifier for the building. type (str): Type of the building (e.g., residential, commercial). area (float): Total area of the building. height (float): Height of the building. floors (int): Number of floors in the building. footprint (Polygon): Footprint area of the building. population_per_floor (int): Population per floor in the building. population_total (int): Total population in the building. built_up_area (float): Total built-up area of the building. houses (List): List of house objects contained within the building. workers (int): Number of workers in the building. worker_list (List): List of workers in the building. coord (Point): Coordinates of the building's centroid. preferred_locations (Optional[PreferredLocations]): Preferred locations for the building. \"\"\" instances = [] def __init__ ( self , building_type , building_area , building_height , building_floors , footprint , population_per_floor , built_up_area ): if footprint == None : raise ValueError ( \"Building footprint is None.\" ) self . uuid = uuid . uuid4 () self . type = building_type self . area = building_area self . height = building_height self . floors = building_floors self . footprint = footprint self . population_per_floor = population_per_floor self . population_total = 0 self . built_up_area = built_up_area self . houses = [] self . instances . append ( self ) self . workers : int = 0 self . worker_list : List = [] #self.isEmpty = True self . coord = footprint . centroid # Initialize the preferred locations for this building self . preferred_locations : Optional ( PreferredLocations ) = None @property def is_empty ( self ): return len ( self . houses ) == 0 @classmethod def clear_instances ( cls ): cls . instances = [] def __repr__ ( self ): return f \"A { self . type } building with { self . floors } floors and { self . population_total } people.\" def info ( self ): \"\"\"Returns a dictionary with information about the building.\"\"\" return { \"Building UUID\" : self . uuid , \"Building Type\" : self . type , \"Building Area\" : self . area , \"Building Height\" : self . height , \"Building Floors\" : self . floors , \"Building Footprint\" : self . footprint , \"Population per Floor\" : self . population_per_floor , \"Population Total\" : self . population_total , \"Houses in Building\" : [ house . info () for house in self . houses ], \"Built up Area\" : self . built_up_area , \"Is building empty\" : self . isEmpty , \"Number of workers\" : self . workers , } @classmethod def instantiate_buildings ( cls , gdf_residential : gpd . GeoDataFrame ): \"\"\"Instantiate building objects based on input data.\"\"\" cls . clear_instances () for _ , row in gdf_residential . iterrows (): Building ( row [ 'byggnadsundergrupp' ], row [ 'area' ], row [ 'height' ], row [ 'floors' ], row [ 'geom' ], row [ 'population_per_floor' ], row [ 'BTA' ] ) if len ( cls . instances ) == 0 : raise ValueError ( \"Unable to instantiate buildings.\" ) def add_houses ( self , house ): self . houses . append ( house ) house . building = self self . population_total += len ( house . household . members ) #self.isEmpty = False house . building_uuid = self . uuid @classmethod def return_gdf ( cls ): \"\"\"Returns a GeoDataFrame with all buildings.\"\"\" gdf = gpd . GeoDataFrame () gdf [ 'uuid' ] = [ building . uuid for building in cls . instances ] gdf [ 'type' ] = [ building . type for building in cls . instances ] gdf [ 'area' ] = [ building . area for building in cls . instances ] gdf [ 'height' ] = [ building . height for building in cls . instances ] gdf [ 'floors' ] = [ building . floors for building in cls . instances ] gdf [ 'footprint' ] = [ building . footprint for building in cls . instances ] gdf [ 'population_per_floor' ] = [ building . population_per_floor for building in cls . instances ] gdf [ 'population_total' ] = [ building . population_total for building in cls . instances ] gdf [ 'built_up_area' ] = [ building . built_up_area for building in cls . instances ] gdf [ 'workers' ] = [ building . workers for building in cls . instances ] gdf [ 'is_empty' ] = [ building . is_empty for building in cls . instances ] gdf [ 'building' ] = [ building for building in cls . instances ] gdf [ 'coord' ] = [ building . coord for building in cls . instances ] gdf [ 'preferred_locations' ] = [ building . preferred_locations for building in cls . instances ] # Set geometry to footprint gdf = gdf . set_geometry ( 'footprint' ) # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" # If there are no buildings raise an error if len ( gdf ) == 0 : raise ValueError ( \"There are no buildings in the simulation.\" ) return gdf import contextily as ctx def plot ( self ): \"\"\" Plots the building footprint on a map with a basemap using contextily. \"\"\" # Create a GeoDataFrame gdf = gpd . GeoDataFrame ({ 'geometry' : [ self . footprint ]}, crs = \"EPSG:3006\" ) # Convert the GeoDataFrame to the Web Mercator projection (used by most contextily basemaps) gdf = gdf . to_crs ( epsg = 3857 ) # Plotting fig , ax = plt . subplots ( figsize = ( 10 , 10 )) gdf . plot ( ax = ax , alpha = 0.5 , color = 'blue' ) # Adjust alpha and color to your preference # Add basemap with contextily ctx . add_basemap ( ax ) # Optionally set bounds ax . set_xlim ([ gdf . total_bounds [ 0 ] - 1000 , gdf . total_bounds [ 2 ] + 1000 ]) ax . set_ylim ([ gdf . total_bounds [ 1 ] - 1000 , gdf . total_bounds [ 3 ] + 1000 ]) ax . axis ( 'off' ) # Turn off axis plt . show ()","title":"Building"},{"location":"building/#tripsender.building.Building.info","text":"Returns a dictionary with information about the building. Source code in tripsender\\building.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def info ( self ): \"\"\"Returns a dictionary with information about the building.\"\"\" return { \"Building UUID\" : self . uuid , \"Building Type\" : self . type , \"Building Area\" : self . area , \"Building Height\" : self . height , \"Building Floors\" : self . floors , \"Building Footprint\" : self . footprint , \"Population per Floor\" : self . population_per_floor , \"Population Total\" : self . population_total , \"Houses in Building\" : [ house . info () for house in self . houses ], \"Built up Area\" : self . built_up_area , \"Is building empty\" : self . isEmpty , \"Number of workers\" : self . workers , }","title":"info"},{"location":"building/#tripsender.building.Building.instantiate_buildings","text":"Instantiate building objects based on input data. Source code in tripsender\\building.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @classmethod def instantiate_buildings ( cls , gdf_residential : gpd . GeoDataFrame ): \"\"\"Instantiate building objects based on input data.\"\"\" cls . clear_instances () for _ , row in gdf_residential . iterrows (): Building ( row [ 'byggnadsundergrupp' ], row [ 'area' ], row [ 'height' ], row [ 'floors' ], row [ 'geom' ], row [ 'population_per_floor' ], row [ 'BTA' ] ) if len ( cls . instances ) == 0 : raise ValueError ( \"Unable to instantiate buildings.\" )","title":"instantiate_buildings"},{"location":"building/#tripsender.building.Building.plot","text":"Plots the building footprint on a map with a basemap using contextily. Source code in tripsender\\building.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 def plot ( self ): \"\"\" Plots the building footprint on a map with a basemap using contextily. \"\"\" # Create a GeoDataFrame gdf = gpd . GeoDataFrame ({ 'geometry' : [ self . footprint ]}, crs = \"EPSG:3006\" ) # Convert the GeoDataFrame to the Web Mercator projection (used by most contextily basemaps) gdf = gdf . to_crs ( epsg = 3857 ) # Plotting fig , ax = plt . subplots ( figsize = ( 10 , 10 )) gdf . plot ( ax = ax , alpha = 0.5 , color = 'blue' ) # Adjust alpha and color to your preference # Add basemap with contextily ctx . add_basemap ( ax ) # Optionally set bounds ax . set_xlim ([ gdf . total_bounds [ 0 ] - 1000 , gdf . total_bounds [ 2 ] + 1000 ]) ax . set_ylim ([ gdf . total_bounds [ 1 ] - 1000 , gdf . total_bounds [ 3 ] + 1000 ]) ax . axis ( 'off' ) # Turn off axis plt . show ()","title":"plot"},{"location":"building/#tripsender.building.Building.return_gdf","text":"Returns a GeoDataFrame with all buildings. Source code in tripsender\\building.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 @classmethod def return_gdf ( cls ): \"\"\"Returns a GeoDataFrame with all buildings.\"\"\" gdf = gpd . GeoDataFrame () gdf [ 'uuid' ] = [ building . uuid for building in cls . instances ] gdf [ 'type' ] = [ building . type for building in cls . instances ] gdf [ 'area' ] = [ building . area for building in cls . instances ] gdf [ 'height' ] = [ building . height for building in cls . instances ] gdf [ 'floors' ] = [ building . floors for building in cls . instances ] gdf [ 'footprint' ] = [ building . footprint for building in cls . instances ] gdf [ 'population_per_floor' ] = [ building . population_per_floor for building in cls . instances ] gdf [ 'population_total' ] = [ building . population_total for building in cls . instances ] gdf [ 'built_up_area' ] = [ building . built_up_area for building in cls . instances ] gdf [ 'workers' ] = [ building . workers for building in cls . instances ] gdf [ 'is_empty' ] = [ building . is_empty for building in cls . instances ] gdf [ 'building' ] = [ building for building in cls . instances ] gdf [ 'coord' ] = [ building . coord for building in cls . instances ] gdf [ 'preferred_locations' ] = [ building . preferred_locations for building in cls . instances ] # Set geometry to footprint gdf = gdf . set_geometry ( 'footprint' ) # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" # If there are no buildings raise an error if len ( gdf ) == 0 : raise ValueError ( \"There are no buildings in the simulation.\" ) return gdf","title":"return_gdf"},{"location":"building/#tripsender.building.PreferredLocations","text":"Represents a collection of preferred locations categorized by type. Each attribute in this class represents a different type of preferred location. While some locations have only one preferred spot (e.g., schools), others can have multiple preferred spots (e.g., leisure locations). Source code in tripsender\\building.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 class PreferredLocations : \"\"\" Represents a collection of preferred locations categorized by type. Each attribute in this class represents a different type of preferred location. While some locations have only one preferred spot (e.g., schools), others can have multiple preferred spots (e.g., leisure locations). \"\"\" instances = [] all_locations_coords = [] # Class-level list to store coordinates def __init__ ( self , locations : List [ Location ]): self . EDUCATION_f\u00f6rskola : Location = None self . EDUCATION_f\u00f6rskoleklass : Location = None self . EDUCATION_grundskola : Location = None self . EDUCATION_gymnasieskola : Location = None self . EDUCATION_fritidshem : Location = None self . LEISURE_sports : List [ Location ] = [] self . LEISURE_playground : List [ Location ] = [] self . EDUCATION : List [ Location ] = [] self . SHOPPING_GROCERY : List [ Location ] = [] self . SHOPPING_OTHER : List [ Location ] = [] self . LEISURE : List [ Location ] = [] self . HEALTHCARE : List [ Location ] = [] self . origin : None self . instances . append ( self ) for location in locations : self . all_locations_coords . append ( location . location_coordinates ) for location in locations : if location . location_type == \"EDUCATION_f\u00f6rskola\" : self . EDUCATION_f\u00f6rskola = location elif location . location_type == \"EDUCATION_f\u00f6rskoleklass\" : self . EDUCATION_f\u00f6rskoleklass = location elif location . location_type == \"EDUCATION_grundskola\" : self . EDUCATION_grundskola = location elif location . location_type == \"EDUCATION_gymnasieskola\" : self . EDUCATION_gymnasieskola = location elif location . location_type == \"EDUCATION_fritidshem\" : self . EDUCATION_fritidshem = location elif location . location_type == \"LEISURE_sports\" : self . LEISURE_sports . append ( location ) elif location . location_type == \"LEISURE_playground\" : self . LEISURE_playground . append ( location ) elif location . location_type == \"EDUCATION\" : self . EDUCATION . append ( location ) elif location . location_type == \"SHOPPING_OTHER\" : self . SHOPPING_OTHER . append ( location ) elif location . location_type == \"LEISURE\" : self . LEISURE . append ( location ) elif location . location_type == \"HEALTHCARE\" : self . HEALTHCARE . append ( location ) elif location . location_type == \"SHOPPING_GROCERY\" : self . SHOPPING_GROCERY . append ( location ) def __repr__ ( self ): return ( f \"Preferred locations for this household: \\n \" f \" EDUCATION_f\u00f6rskola: { self . EDUCATION_f\u00f6rskola } \\n \" f \" EDUCATION_f\u00f6rskoleklass: { self . EDUCATION_f\u00f6rskoleklass } \\n \" f \" EDUCATION_grundskola: { self . EDUCATION_grundskola } \\n \" f \" EDUCATION_gymnasieskola: { self . EDUCATION_gymnasieskola } \\n \" f \" EDUCATION_fritidshem: { self . EDUCATION_fritidshem } \\n \" f \" LEISURE_sports: { self . LEISURE_sports } \\n \" f \" LEISURE_playground: { self . LEISURE_playground } \\n \" f \" EDUCATION: { self . EDUCATION } \\n \" f \" SHOPPING_OTHER: { self . SHOPPING_OTHER } \\n \" f \" LEISURE: { self . LEISURE } \\n \" f \" HEALTHCARE: { self . HEALTHCARE } \\n \" f \" SHOPPING_GROCERY: { self . SHOPPING_GROCERY } \\n \" f \" origin: { self . origin } \\n \" ) def get_dict ( self ): dictionary = { \"EDUCATION_f\u00f6rskola\" : self . EDUCATION_f\u00f6rskola , \"EDUCATION_f\u00f6rskoleklass\" : self . EDUCATION_f\u00f6rskoleklass , \"EDUCATION_grundskola\" : self . EDUCATION_grundskola , \"EDUCATION_gymnasieskola\" : self . EDUCATION_gymnasieskola , \"EDUCATION_fritidshem\" : self . EDUCATION_fritidshem , \"LEISURE_sports\" : self . LEISURE_sports , \"LEISURE_playground\" : self . LEISURE_playground , \"EDUCATION\" : self . EDUCATION , \"SHOPPING_OTHER\" : self . SHOPPING_OTHER , \"LEISURE\" : self . LEISURE , \"HEALTHCARE\" : self . HEALTHCARE , \"SHOPPING_GROCERY\" : self . SHOPPING_GROCERY , \"origin\" : self . origin } return dictionary def random_location ( self ): \"\"\"Returns a random preferred location.\"\"\" # Extracting all locations into a flat list return random . choice ( self . all_locations_coords ) def return_gdf ( self ): \"\"\"Returns a GeoDataFrame of the preferred locations.\"\"\" # Extracting all locations into a flat list all_locations = [] origin = self . origin for attr , value in self . __dict__ . items (): # Skip origin if attr == \"origin\" : continue if isinstance ( value , list ): all_locations . extend ( value ) elif value is not None : all_locations . append ( value ) # Convert locations to GeoDataFrame gdf = gpd . GeoDataFrame ({ 'LocationType' : [ loc . location_type for loc in all_locations ], 'geometry' : [ loc . location_coordinates for loc in all_locations ] }) # Add origin (Point) to GeoDataFrame gdf . loc [ - 1 ] = [ \"Origin\" , origin ] # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" return gdf def plot ( self , figsize = ( 10 , 10 ), ax = None ): \"\"\"Plots the preferred locations using different colors for each activity type.\"\"\" gdf = self . return_gdf () # Defining colors for each location type for visualization colors = { \"EDUCATION_f\u00f6rskola\" : \"blue\" , \"EDUCATION_f\u00f6rskoleklass\" : \"cyan\" , \"EDUCATION_grundskola\" : \"green\" , \"EDUCATION_gymnasieskola\" : \"yellow\" , \"EDUCATION_fritidshem\" : \"purple\" , \"LEISURE_sports\" : \"red\" , \"LEISURE_playground\" : \"orange\" , \"EDUCATION\" : \"pink\" , \"SHOPPING_GROCERY\" : \"brown\" , \"SHOPPING_OTHER\" : \"gray\" , \"LEISURE\" : \"magenta\" , \"HEALTHCARE\" : \"black\" } # Plotting if not ax : fig , ax = plt . subplots () for location_type , color in colors . items (): gdf [ gdf [ 'LocationType' ] == location_type ] . plot ( ax = ax , color = color , label = location_type ) ax . legend ( loc = \"upper left\" ) plt . title ( \"Preferred Locations by Activity Type\" ) plt . xlabel ( \"Longitude\" ) plt . ylabel ( \"Latitude\" ) plt . grid ( True ) plt . show () @classmethod def return_convex_hull ( cls ): \"\"\"Returns the convex hull of all preferred locations.\"\"\" # Convert list of coordinates to MultiPoint #Chcekc that all_locations_coords is not empty if len ( cls . all_locations_coords ) == 0 : raise ValueError ( \"There are no preferred locations in the simulation.\" ) multi_point = MultiPoint ( cls . all_locations_coords ) # Return the convex hull return multi_point . convex_hull","title":"PreferredLocations"},{"location":"building/#tripsender.building.PreferredLocations.plot","text":"Plots the preferred locations using different colors for each activity type. Source code in tripsender\\building.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 def plot ( self , figsize = ( 10 , 10 ), ax = None ): \"\"\"Plots the preferred locations using different colors for each activity type.\"\"\" gdf = self . return_gdf () # Defining colors for each location type for visualization colors = { \"EDUCATION_f\u00f6rskola\" : \"blue\" , \"EDUCATION_f\u00f6rskoleklass\" : \"cyan\" , \"EDUCATION_grundskola\" : \"green\" , \"EDUCATION_gymnasieskola\" : \"yellow\" , \"EDUCATION_fritidshem\" : \"purple\" , \"LEISURE_sports\" : \"red\" , \"LEISURE_playground\" : \"orange\" , \"EDUCATION\" : \"pink\" , \"SHOPPING_GROCERY\" : \"brown\" , \"SHOPPING_OTHER\" : \"gray\" , \"LEISURE\" : \"magenta\" , \"HEALTHCARE\" : \"black\" } # Plotting if not ax : fig , ax = plt . subplots () for location_type , color in colors . items (): gdf [ gdf [ 'LocationType' ] == location_type ] . plot ( ax = ax , color = color , label = location_type ) ax . legend ( loc = \"upper left\" ) plt . title ( \"Preferred Locations by Activity Type\" ) plt . xlabel ( \"Longitude\" ) plt . ylabel ( \"Latitude\" ) plt . grid ( True ) plt . show ()","title":"plot"},{"location":"building/#tripsender.building.PreferredLocations.random_location","text":"Returns a random preferred location. Source code in tripsender\\building.py 291 292 293 294 def random_location ( self ): \"\"\"Returns a random preferred location.\"\"\" # Extracting all locations into a flat list return random . choice ( self . all_locations_coords )","title":"random_location"},{"location":"building/#tripsender.building.PreferredLocations.return_convex_hull","text":"Returns the convex hull of all preferred locations. Source code in tripsender\\building.py 359 360 361 362 363 364 365 366 367 368 369 370 371 @classmethod def return_convex_hull ( cls ): \"\"\"Returns the convex hull of all preferred locations.\"\"\" # Convert list of coordinates to MultiPoint #Chcekc that all_locations_coords is not empty if len ( cls . all_locations_coords ) == 0 : raise ValueError ( \"There are no preferred locations in the simulation.\" ) multi_point = MultiPoint ( cls . all_locations_coords ) # Return the convex hull return multi_point . convex_hull","title":"return_convex_hull"},{"location":"building/#tripsender.building.PreferredLocations.return_gdf","text":"Returns a GeoDataFrame of the preferred locations. Source code in tripsender\\building.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 def return_gdf ( self ): \"\"\"Returns a GeoDataFrame of the preferred locations.\"\"\" # Extracting all locations into a flat list all_locations = [] origin = self . origin for attr , value in self . __dict__ . items (): # Skip origin if attr == \"origin\" : continue if isinstance ( value , list ): all_locations . extend ( value ) elif value is not None : all_locations . append ( value ) # Convert locations to GeoDataFrame gdf = gpd . GeoDataFrame ({ 'LocationType' : [ loc . location_type for loc in all_locations ], 'geometry' : [ loc . location_coordinates for loc in all_locations ] }) # Add origin (Point) to GeoDataFrame gdf . loc [ - 1 ] = [ \"Origin\" , origin ] # Set crs to EPSG:3006 gdf . crs = \"EPSG:3006\" return gdf","title":"return_gdf"},{"location":"house/","text":"House Represents a housing unit occupied by residents in Gothenburg. Each household is assigned a house object that represents the housing unit that the residents occupy. A house is associated with a physical building in Gothenburg. For single-family houses, a single-house object is related to a building; for multi-family houses, multiple house objects are associated with a building. The house object contains Floor area Reference to a building Reference to a household Unique identifier Attributes: Name Type Description uuid UUID Unique identifier for the house. household Household The household occupying the house. building Building The building the house is associated with. building_uuid UUID Unique identifier of the building. area float Floor area of the house. Source code in tripsender\\house.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class House : \"\"\" Represents a housing unit occupied by residents in Gothenburg. Each household is assigned a house object that represents the housing unit that the residents occupy. A house is associated with a physical building in Gothenburg. For single-family houses, a single-house object is related to a building; for multi-family houses, multiple house objects are associated with a building. The house object contains: - Floor area - Reference to a building - Reference to a household - Unique identifier Attributes: uuid (UUID): Unique identifier for the house. household (Household): The household occupying the house. building (Building): The building the house is associated with. building_uuid (UUID): Unique identifier of the building. area (float): Floor area of the house. \"\"\" instances = [] def __init__ ( self , household , building ): \"\"\"Initialize the House with given attributes.\"\"\" self . uuid = uuid . uuid4 () self . household = household self . building = building self . building_uuid = building . uuid # https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ self . area = 36 * len ( household . members ) self . building . houses . append ( self ) self . building . population_total += len ( self . household . members ) self . building . isEmpty = False self . instances . append ( self ) # Add the origin on the building to the individuals in the household for member in self . household . members : member . origin = self . building . coord # For the household used to create the house, set the house attribute to the house household . house = self def __repr__ ( self ): return f \"A house with { len ( self . household . members ) } people.\" @classmethod def clear_instances ( cls ): \"\"\" Clear the instances list. \"\"\" cls . instances = [] @classmethod def return_dataframe ( cls ): \"\"\" Return a dataframe with all the instances. \"\"\" data = [] for instance in cls . instances : data . append ( instance . info ()) return pd . DataFrame ( data ) def info ( self ): \"\"\"Returns a dictionary with information about the house.\"\"\" return { \"House UUID\" : self . uuid , \"Household UUID\" : self . household . uuid , \"Building UUID\" : self . building . uuid , \"Members in house\" : len ( self . household . members ), \"Adults in house\" : len ([ member for member in self . household . members if member . is_child == False ]), \"Children in house\" : len ([ member for member in self . household . members if member . is_child == True ]), \"Cars in the household\" : self . household . cars , \"Area\" : self . area } __init__ ( household , building ) Initialize the House with given attributes. Source code in tripsender\\house.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , household , building ): \"\"\"Initialize the House with given attributes.\"\"\" self . uuid = uuid . uuid4 () self . household = household self . building = building self . building_uuid = building . uuid # https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ self . area = 36 * len ( household . members ) self . building . houses . append ( self ) self . building . population_total += len ( self . household . members ) self . building . isEmpty = False self . instances . append ( self ) # Add the origin on the building to the individuals in the household for member in self . household . members : member . origin = self . building . coord # For the household used to create the house, set the house attribute to the house household . house = self clear_instances () classmethod Clear the instances list. Source code in tripsender\\house.py 74 75 76 77 @classmethod def clear_instances ( cls ): \"\"\" Clear the instances list. \"\"\" cls . instances = [] info () Returns a dictionary with information about the house. Source code in tripsender\\house.py 88 89 90 91 92 93 94 95 96 97 98 99 def info ( self ): \"\"\"Returns a dictionary with information about the house.\"\"\" return { \"House UUID\" : self . uuid , \"Household UUID\" : self . household . uuid , \"Building UUID\" : self . building . uuid , \"Members in house\" : len ( self . household . members ), \"Adults in house\" : len ([ member for member in self . household . members if member . is_child == False ]), \"Children in house\" : len ([ member for member in self . household . members if member . is_child == True ]), \"Cars in the household\" : self . household . cars , \"Area\" : self . area } return_dataframe () classmethod Return a dataframe with all the instances. Source code in tripsender\\house.py 79 80 81 82 83 84 85 86 @classmethod def return_dataframe ( cls ): \"\"\" Return a dataframe with all the instances. \"\"\" data = [] for instance in cls . instances : data . append ( instance . info ()) return pd . DataFrame ( data )","title":"house"},{"location":"house/#tripsender.house.House","text":"Represents a housing unit occupied by residents in Gothenburg. Each household is assigned a house object that represents the housing unit that the residents occupy. A house is associated with a physical building in Gothenburg. For single-family houses, a single-house object is related to a building; for multi-family houses, multiple house objects are associated with a building. The house object contains Floor area Reference to a building Reference to a household Unique identifier Attributes: Name Type Description uuid UUID Unique identifier for the house. household Household The household occupying the house. building Building The building the house is associated with. building_uuid UUID Unique identifier of the building. area float Floor area of the house. Source code in tripsender\\house.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class House : \"\"\" Represents a housing unit occupied by residents in Gothenburg. Each household is assigned a house object that represents the housing unit that the residents occupy. A house is associated with a physical building in Gothenburg. For single-family houses, a single-house object is related to a building; for multi-family houses, multiple house objects are associated with a building. The house object contains: - Floor area - Reference to a building - Reference to a household - Unique identifier Attributes: uuid (UUID): Unique identifier for the house. household (Household): The household occupying the house. building (Building): The building the house is associated with. building_uuid (UUID): Unique identifier of the building. area (float): Floor area of the house. \"\"\" instances = [] def __init__ ( self , household , building ): \"\"\"Initialize the House with given attributes.\"\"\" self . uuid = uuid . uuid4 () self . household = household self . building = building self . building_uuid = building . uuid # https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ self . area = 36 * len ( household . members ) self . building . houses . append ( self ) self . building . population_total += len ( self . household . members ) self . building . isEmpty = False self . instances . append ( self ) # Add the origin on the building to the individuals in the household for member in self . household . members : member . origin = self . building . coord # For the household used to create the house, set the house attribute to the house household . house = self def __repr__ ( self ): return f \"A house with { len ( self . household . members ) } people.\" @classmethod def clear_instances ( cls ): \"\"\" Clear the instances list. \"\"\" cls . instances = [] @classmethod def return_dataframe ( cls ): \"\"\" Return a dataframe with all the instances. \"\"\" data = [] for instance in cls . instances : data . append ( instance . info ()) return pd . DataFrame ( data ) def info ( self ): \"\"\"Returns a dictionary with information about the house.\"\"\" return { \"House UUID\" : self . uuid , \"Household UUID\" : self . household . uuid , \"Building UUID\" : self . building . uuid , \"Members in house\" : len ( self . household . members ), \"Adults in house\" : len ([ member for member in self . household . members if member . is_child == False ]), \"Children in house\" : len ([ member for member in self . household . members if member . is_child == True ]), \"Cars in the household\" : self . household . cars , \"Area\" : self . area }","title":"House"},{"location":"house/#tripsender.house.House.__init__","text":"Initialize the House with given attributes. Source code in tripsender\\house.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , household , building ): \"\"\"Initialize the House with given attributes.\"\"\" self . uuid = uuid . uuid4 () self . household = household self . building = building self . building_uuid = building . uuid # https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ self . area = 36 * len ( household . members ) self . building . houses . append ( self ) self . building . population_total += len ( self . household . members ) self . building . isEmpty = False self . instances . append ( self ) # Add the origin on the building to the individuals in the household for member in self . household . members : member . origin = self . building . coord # For the household used to create the house, set the house attribute to the house household . house = self","title":"__init__"},{"location":"house/#tripsender.house.House.clear_instances","text":"Clear the instances list. Source code in tripsender\\house.py 74 75 76 77 @classmethod def clear_instances ( cls ): \"\"\" Clear the instances list. \"\"\" cls . instances = []","title":"clear_instances"},{"location":"house/#tripsender.house.House.info","text":"Returns a dictionary with information about the house. Source code in tripsender\\house.py 88 89 90 91 92 93 94 95 96 97 98 99 def info ( self ): \"\"\"Returns a dictionary with information about the house.\"\"\" return { \"House UUID\" : self . uuid , \"Household UUID\" : self . household . uuid , \"Building UUID\" : self . building . uuid , \"Members in house\" : len ( self . household . members ), \"Adults in house\" : len ([ member for member in self . household . members if member . is_child == False ]), \"Children in house\" : len ([ member for member in self . household . members if member . is_child == True ]), \"Cars in the household\" : self . household . cars , \"Area\" : self . area }","title":"info"},{"location":"house/#tripsender.house.House.return_dataframe","text":"Return a dataframe with all the instances. Source code in tripsender\\house.py 79 80 81 82 83 84 85 86 @classmethod def return_dataframe ( cls ): \"\"\" Return a dataframe with all the instances. \"\"\" data = [] for instance in cls . instances : data . append ( instance . info ()) return pd . DataFrame ( data )","title":"return_dataframe"},{"location":"household/","text":"Household Represents a household with members, cars, and other properties. A household represents a collection of persons that live together. It comprises: - Household category - House type - List of household members - Unique identifier - Reference to a house object - Preferred destinations for different activities related to the household - Number of cars in the household - Number of children in the household Attributes: Name Type Description uuid UUID Unique identifier for the household. category str Category of the household. children int Number of children in the household. has_children bool Whether the household has children. adults int Number of adults in the household. members List [ Person ] List of members in the household. house_type Optional [ str ] Type of house the household lives in. house Optional [ House ] Reference to the house object associated with the household. cars int Number of cars owned by the household. head_of_household Optional [ Person ] The head of the household. Source code in tripsender\\household.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 class Household : \"\"\" Represents a household with members, cars, and other properties. A household represents a collection of persons that live together. It comprises: - Household category - House type - List of household members - Unique identifier - Reference to a house object - Preferred destinations for different activities related to the household - Number of cars in the household - Number of children in the household Attributes: uuid (UUID): Unique identifier for the household. category (str): Category of the household. children (int): Number of children in the household. has_children (bool): Whether the household has children. adults (int): Number of adults in the household. members (List[Person]): List of members in the household. house_type (Optional[str]): Type of house the household lives in. house (Optional[House]): Reference to the house object associated with the household. cars (int): Number of cars owned by the household. head_of_household (Optional[Person]): The head of the household. \"\"\" instances : List [ 'Household' ] = [] def __init__ ( self , category ): \"\"\"Initialize the Household with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . category : str = category self . children : int = 0 self . has_children : bool = False self . adults : int = 0 self . members : List [ Person ] = [] self . instances . append ( self ) self . house_type : Optional [ str ] = None self . house : Optional [ House ] = None # assuming there's a House class self . cars : int = 0 self . head_of_household : Person = None def __repr__ ( self ): \"\"\"Representation of the Household instance.\"\"\" return f \"A { self . category } household with { len ( self . members ) } members. { self . children } children and { self . adults } adults.\" def add_member ( self , person ): \"\"\"Adds a person to the household.\"\"\" self . members . append ( person ) person . household = self # If person is not child, then increase adult count if not person . is_child : self . adults += 1 # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # If there are no persons in the household, the the first person to be added is the head of the household # As people are added to the household, check the age of the person and if the person is older than the current head of the household, then replace the head of the household with the new person if len ( self . members ) == 1 : self . head_of_household = person person . is_head = True elif person . age > self . head_of_household . age : self . head_of_household . is_head = False self . head_of_household = person person . is_head = True def add_child ( self , person ): \"\"\"Adds a child to the household.\"\"\" # Confirm that the person is a child person . is_child = True self . members . append ( person ) person . household = self self . children += 1 self . has_children = True # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # Set parent uuid person . parent_uuid = self . head_of_household . uuid @classmethod def sync_children_in_households ( cls ): \"\"\"Syncs the number of children in households.\"\"\" for household in cls . instances : household . children = sum ( 1 for member in household . members if member . is_child ) household . has_children = household . children > 0 @classmethod def return_dataframe ( cls ): \"\"\"Returns a dataframe with information about the households.\"\"\" data = [] for household in cls . instances : household_dict = { \"uuid_household\" : household . uuid , \"name_category\" : household . category , \"count_children\" : household . children , \"bool_children\" : household . has_children , \"count_adults\" : household . adults , \"count_members\" : len ( household . members ), \"uuid_members\" : [ member . uuid for member in household . members ], \"type_house\" : household . house_type , \"uuid_house\" : household . house . uuid if household . house else None , \"count_cars\" : household . cars , \"head_of_household\" : household . head_of_household . uuid if household . head_of_household else None } data . append ( household_dict ) return pd . DataFrame ( data ) def info ( self ): \"\"\"Returns a dictionary with information about the household.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Category\" : self . category , \"Number of Members\" : len ( self . members ), \"Members\" : [ member . info () for member in self . members ], \"Children\" : self . children , \"House Type\" : self . house_type , \"Cars\" : self . cars } return info_dict @classmethod def clear_instances ( cls ): cls . instances = [] @classmethod def class_info ( cls ): \"\"\"Print information about the household categories and their compositions.\"\"\" # Get categories categories = [ household . category for household in cls . instances ] unique_categories = set ( categories ) # Count males and females males = sum ( 1 for person in Person . instances if person . sex == MALE ) females = len ( Person . instances ) - males # Count same-sex couples and households with children same_sex_couples = sum ( 1 for household in cls . instances if household . category == COUPLE and household . members [ 0 ] . sex == household . members [ 1 ] . sex ) households_with_children = sum ( 1 for household in cls . instances if household . children ) # Count total children total_children = sum ( 1 for household in cls . instances for person in household . members if person . is_child ) # Count total cars total_cars = sum ( household . cars for household in cls . instances ) # Print the gathered information logger . info ( f 'There are { len ( unique_categories ) } categories in this dataset' ) logger . info ( f 'There are { len ( cls . instances ) } households' ) logger . info ( f 'There are { len ( Person . instances ) } persons' ) logger . info ( f 'The categories are { unique_categories } ' ) for category in unique_categories : logger . info ( f ' There are { categories . count ( category ) } { category } households' ) logger . info ( f 'There are { males } males and { females } females in the population' ) logger . info ( f 'There are { same_sex_couples } same sex couples out of { categories . count ( COUPLE ) } couples' ) logger . info ( f 'There are { households_with_children } households with children out of { len ( cls . instances ) } households' ) logger . info ( f 'There are { total_children } children out of { len ( Person . instances ) } persons' ) logger . info ( f 'There are { total_cars } cars in all households' ) def plot_member_graph ( self ): \"\"\" Plots a relational graph of all members in the household\"\"\" members = self . members adults = [ member for member in members if member . is_child == False ] children = [ member for member in members if member . is_child == True ] G = nx . Graph () # Adding household node with size = number of members and colour = red G . add_node ( self . uuid , type = \"household\" , size = len ( self . members ) * 10 , color = \"#FF6961\" ) # Adding adult nodes with size = age and colour = blue for adult in adults : G . add_node ( adult . uuid , type = \"adult\" , age = adult . age , size = adult . age , color = \"#AEC6CF\" , gender = adult . sex ) # Adding child nodes with size = age and colour = green for child in children : G . add_node ( child . uuid , type = \"child\" , age = child . age , size = child . age , color = \"#77DD77\" , gender = child . sex ) # Adding edges between household and adults for adult in adults : G . add_edge ( self . uuid , adult . uuid ) # Adding edges between adults and children with length = 1 for adult in adults : for child in children : G . add_edge ( adult . uuid , child . uuid , length = 1 ) # Plotting the graph with node size and colour plt . figure ( figsize = ( 10 , 10 )) # Draw a hierarchical tree graph pos = nx . spring_layout ( G ) nx . draw ( G , pos , with_labels = False , node_size = [ v [ 'size' ] * 50 for v in G . nodes . values ()], node_color = [ v [ 'color' ] for v in G . nodes . values ()]) # Add node labels with age and gender attributes node_labels = {} for node in G . nodes : if G . nodes [ node ][ 'type' ] == 'household' : continue age = G . nodes [ node ][ 'age' ] gender = G . nodes [ node ][ 'gender' ] node_labels [ node ] = f \"Age: { age } \\n Gender: { gender } \" nx . draw_networkx_labels ( G , pos , labels = node_labels , font_color = \"black\" , font_size = 8 ) # Add the title and subtitle plt . title ( \"Household Graph\" ) plt . suptitle ( f \"Household Category: { self . category } - Number of Members: { len ( self . members ) } \" , fontsize = 12 ) plt . show () def plot_activities ( self , color_palette = None ): if not any ( member . activity_sequence . activities for member in self . members ): print ( \"No activities to plot\" ) return fig , ax = plt . subplots ( figsize = ( 12 , 6 )) if color_palette : activity_colors = color_palette else : activity_colors = self . _get_activity_colors () y_ticks , y_labels = self . _get_member_info () for y , member in zip ( y_ticks , self . members ): if member . activity_sequence is None : self . _add_activity_rectangles ( ax , 0 , 24 , y , \"#d4d4d4\" , \"Children activities are not included\" ) elif member . activity_sequence . activities : for activity in member . activity_sequence . activities : start_time , end_time = self . _get_activity_times ( activity ) self . _add_activity_rectangles ( ax , start_time , end_time , y , activity_colors [ activity . purpose ]) if activity . mode : self . _add_activity_mode_label ( ax , start_time , end_time , y , activity . mode ) self . _set_plot_settings ( ax , y_ticks , y_labels , activity_colors ) plt . tight_layout () plt . show () def _get_activity_colors ( self ): return { \"Transit\" : \"#9e0142\" , \"Travel\" : \"#d53e4f\" , 'Grocery' : \"#f46d43\" , \"Shopping\" : \"#fdae61\" , \"Leisure\" : \"#fee08b\" , \"Home\" : \"#ffffbf\" , \"Work\" : \"#e6f598\" , \"Education\" : \"#abdda4\" , 'Healthcare' : \"#66c2a5\" , 'Pickup/Dropoff child' : \"#3288bd\" , \"Other\" : \"#5e4fa2\" , # Add other activity types here } def _get_member_info ( self ): y_ticks = range ( 1 , len ( self . members ) + 1 ) y_labels = [ member . __str__ () for member in self . members ] return y_ticks , y_labels def _get_activity_times ( self , activity ): if activity . start_time == time ( 3 , 0 ) and activity . end_time == time ( 3 , 0 ): return 0 , 24 return activity . start_time . hour + activity . start_time . minute / 60 , activity . end_time . hour + activity . end_time . minute / 60 #self._add_activity_rectangles(ax, 0, 24, y, \"#d4d4d4\",\"Children activities are not included\") def _add_activity_rectangles ( self , ax , start_time , end_time , y , color , text = None ): if end_time < start_time : rects = [ patches . Rectangle (( start_time , y - 0.3 ), 24 - start_time , 0.6 , facecolor = color , edgecolor = color ), patches . Rectangle (( 0 , y - 0.3 ), end_time , 0.6 , facecolor = color , edgecolor = color )] else : rects = [ patches . Rectangle (( start_time , y - 0.3 ), end_time - start_time , 0.6 , facecolor = color , edgecolor = color )] for rect in rects : ax . add_patch ( rect ) if text : ax . text ( 12 , y , text , ha = 'center' , va = 'center' , fontsize = 8 , color = 'black' , rotation = 0 ) def _add_activity_mode_label ( self , ax , start_time , end_time , y , mode ): ax . text (( start_time + end_time ) / 2 , y , mode , ha = 'center' , va = 'center' , fontsize = 8 , color = 'white' , rotation = 90 ) def _set_plot_settings ( self , ax , y_ticks , y_labels , activity_colors ): ax . set_yticks ( y_ticks ) ax . set_yticklabels ( y_labels , fontsize = 8 ) ax . set_ylim ( 0.5 , len ( y_labels ) + 0.5 ) ax . set_xlim ( 0 , 24 ) ax . set_xticks ( range ( 0 , 25 , 1 )) ax . set_xlabel ( \"Time of Day\" , fontsize = 8 ) ax . set_ylabel ( \"Household Members\" , fontsize = 8 ) ax . set_title ( \"Household Activities Timeline\" , fontsize = 10 ) ax . grid ( True , which = 'both' , axis = 'x' , linestyle = '--' , linewidth = 0.5 , color = '#d4d4d4' ) handles = [ patches . Patch ( color = color , label = purpose ) for purpose , color in activity_colors . items ()] ax . legend ( handles = handles , loc = 'upper center' , bbox_to_anchor = ( 0.5 , - 0.15 ), ncol = 6 , fontsize = 8 ) for spine in ax . spines . values (): spine . set_visible ( False ) @classmethod def plot_cars ( cls ): # Plot distribution of cars in the neighborhood cars = {} for household in cls . instances : if household . cars in cars : cars [ household . cars ] += 1 else : cars [ household . cars ] = 1 # Display the bar chart plt . bar ( cars . keys (), cars . values ()) plt . xticks ( rotation = 90 ) plt . title ( 'Number of cars per household (After scaling)' ) plt . xlabel ( 'Number of cars' ) plt . ylabel ( 'Count' ) plt . show () for k , v in cars . items (): print ( f \"Households with { k } cars: { v } \" ) @classmethod def return_nhts ( cls , onehotencode = False , drop = [ 'primary_status' ]): \"\"\" Returns a dataframe with information about the households and persons in a common NHTS format. \"\"\" # Helper function to determine age group def _determine_age_group ( age ): if age < 25 : return '16-24' elif age < 35 : return '25-34' elif age < 45 : return '35-44' elif age < 55 : return '45-54' elif age < 65 : return '55-64' elif age < 75 : return '65-74' else : return '75+' list_of_dicts = [] adults = [] for household in cls . instances : for person in household . members : if person . age > 18 : adults . append ( person ) age_group = _determine_age_group ( person . age ) person_dict = { 'sex' : person . sex , 'age_group' : age_group , 'house_type' : person . household . house_type , 'child_count' : person . household . children , 'adult_count' : len ( person . household . members ) - person . household . children , 'household_type' : person . household . category , 'car_count' : person . household . cars , 'primary_status' : person . primary_status , } list_of_dicts . append ( person_dict ) df = pd . DataFrame ( list_of_dicts ) # If drop, then drop the columns in the list if drop : df = df . drop ( drop , axis = 1 ) if onehotencode : ohe = OneHotEncoder ( sparse = False ) # Initialize the encoder categorical_variables = [ 'sex' , 'age_group' , 'house_type' , 'household_type' ] df_ohe = pd . DataFrame ( ohe . fit_transform ( df [ categorical_variables ])) df_ohe . columns = ohe . get_feature_names () df = df . drop ( categorical_variables , axis = 1 ) . reset_index ( drop = True ) df = pd . concat ([ df , df_ohe ], axis = 1 ) return df , adults @classmethod def plot_children_in_households ( cls , year , area ): # Creating a dictionary for each category household_categories = { 'Single_no_children' : [], 'Single_children_0_24' : [], 'Single_children_25' : [], 'Couple_no_children' : [], 'Couple_children_0_24' : [], 'Couple_children_25' : [], 'Other_no_children' : [], 'Other_children_0_24' : [], 'Other_children_25' : [] } household_instances = cls . instances # A household can be in only one category from the list above # Looping through all households for household in household_instances : if household . children == 0 : category = f ' { household . category } _no_children' # If the household has children, then check the age of the children, if any of the children are below 25, # then the household is categorised as children_0_24, otherwise it is categorised as children_25 elif any ( person . age < 25 for person in household . members if person . is_child ): category = f ' { household . category } _children_0_24' else : category = f ' { household . category } _children_25' household_categories [ category ] . append ( household ) # Creating a list of counts and labels counts = [] labels = [] for key , value in household_categories . items (): labels . append ( key . replace ( \"_\" , \" \" )) counts . append ( len ( value )) print ( 'Number of households: ' , sum ( counts )) # show data value on the plot for i in range ( len ( counts )): plt . text ( x = i , y = counts [ i ], s = counts [ i ], ha = 'center' , va = 'bottom' ) # Plotting the counts plt . bar ( labels , counts ) plt . xticks ( rotation = 90 ) plt . title ( 'Household categories' ) plt . xlabel ( 'Household category' ) plt . ylabel ( 'Count' ) d = fetcher . fetch_older_children_data ( year , area ) scb_data = [ int ( value [ 'values' ][ 0 ]) for value in d [ 'data' ]] plt . plot ( labels , scb_data , color = 'red' , marker = 'o' ) plt . legend ([ 'SCB data' , 'Our data' ]) # Calculate the error error = [ counts [ i ] - scb_data [ i ] for i in range ( len ( counts ))] # Plot the error plt . figure () plt . bar ( labels , error ) plt . xticks ( rotation = 90 ) plt . title ( 'Incorrectly categorised persons' ) plt . xlabel ( 'Household category' ) plt . ylabel ( 'Error' ) plt . show () def update_has_child ( self ): \"\"\" Set the has_child attribute for adults in the household based on the number of children in the household\"\"\" if self . children > 0 : self . has_child = True else : self . has_child = False for member in self . members : if member . is_child == False : member . has_child = self . has_child __init__ ( category ) Initialize the Household with given attributes. Source code in tripsender\\household.py 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , category ): \"\"\"Initialize the Household with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . category : str = category self . children : int = 0 self . has_children : bool = False self . adults : int = 0 self . members : List [ Person ] = [] self . instances . append ( self ) self . house_type : Optional [ str ] = None self . house : Optional [ House ] = None # assuming there's a House class self . cars : int = 0 self . head_of_household : Person = None __repr__ () Representation of the Household instance. Source code in tripsender\\household.py 84 85 86 def __repr__ ( self ): \"\"\"Representation of the Household instance.\"\"\" return f \"A { self . category } household with { len ( self . members ) } members. { self . children } children and { self . adults } adults.\" add_child ( person ) Adds a child to the household. Source code in tripsender\\household.py 107 108 109 110 111 112 113 114 115 116 117 118 def add_child ( self , person ): \"\"\"Adds a child to the household.\"\"\" # Confirm that the person is a child person . is_child = True self . members . append ( person ) person . household = self self . children += 1 self . has_children = True # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # Set parent uuid person . parent_uuid = self . head_of_household . uuid add_member ( person ) Adds a person to the household. Source code in tripsender\\household.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def add_member ( self , person ): \"\"\"Adds a person to the household.\"\"\" self . members . append ( person ) person . household = self # If person is not child, then increase adult count if not person . is_child : self . adults += 1 # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # If there are no persons in the household, the the first person to be added is the head of the household # As people are added to the household, check the age of the person and if the person is older than the current head of the household, then replace the head of the household with the new person if len ( self . members ) == 1 : self . head_of_household = person person . is_head = True elif person . age > self . head_of_household . age : self . head_of_household . is_head = False self . head_of_household = person person . is_head = True class_info () classmethod Print information about the household categories and their compositions. Source code in tripsender\\household.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 @classmethod def class_info ( cls ): \"\"\"Print information about the household categories and their compositions.\"\"\" # Get categories categories = [ household . category for household in cls . instances ] unique_categories = set ( categories ) # Count males and females males = sum ( 1 for person in Person . instances if person . sex == MALE ) females = len ( Person . instances ) - males # Count same-sex couples and households with children same_sex_couples = sum ( 1 for household in cls . instances if household . category == COUPLE and household . members [ 0 ] . sex == household . members [ 1 ] . sex ) households_with_children = sum ( 1 for household in cls . instances if household . children ) # Count total children total_children = sum ( 1 for household in cls . instances for person in household . members if person . is_child ) # Count total cars total_cars = sum ( household . cars for household in cls . instances ) # Print the gathered information logger . info ( f 'There are { len ( unique_categories ) } categories in this dataset' ) logger . info ( f 'There are { len ( cls . instances ) } households' ) logger . info ( f 'There are { len ( Person . instances ) } persons' ) logger . info ( f 'The categories are { unique_categories } ' ) for category in unique_categories : logger . info ( f ' There are { categories . count ( category ) } { category } households' ) logger . info ( f 'There are { males } males and { females } females in the population' ) logger . info ( f 'There are { same_sex_couples } same sex couples out of { categories . count ( COUPLE ) } couples' ) logger . info ( f 'There are { households_with_children } households with children out of { len ( cls . instances ) } households' ) logger . info ( f 'There are { total_children } children out of { len ( Person . instances ) } persons' ) logger . info ( f 'There are { total_cars } cars in all households' ) info () Returns a dictionary with information about the household. Source code in tripsender\\household.py 150 151 152 153 154 155 156 157 158 159 160 161 162 def info ( self ): \"\"\"Returns a dictionary with information about the household.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Category\" : self . category , \"Number of Members\" : len ( self . members ), \"Members\" : [ member . info () for member in self . members ], \"Children\" : self . children , \"House Type\" : self . house_type , \"Cars\" : self . cars } return info_dict plot_member_graph () Plots a relational graph of all members in the household Source code in tripsender\\household.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 def plot_member_graph ( self ): \"\"\" Plots a relational graph of all members in the household\"\"\" members = self . members adults = [ member for member in members if member . is_child == False ] children = [ member for member in members if member . is_child == True ] G = nx . Graph () # Adding household node with size = number of members and colour = red G . add_node ( self . uuid , type = \"household\" , size = len ( self . members ) * 10 , color = \"#FF6961\" ) # Adding adult nodes with size = age and colour = blue for adult in adults : G . add_node ( adult . uuid , type = \"adult\" , age = adult . age , size = adult . age , color = \"#AEC6CF\" , gender = adult . sex ) # Adding child nodes with size = age and colour = green for child in children : G . add_node ( child . uuid , type = \"child\" , age = child . age , size = child . age , color = \"#77DD77\" , gender = child . sex ) # Adding edges between household and adults for adult in adults : G . add_edge ( self . uuid , adult . uuid ) # Adding edges between adults and children with length = 1 for adult in adults : for child in children : G . add_edge ( adult . uuid , child . uuid , length = 1 ) # Plotting the graph with node size and colour plt . figure ( figsize = ( 10 , 10 )) # Draw a hierarchical tree graph pos = nx . spring_layout ( G ) nx . draw ( G , pos , with_labels = False , node_size = [ v [ 'size' ] * 50 for v in G . nodes . values ()], node_color = [ v [ 'color' ] for v in G . nodes . values ()]) # Add node labels with age and gender attributes node_labels = {} for node in G . nodes : if G . nodes [ node ][ 'type' ] == 'household' : continue age = G . nodes [ node ][ 'age' ] gender = G . nodes [ node ][ 'gender' ] node_labels [ node ] = f \"Age: { age } \\n Gender: { gender } \" nx . draw_networkx_labels ( G , pos , labels = node_labels , font_color = \"black\" , font_size = 8 ) # Add the title and subtitle plt . title ( \"Household Graph\" ) plt . suptitle ( f \"Household Category: { self . category } - Number of Members: { len ( self . members ) } \" , fontsize = 12 ) plt . show () return_dataframe () classmethod Returns a dataframe with information about the households. Source code in tripsender\\household.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @classmethod def return_dataframe ( cls ): \"\"\"Returns a dataframe with information about the households.\"\"\" data = [] for household in cls . instances : household_dict = { \"uuid_household\" : household . uuid , \"name_category\" : household . category , \"count_children\" : household . children , \"bool_children\" : household . has_children , \"count_adults\" : household . adults , \"count_members\" : len ( household . members ), \"uuid_members\" : [ member . uuid for member in household . members ], \"type_house\" : household . house_type , \"uuid_house\" : household . house . uuid if household . house else None , \"count_cars\" : household . cars , \"head_of_household\" : household . head_of_household . uuid if household . head_of_household else None } data . append ( household_dict ) return pd . DataFrame ( data ) return_nhts ( onehotencode = False , drop = [ 'primary_status' ]) classmethod Returns a dataframe with information about the households and persons in a common NHTS format. Source code in tripsender\\household.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 @classmethod def return_nhts ( cls , onehotencode = False , drop = [ 'primary_status' ]): \"\"\" Returns a dataframe with information about the households and persons in a common NHTS format. \"\"\" # Helper function to determine age group def _determine_age_group ( age ): if age < 25 : return '16-24' elif age < 35 : return '25-34' elif age < 45 : return '35-44' elif age < 55 : return '45-54' elif age < 65 : return '55-64' elif age < 75 : return '65-74' else : return '75+' list_of_dicts = [] adults = [] for household in cls . instances : for person in household . members : if person . age > 18 : adults . append ( person ) age_group = _determine_age_group ( person . age ) person_dict = { 'sex' : person . sex , 'age_group' : age_group , 'house_type' : person . household . house_type , 'child_count' : person . household . children , 'adult_count' : len ( person . household . members ) - person . household . children , 'household_type' : person . household . category , 'car_count' : person . household . cars , 'primary_status' : person . primary_status , } list_of_dicts . append ( person_dict ) df = pd . DataFrame ( list_of_dicts ) # If drop, then drop the columns in the list if drop : df = df . drop ( drop , axis = 1 ) if onehotencode : ohe = OneHotEncoder ( sparse = False ) # Initialize the encoder categorical_variables = [ 'sex' , 'age_group' , 'house_type' , 'household_type' ] df_ohe = pd . DataFrame ( ohe . fit_transform ( df [ categorical_variables ])) df_ohe . columns = ohe . get_feature_names () df = df . drop ( categorical_variables , axis = 1 ) . reset_index ( drop = True ) df = pd . concat ([ df , df_ohe ], axis = 1 ) return df , adults sync_children_in_households () classmethod Syncs the number of children in households. Source code in tripsender\\household.py 121 122 123 124 125 126 @classmethod def sync_children_in_households ( cls ): \"\"\"Syncs the number of children in households.\"\"\" for household in cls . instances : household . children = sum ( 1 for member in household . members if member . is_child ) household . has_children = household . children > 0 update_has_child () Set the has_child attribute for adults in the household based on the number of children in the household Source code in tripsender\\household.py 499 500 501 502 503 504 505 506 507 def update_has_child ( self ): \"\"\" Set the has_child attribute for adults in the household based on the number of children in the household\"\"\" if self . children > 0 : self . has_child = True else : self . has_child = False for member in self . members : if member . is_child == False : member . has_child = self . has_child","title":"household"},{"location":"household/#tripsender.household.Household","text":"Represents a household with members, cars, and other properties. A household represents a collection of persons that live together. It comprises: - Household category - House type - List of household members - Unique identifier - Reference to a house object - Preferred destinations for different activities related to the household - Number of cars in the household - Number of children in the household Attributes: Name Type Description uuid UUID Unique identifier for the household. category str Category of the household. children int Number of children in the household. has_children bool Whether the household has children. adults int Number of adults in the household. members List [ Person ] List of members in the household. house_type Optional [ str ] Type of house the household lives in. house Optional [ House ] Reference to the house object associated with the household. cars int Number of cars owned by the household. head_of_household Optional [ Person ] The head of the household. Source code in tripsender\\household.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 class Household : \"\"\" Represents a household with members, cars, and other properties. A household represents a collection of persons that live together. It comprises: - Household category - House type - List of household members - Unique identifier - Reference to a house object - Preferred destinations for different activities related to the household - Number of cars in the household - Number of children in the household Attributes: uuid (UUID): Unique identifier for the household. category (str): Category of the household. children (int): Number of children in the household. has_children (bool): Whether the household has children. adults (int): Number of adults in the household. members (List[Person]): List of members in the household. house_type (Optional[str]): Type of house the household lives in. house (Optional[House]): Reference to the house object associated with the household. cars (int): Number of cars owned by the household. head_of_household (Optional[Person]): The head of the household. \"\"\" instances : List [ 'Household' ] = [] def __init__ ( self , category ): \"\"\"Initialize the Household with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . category : str = category self . children : int = 0 self . has_children : bool = False self . adults : int = 0 self . members : List [ Person ] = [] self . instances . append ( self ) self . house_type : Optional [ str ] = None self . house : Optional [ House ] = None # assuming there's a House class self . cars : int = 0 self . head_of_household : Person = None def __repr__ ( self ): \"\"\"Representation of the Household instance.\"\"\" return f \"A { self . category } household with { len ( self . members ) } members. { self . children } children and { self . adults } adults.\" def add_member ( self , person ): \"\"\"Adds a person to the household.\"\"\" self . members . append ( person ) person . household = self # If person is not child, then increase adult count if not person . is_child : self . adults += 1 # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # If there are no persons in the household, the the first person to be added is the head of the household # As people are added to the household, check the age of the person and if the person is older than the current head of the household, then replace the head of the household with the new person if len ( self . members ) == 1 : self . head_of_household = person person . is_head = True elif person . age > self . head_of_household . age : self . head_of_household . is_head = False self . head_of_household = person person . is_head = True def add_child ( self , person ): \"\"\"Adds a child to the household.\"\"\" # Confirm that the person is a child person . is_child = True self . members . append ( person ) person . household = self self . children += 1 self . has_children = True # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # Set parent uuid person . parent_uuid = self . head_of_household . uuid @classmethod def sync_children_in_households ( cls ): \"\"\"Syncs the number of children in households.\"\"\" for household in cls . instances : household . children = sum ( 1 for member in household . members if member . is_child ) household . has_children = household . children > 0 @classmethod def return_dataframe ( cls ): \"\"\"Returns a dataframe with information about the households.\"\"\" data = [] for household in cls . instances : household_dict = { \"uuid_household\" : household . uuid , \"name_category\" : household . category , \"count_children\" : household . children , \"bool_children\" : household . has_children , \"count_adults\" : household . adults , \"count_members\" : len ( household . members ), \"uuid_members\" : [ member . uuid for member in household . members ], \"type_house\" : household . house_type , \"uuid_house\" : household . house . uuid if household . house else None , \"count_cars\" : household . cars , \"head_of_household\" : household . head_of_household . uuid if household . head_of_household else None } data . append ( household_dict ) return pd . DataFrame ( data ) def info ( self ): \"\"\"Returns a dictionary with information about the household.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Category\" : self . category , \"Number of Members\" : len ( self . members ), \"Members\" : [ member . info () for member in self . members ], \"Children\" : self . children , \"House Type\" : self . house_type , \"Cars\" : self . cars } return info_dict @classmethod def clear_instances ( cls ): cls . instances = [] @classmethod def class_info ( cls ): \"\"\"Print information about the household categories and their compositions.\"\"\" # Get categories categories = [ household . category for household in cls . instances ] unique_categories = set ( categories ) # Count males and females males = sum ( 1 for person in Person . instances if person . sex == MALE ) females = len ( Person . instances ) - males # Count same-sex couples and households with children same_sex_couples = sum ( 1 for household in cls . instances if household . category == COUPLE and household . members [ 0 ] . sex == household . members [ 1 ] . sex ) households_with_children = sum ( 1 for household in cls . instances if household . children ) # Count total children total_children = sum ( 1 for household in cls . instances for person in household . members if person . is_child ) # Count total cars total_cars = sum ( household . cars for household in cls . instances ) # Print the gathered information logger . info ( f 'There are { len ( unique_categories ) } categories in this dataset' ) logger . info ( f 'There are { len ( cls . instances ) } households' ) logger . info ( f 'There are { len ( Person . instances ) } persons' ) logger . info ( f 'The categories are { unique_categories } ' ) for category in unique_categories : logger . info ( f ' There are { categories . count ( category ) } { category } households' ) logger . info ( f 'There are { males } males and { females } females in the population' ) logger . info ( f 'There are { same_sex_couples } same sex couples out of { categories . count ( COUPLE ) } couples' ) logger . info ( f 'There are { households_with_children } households with children out of { len ( cls . instances ) } households' ) logger . info ( f 'There are { total_children } children out of { len ( Person . instances ) } persons' ) logger . info ( f 'There are { total_cars } cars in all households' ) def plot_member_graph ( self ): \"\"\" Plots a relational graph of all members in the household\"\"\" members = self . members adults = [ member for member in members if member . is_child == False ] children = [ member for member in members if member . is_child == True ] G = nx . Graph () # Adding household node with size = number of members and colour = red G . add_node ( self . uuid , type = \"household\" , size = len ( self . members ) * 10 , color = \"#FF6961\" ) # Adding adult nodes with size = age and colour = blue for adult in adults : G . add_node ( adult . uuid , type = \"adult\" , age = adult . age , size = adult . age , color = \"#AEC6CF\" , gender = adult . sex ) # Adding child nodes with size = age and colour = green for child in children : G . add_node ( child . uuid , type = \"child\" , age = child . age , size = child . age , color = \"#77DD77\" , gender = child . sex ) # Adding edges between household and adults for adult in adults : G . add_edge ( self . uuid , adult . uuid ) # Adding edges between adults and children with length = 1 for adult in adults : for child in children : G . add_edge ( adult . uuid , child . uuid , length = 1 ) # Plotting the graph with node size and colour plt . figure ( figsize = ( 10 , 10 )) # Draw a hierarchical tree graph pos = nx . spring_layout ( G ) nx . draw ( G , pos , with_labels = False , node_size = [ v [ 'size' ] * 50 for v in G . nodes . values ()], node_color = [ v [ 'color' ] for v in G . nodes . values ()]) # Add node labels with age and gender attributes node_labels = {} for node in G . nodes : if G . nodes [ node ][ 'type' ] == 'household' : continue age = G . nodes [ node ][ 'age' ] gender = G . nodes [ node ][ 'gender' ] node_labels [ node ] = f \"Age: { age } \\n Gender: { gender } \" nx . draw_networkx_labels ( G , pos , labels = node_labels , font_color = \"black\" , font_size = 8 ) # Add the title and subtitle plt . title ( \"Household Graph\" ) plt . suptitle ( f \"Household Category: { self . category } - Number of Members: { len ( self . members ) } \" , fontsize = 12 ) plt . show () def plot_activities ( self , color_palette = None ): if not any ( member . activity_sequence . activities for member in self . members ): print ( \"No activities to plot\" ) return fig , ax = plt . subplots ( figsize = ( 12 , 6 )) if color_palette : activity_colors = color_palette else : activity_colors = self . _get_activity_colors () y_ticks , y_labels = self . _get_member_info () for y , member in zip ( y_ticks , self . members ): if member . activity_sequence is None : self . _add_activity_rectangles ( ax , 0 , 24 , y , \"#d4d4d4\" , \"Children activities are not included\" ) elif member . activity_sequence . activities : for activity in member . activity_sequence . activities : start_time , end_time = self . _get_activity_times ( activity ) self . _add_activity_rectangles ( ax , start_time , end_time , y , activity_colors [ activity . purpose ]) if activity . mode : self . _add_activity_mode_label ( ax , start_time , end_time , y , activity . mode ) self . _set_plot_settings ( ax , y_ticks , y_labels , activity_colors ) plt . tight_layout () plt . show () def _get_activity_colors ( self ): return { \"Transit\" : \"#9e0142\" , \"Travel\" : \"#d53e4f\" , 'Grocery' : \"#f46d43\" , \"Shopping\" : \"#fdae61\" , \"Leisure\" : \"#fee08b\" , \"Home\" : \"#ffffbf\" , \"Work\" : \"#e6f598\" , \"Education\" : \"#abdda4\" , 'Healthcare' : \"#66c2a5\" , 'Pickup/Dropoff child' : \"#3288bd\" , \"Other\" : \"#5e4fa2\" , # Add other activity types here } def _get_member_info ( self ): y_ticks = range ( 1 , len ( self . members ) + 1 ) y_labels = [ member . __str__ () for member in self . members ] return y_ticks , y_labels def _get_activity_times ( self , activity ): if activity . start_time == time ( 3 , 0 ) and activity . end_time == time ( 3 , 0 ): return 0 , 24 return activity . start_time . hour + activity . start_time . minute / 60 , activity . end_time . hour + activity . end_time . minute / 60 #self._add_activity_rectangles(ax, 0, 24, y, \"#d4d4d4\",\"Children activities are not included\") def _add_activity_rectangles ( self , ax , start_time , end_time , y , color , text = None ): if end_time < start_time : rects = [ patches . Rectangle (( start_time , y - 0.3 ), 24 - start_time , 0.6 , facecolor = color , edgecolor = color ), patches . Rectangle (( 0 , y - 0.3 ), end_time , 0.6 , facecolor = color , edgecolor = color )] else : rects = [ patches . Rectangle (( start_time , y - 0.3 ), end_time - start_time , 0.6 , facecolor = color , edgecolor = color )] for rect in rects : ax . add_patch ( rect ) if text : ax . text ( 12 , y , text , ha = 'center' , va = 'center' , fontsize = 8 , color = 'black' , rotation = 0 ) def _add_activity_mode_label ( self , ax , start_time , end_time , y , mode ): ax . text (( start_time + end_time ) / 2 , y , mode , ha = 'center' , va = 'center' , fontsize = 8 , color = 'white' , rotation = 90 ) def _set_plot_settings ( self , ax , y_ticks , y_labels , activity_colors ): ax . set_yticks ( y_ticks ) ax . set_yticklabels ( y_labels , fontsize = 8 ) ax . set_ylim ( 0.5 , len ( y_labels ) + 0.5 ) ax . set_xlim ( 0 , 24 ) ax . set_xticks ( range ( 0 , 25 , 1 )) ax . set_xlabel ( \"Time of Day\" , fontsize = 8 ) ax . set_ylabel ( \"Household Members\" , fontsize = 8 ) ax . set_title ( \"Household Activities Timeline\" , fontsize = 10 ) ax . grid ( True , which = 'both' , axis = 'x' , linestyle = '--' , linewidth = 0.5 , color = '#d4d4d4' ) handles = [ patches . Patch ( color = color , label = purpose ) for purpose , color in activity_colors . items ()] ax . legend ( handles = handles , loc = 'upper center' , bbox_to_anchor = ( 0.5 , - 0.15 ), ncol = 6 , fontsize = 8 ) for spine in ax . spines . values (): spine . set_visible ( False ) @classmethod def plot_cars ( cls ): # Plot distribution of cars in the neighborhood cars = {} for household in cls . instances : if household . cars in cars : cars [ household . cars ] += 1 else : cars [ household . cars ] = 1 # Display the bar chart plt . bar ( cars . keys (), cars . values ()) plt . xticks ( rotation = 90 ) plt . title ( 'Number of cars per household (After scaling)' ) plt . xlabel ( 'Number of cars' ) plt . ylabel ( 'Count' ) plt . show () for k , v in cars . items (): print ( f \"Households with { k } cars: { v } \" ) @classmethod def return_nhts ( cls , onehotencode = False , drop = [ 'primary_status' ]): \"\"\" Returns a dataframe with information about the households and persons in a common NHTS format. \"\"\" # Helper function to determine age group def _determine_age_group ( age ): if age < 25 : return '16-24' elif age < 35 : return '25-34' elif age < 45 : return '35-44' elif age < 55 : return '45-54' elif age < 65 : return '55-64' elif age < 75 : return '65-74' else : return '75+' list_of_dicts = [] adults = [] for household in cls . instances : for person in household . members : if person . age > 18 : adults . append ( person ) age_group = _determine_age_group ( person . age ) person_dict = { 'sex' : person . sex , 'age_group' : age_group , 'house_type' : person . household . house_type , 'child_count' : person . household . children , 'adult_count' : len ( person . household . members ) - person . household . children , 'household_type' : person . household . category , 'car_count' : person . household . cars , 'primary_status' : person . primary_status , } list_of_dicts . append ( person_dict ) df = pd . DataFrame ( list_of_dicts ) # If drop, then drop the columns in the list if drop : df = df . drop ( drop , axis = 1 ) if onehotencode : ohe = OneHotEncoder ( sparse = False ) # Initialize the encoder categorical_variables = [ 'sex' , 'age_group' , 'house_type' , 'household_type' ] df_ohe = pd . DataFrame ( ohe . fit_transform ( df [ categorical_variables ])) df_ohe . columns = ohe . get_feature_names () df = df . drop ( categorical_variables , axis = 1 ) . reset_index ( drop = True ) df = pd . concat ([ df , df_ohe ], axis = 1 ) return df , adults @classmethod def plot_children_in_households ( cls , year , area ): # Creating a dictionary for each category household_categories = { 'Single_no_children' : [], 'Single_children_0_24' : [], 'Single_children_25' : [], 'Couple_no_children' : [], 'Couple_children_0_24' : [], 'Couple_children_25' : [], 'Other_no_children' : [], 'Other_children_0_24' : [], 'Other_children_25' : [] } household_instances = cls . instances # A household can be in only one category from the list above # Looping through all households for household in household_instances : if household . children == 0 : category = f ' { household . category } _no_children' # If the household has children, then check the age of the children, if any of the children are below 25, # then the household is categorised as children_0_24, otherwise it is categorised as children_25 elif any ( person . age < 25 for person in household . members if person . is_child ): category = f ' { household . category } _children_0_24' else : category = f ' { household . category } _children_25' household_categories [ category ] . append ( household ) # Creating a list of counts and labels counts = [] labels = [] for key , value in household_categories . items (): labels . append ( key . replace ( \"_\" , \" \" )) counts . append ( len ( value )) print ( 'Number of households: ' , sum ( counts )) # show data value on the plot for i in range ( len ( counts )): plt . text ( x = i , y = counts [ i ], s = counts [ i ], ha = 'center' , va = 'bottom' ) # Plotting the counts plt . bar ( labels , counts ) plt . xticks ( rotation = 90 ) plt . title ( 'Household categories' ) plt . xlabel ( 'Household category' ) plt . ylabel ( 'Count' ) d = fetcher . fetch_older_children_data ( year , area ) scb_data = [ int ( value [ 'values' ][ 0 ]) for value in d [ 'data' ]] plt . plot ( labels , scb_data , color = 'red' , marker = 'o' ) plt . legend ([ 'SCB data' , 'Our data' ]) # Calculate the error error = [ counts [ i ] - scb_data [ i ] for i in range ( len ( counts ))] # Plot the error plt . figure () plt . bar ( labels , error ) plt . xticks ( rotation = 90 ) plt . title ( 'Incorrectly categorised persons' ) plt . xlabel ( 'Household category' ) plt . ylabel ( 'Error' ) plt . show () def update_has_child ( self ): \"\"\" Set the has_child attribute for adults in the household based on the number of children in the household\"\"\" if self . children > 0 : self . has_child = True else : self . has_child = False for member in self . members : if member . is_child == False : member . has_child = self . has_child","title":"Household"},{"location":"household/#tripsender.household.Household.__init__","text":"Initialize the Household with given attributes. Source code in tripsender\\household.py 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , category ): \"\"\"Initialize the Household with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . category : str = category self . children : int = 0 self . has_children : bool = False self . adults : int = 0 self . members : List [ Person ] = [] self . instances . append ( self ) self . house_type : Optional [ str ] = None self . house : Optional [ House ] = None # assuming there's a House class self . cars : int = 0 self . head_of_household : Person = None","title":"__init__"},{"location":"household/#tripsender.household.Household.__repr__","text":"Representation of the Household instance. Source code in tripsender\\household.py 84 85 86 def __repr__ ( self ): \"\"\"Representation of the Household instance.\"\"\" return f \"A { self . category } household with { len ( self . members ) } members. { self . children } children and { self . adults } adults.\"","title":"__repr__"},{"location":"household/#tripsender.household.Household.add_child","text":"Adds a child to the household. Source code in tripsender\\household.py 107 108 109 110 111 112 113 114 115 116 117 118 def add_child ( self , person ): \"\"\"Adds a child to the household.\"\"\" # Confirm that the person is a child person . is_child = True self . members . append ( person ) person . household = self self . children += 1 self . has_children = True # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # Set parent uuid person . parent_uuid = self . head_of_household . uuid","title":"add_child"},{"location":"household/#tripsender.household.Household.add_member","text":"Adds a person to the household. Source code in tripsender\\household.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def add_member ( self , person ): \"\"\"Adds a person to the household.\"\"\" self . members . append ( person ) person . household = self # If person is not child, then increase adult count if not person . is_child : self . adults += 1 # Set the household UUID to person.household_uuid person . household_uuid = self . uuid # If there are no persons in the household, the the first person to be added is the head of the household # As people are added to the household, check the age of the person and if the person is older than the current head of the household, then replace the head of the household with the new person if len ( self . members ) == 1 : self . head_of_household = person person . is_head = True elif person . age > self . head_of_household . age : self . head_of_household . is_head = False self . head_of_household = person person . is_head = True","title":"add_member"},{"location":"household/#tripsender.household.Household.class_info","text":"Print information about the household categories and their compositions. Source code in tripsender\\household.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 @classmethod def class_info ( cls ): \"\"\"Print information about the household categories and their compositions.\"\"\" # Get categories categories = [ household . category for household in cls . instances ] unique_categories = set ( categories ) # Count males and females males = sum ( 1 for person in Person . instances if person . sex == MALE ) females = len ( Person . instances ) - males # Count same-sex couples and households with children same_sex_couples = sum ( 1 for household in cls . instances if household . category == COUPLE and household . members [ 0 ] . sex == household . members [ 1 ] . sex ) households_with_children = sum ( 1 for household in cls . instances if household . children ) # Count total children total_children = sum ( 1 for household in cls . instances for person in household . members if person . is_child ) # Count total cars total_cars = sum ( household . cars for household in cls . instances ) # Print the gathered information logger . info ( f 'There are { len ( unique_categories ) } categories in this dataset' ) logger . info ( f 'There are { len ( cls . instances ) } households' ) logger . info ( f 'There are { len ( Person . instances ) } persons' ) logger . info ( f 'The categories are { unique_categories } ' ) for category in unique_categories : logger . info ( f ' There are { categories . count ( category ) } { category } households' ) logger . info ( f 'There are { males } males and { females } females in the population' ) logger . info ( f 'There are { same_sex_couples } same sex couples out of { categories . count ( COUPLE ) } couples' ) logger . info ( f 'There are { households_with_children } households with children out of { len ( cls . instances ) } households' ) logger . info ( f 'There are { total_children } children out of { len ( Person . instances ) } persons' ) logger . info ( f 'There are { total_cars } cars in all households' )","title":"class_info"},{"location":"household/#tripsender.household.Household.info","text":"Returns a dictionary with information about the household. Source code in tripsender\\household.py 150 151 152 153 154 155 156 157 158 159 160 161 162 def info ( self ): \"\"\"Returns a dictionary with information about the household.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Category\" : self . category , \"Number of Members\" : len ( self . members ), \"Members\" : [ member . info () for member in self . members ], \"Children\" : self . children , \"House Type\" : self . house_type , \"Cars\" : self . cars } return info_dict","title":"info"},{"location":"household/#tripsender.household.Household.plot_member_graph","text":"Plots a relational graph of all members in the household Source code in tripsender\\household.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 def plot_member_graph ( self ): \"\"\" Plots a relational graph of all members in the household\"\"\" members = self . members adults = [ member for member in members if member . is_child == False ] children = [ member for member in members if member . is_child == True ] G = nx . Graph () # Adding household node with size = number of members and colour = red G . add_node ( self . uuid , type = \"household\" , size = len ( self . members ) * 10 , color = \"#FF6961\" ) # Adding adult nodes with size = age and colour = blue for adult in adults : G . add_node ( adult . uuid , type = \"adult\" , age = adult . age , size = adult . age , color = \"#AEC6CF\" , gender = adult . sex ) # Adding child nodes with size = age and colour = green for child in children : G . add_node ( child . uuid , type = \"child\" , age = child . age , size = child . age , color = \"#77DD77\" , gender = child . sex ) # Adding edges between household and adults for adult in adults : G . add_edge ( self . uuid , adult . uuid ) # Adding edges between adults and children with length = 1 for adult in adults : for child in children : G . add_edge ( adult . uuid , child . uuid , length = 1 ) # Plotting the graph with node size and colour plt . figure ( figsize = ( 10 , 10 )) # Draw a hierarchical tree graph pos = nx . spring_layout ( G ) nx . draw ( G , pos , with_labels = False , node_size = [ v [ 'size' ] * 50 for v in G . nodes . values ()], node_color = [ v [ 'color' ] for v in G . nodes . values ()]) # Add node labels with age and gender attributes node_labels = {} for node in G . nodes : if G . nodes [ node ][ 'type' ] == 'household' : continue age = G . nodes [ node ][ 'age' ] gender = G . nodes [ node ][ 'gender' ] node_labels [ node ] = f \"Age: { age } \\n Gender: { gender } \" nx . draw_networkx_labels ( G , pos , labels = node_labels , font_color = \"black\" , font_size = 8 ) # Add the title and subtitle plt . title ( \"Household Graph\" ) plt . suptitle ( f \"Household Category: { self . category } - Number of Members: { len ( self . members ) } \" , fontsize = 12 ) plt . show ()","title":"plot_member_graph"},{"location":"household/#tripsender.household.Household.return_dataframe","text":"Returns a dataframe with information about the households. Source code in tripsender\\household.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @classmethod def return_dataframe ( cls ): \"\"\"Returns a dataframe with information about the households.\"\"\" data = [] for household in cls . instances : household_dict = { \"uuid_household\" : household . uuid , \"name_category\" : household . category , \"count_children\" : household . children , \"bool_children\" : household . has_children , \"count_adults\" : household . adults , \"count_members\" : len ( household . members ), \"uuid_members\" : [ member . uuid for member in household . members ], \"type_house\" : household . house_type , \"uuid_house\" : household . house . uuid if household . house else None , \"count_cars\" : household . cars , \"head_of_household\" : household . head_of_household . uuid if household . head_of_household else None } data . append ( household_dict ) return pd . DataFrame ( data )","title":"return_dataframe"},{"location":"household/#tripsender.household.Household.return_nhts","text":"Returns a dataframe with information about the households and persons in a common NHTS format. Source code in tripsender\\household.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 @classmethod def return_nhts ( cls , onehotencode = False , drop = [ 'primary_status' ]): \"\"\" Returns a dataframe with information about the households and persons in a common NHTS format. \"\"\" # Helper function to determine age group def _determine_age_group ( age ): if age < 25 : return '16-24' elif age < 35 : return '25-34' elif age < 45 : return '35-44' elif age < 55 : return '45-54' elif age < 65 : return '55-64' elif age < 75 : return '65-74' else : return '75+' list_of_dicts = [] adults = [] for household in cls . instances : for person in household . members : if person . age > 18 : adults . append ( person ) age_group = _determine_age_group ( person . age ) person_dict = { 'sex' : person . sex , 'age_group' : age_group , 'house_type' : person . household . house_type , 'child_count' : person . household . children , 'adult_count' : len ( person . household . members ) - person . household . children , 'household_type' : person . household . category , 'car_count' : person . household . cars , 'primary_status' : person . primary_status , } list_of_dicts . append ( person_dict ) df = pd . DataFrame ( list_of_dicts ) # If drop, then drop the columns in the list if drop : df = df . drop ( drop , axis = 1 ) if onehotencode : ohe = OneHotEncoder ( sparse = False ) # Initialize the encoder categorical_variables = [ 'sex' , 'age_group' , 'house_type' , 'household_type' ] df_ohe = pd . DataFrame ( ohe . fit_transform ( df [ categorical_variables ])) df_ohe . columns = ohe . get_feature_names () df = df . drop ( categorical_variables , axis = 1 ) . reset_index ( drop = True ) df = pd . concat ([ df , df_ohe ], axis = 1 ) return df , adults","title":"return_nhts"},{"location":"household/#tripsender.household.Household.sync_children_in_households","text":"Syncs the number of children in households. Source code in tripsender\\household.py 121 122 123 124 125 126 @classmethod def sync_children_in_households ( cls ): \"\"\"Syncs the number of children in households.\"\"\" for household in cls . instances : household . children = sum ( 1 for member in household . members if member . is_child ) household . has_children = household . children > 0","title":"sync_children_in_households"},{"location":"household/#tripsender.household.Household.update_has_child","text":"Set the has_child attribute for adults in the household based on the number of children in the household Source code in tripsender\\household.py 499 500 501 502 503 504 505 506 507 def update_has_child ( self ): \"\"\" Set the has_child attribute for adults in the household based on the number of children in the household\"\"\" if self . children > 0 : self . has_child = True else : self . has_child = False for member in self . members : if member . is_child == False : member . has_child = self . has_child","title":"update_has_child"},{"location":"io/","text":"fetch_igraph ( graph_type ) Fetches an igraph graph based on the type specified (drive, walk, bike). Parameters: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. Source code in tripsender\\io.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def fetch_igraph ( graph_type ): \"\"\" Fetches an igraph graph based on the type specified (drive, walk, bike). Parameters: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. \"\"\" graph_path = GRAPH_PATHS . get ( graph_type ) if graph_path is None : raise ValueError ( f \"Graph type ' { graph_type } ' is not supported.\" ) logger . info ( f \"Loading { graph_type } networkx graph...\" ) G_nx = ox . load_graphml ( graph_path ) logger . info ( f \"Converting { graph_type } networkx graph to igraph...\" ) G_ig = ig . Graph . from_networkx ( G_nx ) return G_ig fetch_osm_graph ( graph_type ) Fetches an igraph graph based on the type specified (drive, walk, bike). Attributes: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. Source code in tripsender\\io.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def fetch_osm_graph ( graph_type ): \"\"\" Fetches an igraph graph based on the type specified (drive, walk, bike). Attributes: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. \"\"\" path_to_pbf = \"data\\osm\\GOT_OSM.pbf\" osm = OSM ( path_to_pbf ) nodes , edges = osm . get_network ( nodes = True , network_type = graph_type ) G_ig = osm . to_graph ( nodes , edges ) return G_ig write_to_database ( area , year , od_matrix ) Writes the data to a database. Attributes: area (str): The area for which the data is being written. year (int): The year for which the data is being written. od_matrix (ODMatrix): The ODMatrix object containing the data to be written. Source code in tripsender\\io.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 def write_to_database ( area , year , od_matrix ): \"\"\" Writes the data to a database. Attributes: area (str): The area for which the data is being written. year (int): The year for which the data is being written. od_matrix (ODMatrix): The ODMatrix object containing the data to be written. \"\"\" date_today = datetime . date . today () # Format yyyymmdd date_today = date_today . strftime ( \"%Y%m %d \" ) db_name = str . format ( 'data/processed/ {} _tripsender_ {} _ {} .db' , date_today , year , area ) person_df = Person . return_dataframe () household_df = Household . return_dataframe () od_matrix_df = od_matrix . matrix house_df = House . return_dataframe () building_df = Building . return_gdf () . drop ( columns = [ 'footprint' ]) # Now lets define the database schema and setup the primary keys # Create a connection to the database conn = sqlite3 . connect ( db_name ) # Create a cursor object cursor = conn . cursor () # Create the person table cursor . execute ( '''CREATE TABLE IF NOT EXISTS person ( uuid TEXT PRIMARY KEY, uuid_household TEXT, uuid_parent TEXT, age INTEGER, sex TEXT, type_household TEXT, household TEXT, has_car BOOLEAN, child_count INTEGER, is_head BOOLEAN, is_child BOOLEAN, origin TEXT, activity_sequence TEXT, primary_status TEXT, age_group TEXT, location_work TEXT, type_house TEXT, has_child BOOLEAN, location_mapping TEXT, FOREIGN KEY (uuid_household) REFERENCES household(uuid), FOREIGN KEY (uuid_parent) REFERENCES person(uuid));''' ) # Create the household table cursor . execute ( '''CREATE TABLE IF NOT EXISTS household ( uuid TEXT PRIMARY KEY, name_category TEXT, count_children INTEGER, bool_children BOOLEAN, count_adults INTEGER, count_members INTEGER, uuid_members TEXT, -- Assuming this stores a list, consider normalization if possible type_house TEXT, uuid_house TEXT, -- Foreign key linking to the house table count_cars INTEGER, head_of_household TEXT, -- Foreign key linking to the person table FOREIGN KEY (uuid_house) REFERENCES house(uuid), FOREIGN KEY (head_of_household) REFERENCES person(uuid) );''' ) # Create the od_matrix table cursor . execute ( '''CREATE TABLE IF NOT EXISTS od_matrix ( uuid TEXT PRIMARY KEY, origin TEXT, destination TEXT, mode TEXT, distance REAL, duration REAL, FOREIGN KEY (origin) REFERENCES building(uuid), FOREIGN KEY (destination) REFERENCES building(uuid));''' ) # Create the house table cursor . execute ( '''CREATE TABLE IF NOT EXISTS od_matrix ( origin TEXT, destination TEXT, mode TEXT, transit_activity TEXT, origin_purpose TEXT, destination_purpose TEXT, activity_sequence TEXT, uuid_person TEXT, -- Foreign key linking to the person table PRIMARY KEY (origin, destination, uuid_person), -- Composite primary key, adjust as needed FOREIGN KEY (uuid_person) REFERENCES person(uuid) );''' ) # Create the building table cursor . execute ( '''CREATE TABLE IF NOT EXISTS building ( uuid TEXT PRIMARY KEY, type_building TEXT, area_square_meters REAL, height_meters REAL, count_floors INTEGER, population_per_floor INTEGER, population_total INTEGER, built_up_area REAL, count_workers INTEGER, is_empty BOOLEAN, building TEXT, -- This column's purpose seems redundant given the table context, consider its necessity coord TEXT, -- Assuming this stores coordinates; consider storing as separate latitude and longitude columns if applicable preferred_locations TEXT -- Assuming this stores a list or complex data; consider normalization if it represents relationships );''' ) # Commit the changes and close the connection conn . commit () conn . close () # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones person_df [ 'uuid' ] = person_df [ 'uuid' ] . astype ( str ) person_df [ 'household_uuid' ] = person_df [ 'household_uuid' ] . astype ( str ) person_df [ 'parent_uuid' ] = person_df [ 'parent_uuid' ] . astype ( str ) person_df [ 'age' ] = person_df [ 'age' ] . astype ( int ) person_df [ 'sex' ] = person_df [ 'sex' ] . astype ( str ) person_df [ 'household_type' ] = person_df [ 'household_type' ] . astype ( str ) person_df [ 'household' ] = person_df [ 'household' ] . astype ( str ) person_df [ 'has_car' ] = person_df [ 'has_car' ] . astype ( bool ) person_df [ 'child_count' ] = person_df [ 'child_count' ] . astype ( int ) person_df [ 'is_head' ] = person_df [ 'is_head' ] . astype ( bool ) person_df [ 'is_child' ] = person_df [ 'is_child' ] . astype ( bool ) person_df [ 'origin' ] = person_df [ 'origin' ] . astype ( str ) person_df [ 'activity_sequence' ] = person_df [ 'activity_sequence' ] . astype ( str ) person_df [ 'primary_status' ] = person_df [ 'primary_status' ] . astype ( str ) person_df [ 'age_group' ] = person_df [ 'age_group' ] . astype ( str ) person_df [ 'work_location' ] = person_df [ 'work_location' ] . astype ( str ) person_df [ 'house_type' ] = person_df [ 'house_type' ] . astype ( str ) person_df [ 'has_child' ] = person_df [ 'has_child' ] . astype ( bool ) person_df [ 'location_mapping' ] = person_df [ 'location_mapping' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'uuid' : 'uuid' , # Primary key 'household_uuid' : 'uuid_household' , # Links to the household table 'parent_uuid' : 'uuid_parent' , # Links to another person in the same table 'age' : 'age' , 'sex' : 'sex' , 'household_type' : 'type_household' , 'household' : 'household' , 'has_car' : 'has_car' , 'child_count' : 'child_count' , 'is_head' : 'is_head' , 'is_child' : 'is_child' , 'origin' : 'origin' , 'activity_sequence' : 'activity_sequence' , 'primary_status' : 'primary_status' , 'age_group' : 'age_group' , 'work_location' : 'location_work' , 'house_type' : 'type_house' , 'has_child' : 'has_child' , 'location_mapping' : 'location_mapping' } person_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database person_df . to_sql ( 'person' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Next households # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones household_df [ 'uuid_household' ] = household_df [ 'uuid_household' ] . astype ( str ) household_df [ 'name_category' ] = household_df [ 'name_category' ] . astype ( str ) household_df [ 'count_children' ] = household_df [ 'count_children' ] . astype ( int ) household_df [ 'bool_children' ] = household_df [ 'bool_children' ] . astype ( bool ) household_df [ 'count_adults' ] = household_df [ 'count_adults' ] . astype ( int ) household_df [ 'count_members' ] = household_df [ 'count_members' ] . astype ( int ) household_df [ 'uuid_members' ] = household_df [ 'uuid_members' ] . astype ( str ) household_df [ 'type_house' ] = household_df [ 'type_house' ] . astype ( str ) household_df [ 'uuid_house' ] = household_df [ 'uuid_house' ] . astype ( str ) household_df [ 'count_cars' ] = household_df [ 'count_cars' ] . astype ( int ) household_df [ 'head_of_household' ] = household_df [ 'head_of_household' ] . astype ( str ) # UUID # Lets now rename all the columns renaming_dict = { 'uuid_household' : 'uuid' , # Primary key 'name_category' : 'name_category' , 'count_children' : 'count_children' , 'bool_children' : 'bool_children' , 'count_adults' : 'count_adults' , 'count_members' : 'count_members' , 'uuid_members' : 'uuid_members' , # List of UUIDs of the members 'type_house' : 'type_house' , 'uuid_house' : 'uuid_house' , # Links to the house table 'count_cars' : 'count_cars' , 'head_of_household' : 'head_of_household' # Links to the person table } household_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database household_df . to_sql ( 'household' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Next the od_matrix_df # The person column contains a person object, we need to create a new column for the uuid of the person od_matrix_df [ 'person_uuid' ] = od_matrix_df [ 'person' ] . apply ( lambda x : x . uuid ) # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones #Attributes from transit_activity #self.start_time = parsed_datetime.time() if parsed_datetime else None #self.duration_minutes = duration_minutes #self.duration_timedelta = self.duration() #self.end_time = (datetime.combine(datetime.today(), self.start_time) + timedelta(minutes=duration_minutes)).time() #self.purpose = purpose #self.mode = mode #self.destination = None #self.destination_coordinates = None #self.origin = None #self.origin_coordinates = None #self.calculated_duration = None #self.route = None # Create a column for route from transit_activity.route od_matrix_df [ 'route' ] = od_matrix_df [ 'transit_activity' ] . apply ( lambda x : x . route ) od_matrix_df [ 'calculated_duration' ] = od_matrix_df [ 'transit_activity' ] . apply ( lambda x : x . calculated_duration ) od_matrix_df [ 'duration_minutes' ] = od_matrix_df [ 'transit_activity' ] . apply ( lambda x : x . duration_minutes ) od_matrix_df [ 'O' ] = od_matrix_df [ 'O' ] . astype ( str ) od_matrix_df [ 'D' ] = od_matrix_df [ 'D' ] . astype ( str ) od_matrix_df [ 'mode' ] = od_matrix_df [ 'mode' ] . astype ( str ) od_matrix_df [ 'transit_activity' ] = od_matrix_df [ 'transit_activity' ] . astype ( str ) od_matrix_df [ 'route' ] = od_matrix_df [ 'route' ] . astype ( str ) od_matrix_df [ 'calculated_duration' ] = od_matrix_df [ 'calculated_duration' ] . astype ( float ) od_matrix_df [ 'duration_minutes' ] = od_matrix_df [ 'duration_minutes' ] . astype ( float ) od_matrix_df [ 'O_purpose' ] = od_matrix_df [ 'O_purpose' ] . astype ( str ) od_matrix_df [ 'D_purpose' ] = od_matrix_df [ 'D_purpose' ] . astype ( str ) od_matrix_df [ 'person' ] = od_matrix_df [ 'person' ] . astype ( str ) od_matrix_df [ 'activity_sequence' ] = od_matrix_df [ 'activity_sequence' ] . astype ( str ) od_matrix_df [ 'person_uuid' ] = od_matrix_df [ 'person_uuid' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'O' : 'origin' , # Primary key 'D' : 'destination' , 'mode' : 'mode' , 'transit_activity' : 'transit_activity' , 'route' : 'route' , 'calculated_duration' : 'calculated_duration' , 'duration_minutes' : 'sampled_duration' , 'O_purpose' : 'origin_purpose' , 'D_purpose' : 'destination_purpose' , 'activity_sequence' : 'activity_sequence' , 'person_uuid' : 'uuid_person' # Links to the person table } od_matrix_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database od_matrix_df . to_sql ( 'od_matrix' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Next the house_df # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones house_df [ 'House UUID' ] = house_df [ 'House UUID' ] . astype ( str ) house_df [ 'Household UUID' ] = house_df [ 'Household UUID' ] . astype ( str ) house_df [ 'Building UUID' ] = house_df [ 'Building UUID' ] . astype ( str ) house_df [ 'Members in house' ] = house_df [ 'Members in house' ] . astype ( int ) house_df [ 'Adults in house' ] = house_df [ 'Adults in house' ] . astype ( int ) house_df [ 'Children in house' ] = house_df [ 'Children in house' ] . astype ( int ) house_df [ 'Cars in the household' ] = house_df [ 'Cars in the household' ] . astype ( int ) house_df [ 'Area' ] = house_df [ 'Area' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'House UUID' : 'uuid' , # Primary key 'Household UUID' : 'uuid_household' , # Links to the household table 'Building UUID' : 'uuid_building' , # Links to the building table 'Members in house' : 'count_members' , 'Adults in house' : 'count_adults' , 'Children in house' : 'count_children' , 'Cars in the household' : 'count_cars' , 'Area' : 'area_square_meters' } house_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database house_df . to_sql ( 'house' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Finally the building_df # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones #Index(['uuid', 'type', 'area', 'height', 'floors', 'population_per_floor', ## 'population_total', 'built_up_area', 'workers', 'is_empty', 'building', # 'coord', 'preferred_locations'], # dtype='object') building_df [ 'uuid' ] = building_df [ 'uuid' ] . astype ( str ) building_df [ 'type' ] = building_df [ 'type' ] . astype ( str ) building_df [ 'area' ] = building_df [ 'area' ] . astype ( float ) building_df [ 'height' ] = building_df [ 'height' ] . astype ( float ) building_df [ 'floors' ] = building_df [ 'floors' ] . astype ( int ) building_df [ 'population_per_floor' ] = building_df [ 'population_per_floor' ] . astype ( int ) building_df [ 'population_total' ] = building_df [ 'population_total' ] . astype ( int ) building_df [ 'built_up_area' ] = building_df [ 'built_up_area' ] . astype ( float ) building_df [ 'workers' ] = building_df [ 'workers' ] . astype ( int ) building_df [ 'is_empty' ] = building_df [ 'is_empty' ] . astype ( bool ) building_df [ 'building' ] = building_df [ 'building' ] . astype ( str ) building_df [ 'coord' ] = building_df [ 'coord' ] . astype ( str ) building_df [ 'preferred_locations' ] = building_df [ 'preferred_locations' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'uuid' : 'uuid' , # Primary key 'type' : 'type_building' , 'area' : 'area_square_meters' , 'height' : 'height_meters' , 'floors' : 'count_floors' , 'population_per_floor' : 'population_per_floor' , 'population_total' : 'population_total' , 'built_up_area' : 'built_up_area' , 'workers' : 'count_workers' , 'is_empty' : 'is_empty' , 'building' : 'building' , 'coord' : 'coord' , 'preferred_locations' : 'preferred_locations' } building_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database building_df . to_sql ( 'building' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close ()","title":"io"},{"location":"io/#tripsender.io.fetch_igraph","text":"Fetches an igraph graph based on the type specified (drive, walk, bike). Parameters: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. Source code in tripsender\\io.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def fetch_igraph ( graph_type ): \"\"\" Fetches an igraph graph based on the type specified (drive, walk, bike). Parameters: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. \"\"\" graph_path = GRAPH_PATHS . get ( graph_type ) if graph_path is None : raise ValueError ( f \"Graph type ' { graph_type } ' is not supported.\" ) logger . info ( f \"Loading { graph_type } networkx graph...\" ) G_nx = ox . load_graphml ( graph_path ) logger . info ( f \"Converting { graph_type } networkx graph to igraph...\" ) G_ig = ig . Graph . from_networkx ( G_nx ) return G_ig","title":"fetch_igraph"},{"location":"io/#tripsender.io.fetch_osm_graph","text":"Fetches an igraph graph based on the type specified (drive, walk, bike). Attributes: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. Source code in tripsender\\io.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def fetch_osm_graph ( graph_type ): \"\"\" Fetches an igraph graph based on the type specified (drive, walk, bike). Attributes: graph_type (str): The type of graph to fetch. Returns: ig.Graph: The igraph graph object. \"\"\" path_to_pbf = \"data\\osm\\GOT_OSM.pbf\" osm = OSM ( path_to_pbf ) nodes , edges = osm . get_network ( nodes = True , network_type = graph_type ) G_ig = osm . to_graph ( nodes , edges ) return G_ig","title":"fetch_osm_graph"},{"location":"io/#tripsender.io.write_to_database","text":"Writes the data to a database. Attributes: area (str): The area for which the data is being written. year (int): The year for which the data is being written. od_matrix (ODMatrix): The ODMatrix object containing the data to be written. Source code in tripsender\\io.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 def write_to_database ( area , year , od_matrix ): \"\"\" Writes the data to a database. Attributes: area (str): The area for which the data is being written. year (int): The year for which the data is being written. od_matrix (ODMatrix): The ODMatrix object containing the data to be written. \"\"\" date_today = datetime . date . today () # Format yyyymmdd date_today = date_today . strftime ( \"%Y%m %d \" ) db_name = str . format ( 'data/processed/ {} _tripsender_ {} _ {} .db' , date_today , year , area ) person_df = Person . return_dataframe () household_df = Household . return_dataframe () od_matrix_df = od_matrix . matrix house_df = House . return_dataframe () building_df = Building . return_gdf () . drop ( columns = [ 'footprint' ]) # Now lets define the database schema and setup the primary keys # Create a connection to the database conn = sqlite3 . connect ( db_name ) # Create a cursor object cursor = conn . cursor () # Create the person table cursor . execute ( '''CREATE TABLE IF NOT EXISTS person ( uuid TEXT PRIMARY KEY, uuid_household TEXT, uuid_parent TEXT, age INTEGER, sex TEXT, type_household TEXT, household TEXT, has_car BOOLEAN, child_count INTEGER, is_head BOOLEAN, is_child BOOLEAN, origin TEXT, activity_sequence TEXT, primary_status TEXT, age_group TEXT, location_work TEXT, type_house TEXT, has_child BOOLEAN, location_mapping TEXT, FOREIGN KEY (uuid_household) REFERENCES household(uuid), FOREIGN KEY (uuid_parent) REFERENCES person(uuid));''' ) # Create the household table cursor . execute ( '''CREATE TABLE IF NOT EXISTS household ( uuid TEXT PRIMARY KEY, name_category TEXT, count_children INTEGER, bool_children BOOLEAN, count_adults INTEGER, count_members INTEGER, uuid_members TEXT, -- Assuming this stores a list, consider normalization if possible type_house TEXT, uuid_house TEXT, -- Foreign key linking to the house table count_cars INTEGER, head_of_household TEXT, -- Foreign key linking to the person table FOREIGN KEY (uuid_house) REFERENCES house(uuid), FOREIGN KEY (head_of_household) REFERENCES person(uuid) );''' ) # Create the od_matrix table cursor . execute ( '''CREATE TABLE IF NOT EXISTS od_matrix ( uuid TEXT PRIMARY KEY, origin TEXT, destination TEXT, mode TEXT, distance REAL, duration REAL, FOREIGN KEY (origin) REFERENCES building(uuid), FOREIGN KEY (destination) REFERENCES building(uuid));''' ) # Create the house table cursor . execute ( '''CREATE TABLE IF NOT EXISTS od_matrix ( origin TEXT, destination TEXT, mode TEXT, transit_activity TEXT, origin_purpose TEXT, destination_purpose TEXT, activity_sequence TEXT, uuid_person TEXT, -- Foreign key linking to the person table PRIMARY KEY (origin, destination, uuid_person), -- Composite primary key, adjust as needed FOREIGN KEY (uuid_person) REFERENCES person(uuid) );''' ) # Create the building table cursor . execute ( '''CREATE TABLE IF NOT EXISTS building ( uuid TEXT PRIMARY KEY, type_building TEXT, area_square_meters REAL, height_meters REAL, count_floors INTEGER, population_per_floor INTEGER, population_total INTEGER, built_up_area REAL, count_workers INTEGER, is_empty BOOLEAN, building TEXT, -- This column's purpose seems redundant given the table context, consider its necessity coord TEXT, -- Assuming this stores coordinates; consider storing as separate latitude and longitude columns if applicable preferred_locations TEXT -- Assuming this stores a list or complex data; consider normalization if it represents relationships );''' ) # Commit the changes and close the connection conn . commit () conn . close () # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones person_df [ 'uuid' ] = person_df [ 'uuid' ] . astype ( str ) person_df [ 'household_uuid' ] = person_df [ 'household_uuid' ] . astype ( str ) person_df [ 'parent_uuid' ] = person_df [ 'parent_uuid' ] . astype ( str ) person_df [ 'age' ] = person_df [ 'age' ] . astype ( int ) person_df [ 'sex' ] = person_df [ 'sex' ] . astype ( str ) person_df [ 'household_type' ] = person_df [ 'household_type' ] . astype ( str ) person_df [ 'household' ] = person_df [ 'household' ] . astype ( str ) person_df [ 'has_car' ] = person_df [ 'has_car' ] . astype ( bool ) person_df [ 'child_count' ] = person_df [ 'child_count' ] . astype ( int ) person_df [ 'is_head' ] = person_df [ 'is_head' ] . astype ( bool ) person_df [ 'is_child' ] = person_df [ 'is_child' ] . astype ( bool ) person_df [ 'origin' ] = person_df [ 'origin' ] . astype ( str ) person_df [ 'activity_sequence' ] = person_df [ 'activity_sequence' ] . astype ( str ) person_df [ 'primary_status' ] = person_df [ 'primary_status' ] . astype ( str ) person_df [ 'age_group' ] = person_df [ 'age_group' ] . astype ( str ) person_df [ 'work_location' ] = person_df [ 'work_location' ] . astype ( str ) person_df [ 'house_type' ] = person_df [ 'house_type' ] . astype ( str ) person_df [ 'has_child' ] = person_df [ 'has_child' ] . astype ( bool ) person_df [ 'location_mapping' ] = person_df [ 'location_mapping' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'uuid' : 'uuid' , # Primary key 'household_uuid' : 'uuid_household' , # Links to the household table 'parent_uuid' : 'uuid_parent' , # Links to another person in the same table 'age' : 'age' , 'sex' : 'sex' , 'household_type' : 'type_household' , 'household' : 'household' , 'has_car' : 'has_car' , 'child_count' : 'child_count' , 'is_head' : 'is_head' , 'is_child' : 'is_child' , 'origin' : 'origin' , 'activity_sequence' : 'activity_sequence' , 'primary_status' : 'primary_status' , 'age_group' : 'age_group' , 'work_location' : 'location_work' , 'house_type' : 'type_house' , 'has_child' : 'has_child' , 'location_mapping' : 'location_mapping' } person_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database person_df . to_sql ( 'person' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Next households # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones household_df [ 'uuid_household' ] = household_df [ 'uuid_household' ] . astype ( str ) household_df [ 'name_category' ] = household_df [ 'name_category' ] . astype ( str ) household_df [ 'count_children' ] = household_df [ 'count_children' ] . astype ( int ) household_df [ 'bool_children' ] = household_df [ 'bool_children' ] . astype ( bool ) household_df [ 'count_adults' ] = household_df [ 'count_adults' ] . astype ( int ) household_df [ 'count_members' ] = household_df [ 'count_members' ] . astype ( int ) household_df [ 'uuid_members' ] = household_df [ 'uuid_members' ] . astype ( str ) household_df [ 'type_house' ] = household_df [ 'type_house' ] . astype ( str ) household_df [ 'uuid_house' ] = household_df [ 'uuid_house' ] . astype ( str ) household_df [ 'count_cars' ] = household_df [ 'count_cars' ] . astype ( int ) household_df [ 'head_of_household' ] = household_df [ 'head_of_household' ] . astype ( str ) # UUID # Lets now rename all the columns renaming_dict = { 'uuid_household' : 'uuid' , # Primary key 'name_category' : 'name_category' , 'count_children' : 'count_children' , 'bool_children' : 'bool_children' , 'count_adults' : 'count_adults' , 'count_members' : 'count_members' , 'uuid_members' : 'uuid_members' , # List of UUIDs of the members 'type_house' : 'type_house' , 'uuid_house' : 'uuid_house' , # Links to the house table 'count_cars' : 'count_cars' , 'head_of_household' : 'head_of_household' # Links to the person table } household_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database household_df . to_sql ( 'household' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Next the od_matrix_df # The person column contains a person object, we need to create a new column for the uuid of the person od_matrix_df [ 'person_uuid' ] = od_matrix_df [ 'person' ] . apply ( lambda x : x . uuid ) # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones #Attributes from transit_activity #self.start_time = parsed_datetime.time() if parsed_datetime else None #self.duration_minutes = duration_minutes #self.duration_timedelta = self.duration() #self.end_time = (datetime.combine(datetime.today(), self.start_time) + timedelta(minutes=duration_minutes)).time() #self.purpose = purpose #self.mode = mode #self.destination = None #self.destination_coordinates = None #self.origin = None #self.origin_coordinates = None #self.calculated_duration = None #self.route = None # Create a column for route from transit_activity.route od_matrix_df [ 'route' ] = od_matrix_df [ 'transit_activity' ] . apply ( lambda x : x . route ) od_matrix_df [ 'calculated_duration' ] = od_matrix_df [ 'transit_activity' ] . apply ( lambda x : x . calculated_duration ) od_matrix_df [ 'duration_minutes' ] = od_matrix_df [ 'transit_activity' ] . apply ( lambda x : x . duration_minutes ) od_matrix_df [ 'O' ] = od_matrix_df [ 'O' ] . astype ( str ) od_matrix_df [ 'D' ] = od_matrix_df [ 'D' ] . astype ( str ) od_matrix_df [ 'mode' ] = od_matrix_df [ 'mode' ] . astype ( str ) od_matrix_df [ 'transit_activity' ] = od_matrix_df [ 'transit_activity' ] . astype ( str ) od_matrix_df [ 'route' ] = od_matrix_df [ 'route' ] . astype ( str ) od_matrix_df [ 'calculated_duration' ] = od_matrix_df [ 'calculated_duration' ] . astype ( float ) od_matrix_df [ 'duration_minutes' ] = od_matrix_df [ 'duration_minutes' ] . astype ( float ) od_matrix_df [ 'O_purpose' ] = od_matrix_df [ 'O_purpose' ] . astype ( str ) od_matrix_df [ 'D_purpose' ] = od_matrix_df [ 'D_purpose' ] . astype ( str ) od_matrix_df [ 'person' ] = od_matrix_df [ 'person' ] . astype ( str ) od_matrix_df [ 'activity_sequence' ] = od_matrix_df [ 'activity_sequence' ] . astype ( str ) od_matrix_df [ 'person_uuid' ] = od_matrix_df [ 'person_uuid' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'O' : 'origin' , # Primary key 'D' : 'destination' , 'mode' : 'mode' , 'transit_activity' : 'transit_activity' , 'route' : 'route' , 'calculated_duration' : 'calculated_duration' , 'duration_minutes' : 'sampled_duration' , 'O_purpose' : 'origin_purpose' , 'D_purpose' : 'destination_purpose' , 'activity_sequence' : 'activity_sequence' , 'person_uuid' : 'uuid_person' # Links to the person table } od_matrix_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database od_matrix_df . to_sql ( 'od_matrix' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Next the house_df # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones house_df [ 'House UUID' ] = house_df [ 'House UUID' ] . astype ( str ) house_df [ 'Household UUID' ] = house_df [ 'Household UUID' ] . astype ( str ) house_df [ 'Building UUID' ] = house_df [ 'Building UUID' ] . astype ( str ) house_df [ 'Members in house' ] = house_df [ 'Members in house' ] . astype ( int ) house_df [ 'Adults in house' ] = house_df [ 'Adults in house' ] . astype ( int ) house_df [ 'Children in house' ] = house_df [ 'Children in house' ] . astype ( int ) house_df [ 'Cars in the household' ] = house_df [ 'Cars in the household' ] . astype ( int ) house_df [ 'Area' ] = house_df [ 'Area' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'House UUID' : 'uuid' , # Primary key 'Household UUID' : 'uuid_household' , # Links to the household table 'Building UUID' : 'uuid_building' , # Links to the building table 'Members in house' : 'count_members' , 'Adults in house' : 'count_adults' , 'Children in house' : 'count_children' , 'Cars in the household' : 'count_cars' , 'Area' : 'area_square_meters' } house_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database house_df . to_sql ( 'house' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close () # Finally the building_df # Create a connection to the database conn = sqlite3 . connect ( db_name ) # We need to convert the datatypes to the correct ones #Index(['uuid', 'type', 'area', 'height', 'floors', 'population_per_floor', ## 'population_total', 'built_up_area', 'workers', 'is_empty', 'building', # 'coord', 'preferred_locations'], # dtype='object') building_df [ 'uuid' ] = building_df [ 'uuid' ] . astype ( str ) building_df [ 'type' ] = building_df [ 'type' ] . astype ( str ) building_df [ 'area' ] = building_df [ 'area' ] . astype ( float ) building_df [ 'height' ] = building_df [ 'height' ] . astype ( float ) building_df [ 'floors' ] = building_df [ 'floors' ] . astype ( int ) building_df [ 'population_per_floor' ] = building_df [ 'population_per_floor' ] . astype ( int ) building_df [ 'population_total' ] = building_df [ 'population_total' ] . astype ( int ) building_df [ 'built_up_area' ] = building_df [ 'built_up_area' ] . astype ( float ) building_df [ 'workers' ] = building_df [ 'workers' ] . astype ( int ) building_df [ 'is_empty' ] = building_df [ 'is_empty' ] . astype ( bool ) building_df [ 'building' ] = building_df [ 'building' ] . astype ( str ) building_df [ 'coord' ] = building_df [ 'coord' ] . astype ( str ) building_df [ 'preferred_locations' ] = building_df [ 'preferred_locations' ] . astype ( str ) # Lets now rename all the columns renaming_dict = { 'uuid' : 'uuid' , # Primary key 'type' : 'type_building' , 'area' : 'area_square_meters' , 'height' : 'height_meters' , 'floors' : 'count_floors' , 'population_per_floor' : 'population_per_floor' , 'population_total' : 'population_total' , 'built_up_area' : 'built_up_area' , 'workers' : 'count_workers' , 'is_empty' : 'is_empty' , 'building' : 'building' , 'coord' : 'coord' , 'preferred_locations' : 'preferred_locations' } building_df . rename ( columns = renaming_dict , inplace = True ) # Writing the person_df to database building_df . to_sql ( 'building' , conn , if_exists = 'replace' , index = False ) # Close the connection conn . close ()","title":"write_to_database"},{"location":"location_assignment/","text":"LocationFinder LocationFinder class helps in finding locations based on the given GeoDataFrame and location counts. This class uses BallTree data structure to efficiently query nearby locations. Different types of locations (like schools, playgrounds, healthcare, etc.) can be associated with different default counts to prioritize their significance. Source code in tripsender\\location_assignment.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 class LocationFinder : \"\"\" LocationFinder class helps in finding locations based on the given GeoDataFrame and location counts. This class uses BallTree data structure to efficiently query nearby locations. Different types of locations (like schools, playgrounds, healthcare, etc.) can be associated with different default counts to prioritize their significance. \"\"\" def __init__ ( self , gdf , location_counts = None ): \"\"\" Initialize the LocationFinder with a given GeoDataFrame and optional location counts. Parameters: - gdf (GeoDataFrame): The input GeoDataFrame containing location data. - location_counts (dict, optional): A dictionary specifying the counts for different location types. \"\"\" self . gdf = gdf self . ball_trees = {} # Dictionary to store BallTrees for different location types count_multiple = 3 # A multiplier for location counts # Default counts for various location types if none are provided self . default_location_counts = { \"EDUCATION_f\u00f6rskola\" : 1 , \"EDUCATION_f\u00f6rskoleklass\" : 1 , \"EDUCATION_grundskola\" : 1 , \"EDUCATION_gymnasieskola\" : 1 , \"EDUCATION_fritidshem\" : 1 , \"LEISURE_sports\" : count_multiple , \"LEISURE_playground\" : count_multiple , \"EDUCATION\" : count_multiple , \"SHOPPING_OTHER\" : count_multiple , # \"SHOPPING_GROCERY\" is handled separately \"LEISURE\" : count_multiple , \"HEALTHCARE\" : count_multiple } # If custom location counts are provided, update the default counts if location_counts : self . default_location_counts . update ( location_counts ) self . populate_ball_trees () # Create BallTrees for the location types self . set_grocery_data () # Handle grocery data separately (method implementation is not provided) def populate_ball_trees ( self ): \"\"\" Populate the BallTrees for the different location types based on the GeoDataFrame. This method creates a BallTree for each location type listed in default_location_counts, allowing for efficient spatial queries. The BallTree, along with the associated GeoDataFrame subset and its count, is stored in the ball_trees dictionary for each location type. \"\"\" # Iterate over each location type and its associated count for loc_type , count in self . default_location_counts . items (): # Filter the GeoDataFrame based on the current location type temp_gdf = self . gdf [ self . gdf [ 'activity' ] == loc_type ] # Extract the coordinates from the 'geometry' column of the filtered GeoDataFrame coords = [( point . x , point . y ) for point in temp_gdf [ 'geometry' ] . values ] # If there are coordinates (i.e., there are entries for this location type in the GeoDataFrame), # create a BallTree for them if coords : # Create a BallTree with the coordinates and use the euclidean metric for spatial queries tree = BallTree ( np . array ( coords ), metric = 'euclidean' ) # Store the BallTree, the subset of the GeoDataFrame, and the count in the ball_trees dictionary self . ball_trees [ loc_type ] = ( tree , temp_gdf , count ) def set_grocery_data ( self ): \"\"\" Initialize and set the grocery-related data attributes. This method extracts the data related to the \"SHOPPING_GROCERY\" activity from the main GeoDataFrame. It sets up the grocery GeoDataFrame, the coordinates of the grocery locations, and their associated areas. \"\"\" logger . info ( \"Setting up grocery data...\" ) # Filter the main GeoDataFrame to extract only the rows related to \"SHOPPING_GROCERY\" activity self . grocery_gdf = self . gdf [ self . gdf [ 'activity' ] == \"SHOPPING_GROCERY\" ] # Extract the x and y coordinates from the 'geometry' column of the grocery GeoDataFrame self . grocery_coords = [( point . x , point . y ) for point in self . grocery_gdf [ 'geometry' ] . values ] # Extract the 'area' values corresponding to each grocery location self . grocery_areas = self . grocery_gdf [ 'area' ] . values def find_closest_locations ( self , origin_point , k = None ): \"\"\" Find the closest locations to a given origin point for each location type. This method queries the BallTree for each location type to find the closest locations. The number of closest locations for each type is determined by the 'k' parameter or the default count associated with the location type. Parameters: - origin_point (Point): The origin point from which distances are measured. - k (int, optional): The number of closest locations to return for each location type. If not provided, the default count for each type is used. Returns: - results (list): A list containing Location objects for each of the closest locations. \"\"\" results = [] # List to store the resulting Location objects origin = ( origin_point . x , origin_point . y ) # Convert origin point to tuple format # Iterate over each location type and its associated BallTree, GeoDataFrame subset, and count for loc_type , ( tree , relevant_gdf , count ) in self . ball_trees . items (): #logger.info(f\"Fetching location for location type : {loc_type}\") # Determine the number of closest locations to query. Use provided k or default count. current_k = k if k is not None else count # Query the BallTree to find the closest locations distances , indices = tree . query ([ origin ], k = current_k ) # Extract location data from the relevant GeoDataFrame for each of the closest locations for distance , index in zip ( distances [ 0 ], indices [ 0 ]): closest_row = relevant_gdf . iloc [ index ] #logger.info(f\"Found a location for amenity {loc_type} : {closest_row['name']}, {distance}m away\") # Create a Location object and add it to the results list location = Location ( loc_type , closest_row [ 'name' ], closest_row [ 'geometry' ], closest_row [ 'amenity' ]) results . append ( location ) return results @staticmethod def gravity_score ( distance , area , alpha = 0 , beta = 2 ): \"\"\" Calculate the gravity-based score for a location based on its area and distance from an origin. The gravity model, used here, is a spatial interaction model which is based on the idea that the interaction between two places can be determined by the product of the size of one (or both) and divided by their separation distance raised to a power (distance decay). Parameters: - distance (float): The distance from the origin to the location. - area (float): The size (area) of the location. - alpha (float, optional): The exponent for the area (default is 1.5). - beta (float, optional): The exponent for the distance decay (default is 2). Returns: - float: The gravity score for the location. \"\"\" epsilon = 1e-10 # Small constant to prevent division by zero # Calculate the gravity score using the formula: (area^alpha) / (distance + epsilon)^beta return 1 / (( distance + epsilon ) ** beta ) def find_closest_grocery_locations ( self , origin_point , k = 2 ): \"\"\" Find the closest grocery locations to a given origin point based on a gravity-based scoring system. This method first computes the euclidean distance between the origin point and each grocery location. It then calculates a gravity-based score for each grocery location using the gravity_score method. The top 'k' grocery locations with the highest gravity scores are returned. Parameters: - origin_point (Point): The origin point from which distances and scores are calculated. - k (int, optional): The number of top-scoring grocery locations to return (default is 3). Returns: - results (list): A list containing Location objects for each of the top 'k' grocery locations. \"\"\" # Convert the origin point to a list format [x, y] origin = [ origin_point . x , origin_point . y ] # Calculate the pairwise euclidean distances between the origin and each grocery location dist_metric = DistanceMetric . get_metric ( 'euclidean' ) distances = dist_metric . pairwise ([ origin ], self . grocery_coords ) . flatten () areas = self . grocery_areas # Get the areas of the grocery locations # Set all areas to 1 to neutralize their effect areas = [ 1 ] * len ( distances ) # Assuming there is one area value for each distance calculated # Compute gravity scores for each grocery location scores = [ self . gravity_score ( dist , area ) for dist , area in zip ( distances , areas )] # Get the indices of the top 'k' grocery locations based on the gravity scores top_indices = sorted ( range ( len ( scores )), key = lambda i : scores [ i ], reverse = True )[: k ] results = [] # List to store the resulting Location objects # Extract location data from the grocery GeoDataFrame for each of the top 'k' locations for index in top_indices : row = self . grocery_gdf . iloc [ index ] # Create a Location object and add it to the results list location = Location ( \"SHOPPING_GROCERY\" , row [ 'name' ], row [ 'geometry' ], row [ 'amenity' ]) results . append ( location ) return results __init__ ( gdf , location_counts = None ) Initialize the LocationFinder with a given GeoDataFrame and optional location counts. Parameters: - gdf (GeoDataFrame): The input GeoDataFrame containing location data. - location_counts (dict, optional): A dictionary specifying the counts for different location types. Source code in tripsender\\location_assignment.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def __init__ ( self , gdf , location_counts = None ): \"\"\" Initialize the LocationFinder with a given GeoDataFrame and optional location counts. Parameters: - gdf (GeoDataFrame): The input GeoDataFrame containing location data. - location_counts (dict, optional): A dictionary specifying the counts for different location types. \"\"\" self . gdf = gdf self . ball_trees = {} # Dictionary to store BallTrees for different location types count_multiple = 3 # A multiplier for location counts # Default counts for various location types if none are provided self . default_location_counts = { \"EDUCATION_f\u00f6rskola\" : 1 , \"EDUCATION_f\u00f6rskoleklass\" : 1 , \"EDUCATION_grundskola\" : 1 , \"EDUCATION_gymnasieskola\" : 1 , \"EDUCATION_fritidshem\" : 1 , \"LEISURE_sports\" : count_multiple , \"LEISURE_playground\" : count_multiple , \"EDUCATION\" : count_multiple , \"SHOPPING_OTHER\" : count_multiple , # \"SHOPPING_GROCERY\" is handled separately \"LEISURE\" : count_multiple , \"HEALTHCARE\" : count_multiple } # If custom location counts are provided, update the default counts if location_counts : self . default_location_counts . update ( location_counts ) self . populate_ball_trees () # Create BallTrees for the location types self . set_grocery_data () # Handle grocery data separately (method implementation is not provided) find_closest_grocery_locations ( origin_point , k = 2 ) Find the closest grocery locations to a given origin point based on a gravity-based scoring system. This method first computes the euclidean distance between the origin point and each grocery location. It then calculates a gravity-based score for each grocery location using the gravity_score method. The top 'k' grocery locations with the highest gravity scores are returned. Parameters: - origin_point (Point): The origin point from which distances and scores are calculated. - k (int, optional): The number of top-scoring grocery locations to return (default is 3). Returns: - results (list): A list containing Location objects for each of the top 'k' grocery locations. Source code in tripsender\\location_assignment.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def find_closest_grocery_locations ( self , origin_point , k = 2 ): \"\"\" Find the closest grocery locations to a given origin point based on a gravity-based scoring system. This method first computes the euclidean distance between the origin point and each grocery location. It then calculates a gravity-based score for each grocery location using the gravity_score method. The top 'k' grocery locations with the highest gravity scores are returned. Parameters: - origin_point (Point): The origin point from which distances and scores are calculated. - k (int, optional): The number of top-scoring grocery locations to return (default is 3). Returns: - results (list): A list containing Location objects for each of the top 'k' grocery locations. \"\"\" # Convert the origin point to a list format [x, y] origin = [ origin_point . x , origin_point . y ] # Calculate the pairwise euclidean distances between the origin and each grocery location dist_metric = DistanceMetric . get_metric ( 'euclidean' ) distances = dist_metric . pairwise ([ origin ], self . grocery_coords ) . flatten () areas = self . grocery_areas # Get the areas of the grocery locations # Set all areas to 1 to neutralize their effect areas = [ 1 ] * len ( distances ) # Assuming there is one area value for each distance calculated # Compute gravity scores for each grocery location scores = [ self . gravity_score ( dist , area ) for dist , area in zip ( distances , areas )] # Get the indices of the top 'k' grocery locations based on the gravity scores top_indices = sorted ( range ( len ( scores )), key = lambda i : scores [ i ], reverse = True )[: k ] results = [] # List to store the resulting Location objects # Extract location data from the grocery GeoDataFrame for each of the top 'k' locations for index in top_indices : row = self . grocery_gdf . iloc [ index ] # Create a Location object and add it to the results list location = Location ( \"SHOPPING_GROCERY\" , row [ 'name' ], row [ 'geometry' ], row [ 'amenity' ]) results . append ( location ) return results find_closest_locations ( origin_point , k = None ) Find the closest locations to a given origin point for each location type. This method queries the BallTree for each location type to find the closest locations. The number of closest locations for each type is determined by the 'k' parameter or the default count associated with the location type. Parameters: - origin_point (Point): The origin point from which distances are measured. - k (int, optional): The number of closest locations to return for each location type. If not provided, the default count for each type is used. Returns: - results (list): A list containing Location objects for each of the closest locations. Source code in tripsender\\location_assignment.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def find_closest_locations ( self , origin_point , k = None ): \"\"\" Find the closest locations to a given origin point for each location type. This method queries the BallTree for each location type to find the closest locations. The number of closest locations for each type is determined by the 'k' parameter or the default count associated with the location type. Parameters: - origin_point (Point): The origin point from which distances are measured. - k (int, optional): The number of closest locations to return for each location type. If not provided, the default count for each type is used. Returns: - results (list): A list containing Location objects for each of the closest locations. \"\"\" results = [] # List to store the resulting Location objects origin = ( origin_point . x , origin_point . y ) # Convert origin point to tuple format # Iterate over each location type and its associated BallTree, GeoDataFrame subset, and count for loc_type , ( tree , relevant_gdf , count ) in self . ball_trees . items (): #logger.info(f\"Fetching location for location type : {loc_type}\") # Determine the number of closest locations to query. Use provided k or default count. current_k = k if k is not None else count # Query the BallTree to find the closest locations distances , indices = tree . query ([ origin ], k = current_k ) # Extract location data from the relevant GeoDataFrame for each of the closest locations for distance , index in zip ( distances [ 0 ], indices [ 0 ]): closest_row = relevant_gdf . iloc [ index ] #logger.info(f\"Found a location for amenity {loc_type} : {closest_row['name']}, {distance}m away\") # Create a Location object and add it to the results list location = Location ( loc_type , closest_row [ 'name' ], closest_row [ 'geometry' ], closest_row [ 'amenity' ]) results . append ( location ) return results gravity_score ( distance , area , alpha = 0 , beta = 2 ) staticmethod Calculate the gravity-based score for a location based on its area and distance from an origin. The gravity model, used here, is a spatial interaction model which is based on the idea that the interaction between two places can be determined by the product of the size of one (or both) and divided by their separation distance raised to a power (distance decay). Parameters: - distance (float): The distance from the origin to the location. - area (float): The size (area) of the location. - alpha (float, optional): The exponent for the area (default is 1.5). - beta (float, optional): The exponent for the distance decay (default is 2). Returns: - float: The gravity score for the location. Source code in tripsender\\location_assignment.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 @staticmethod def gravity_score ( distance , area , alpha = 0 , beta = 2 ): \"\"\" Calculate the gravity-based score for a location based on its area and distance from an origin. The gravity model, used here, is a spatial interaction model which is based on the idea that the interaction between two places can be determined by the product of the size of one (or both) and divided by their separation distance raised to a power (distance decay). Parameters: - distance (float): The distance from the origin to the location. - area (float): The size (area) of the location. - alpha (float, optional): The exponent for the area (default is 1.5). - beta (float, optional): The exponent for the distance decay (default is 2). Returns: - float: The gravity score for the location. \"\"\" epsilon = 1e-10 # Small constant to prevent division by zero # Calculate the gravity score using the formula: (area^alpha) / (distance + epsilon)^beta return 1 / (( distance + epsilon ) ** beta ) populate_ball_trees () Populate the BallTrees for the different location types based on the GeoDataFrame. This method creates a BallTree for each location type listed in default_location_counts, allowing for efficient spatial queries. The BallTree, along with the associated GeoDataFrame subset and its count, is stored in the ball_trees dictionary for each location type. Source code in tripsender\\location_assignment.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def populate_ball_trees ( self ): \"\"\" Populate the BallTrees for the different location types based on the GeoDataFrame. This method creates a BallTree for each location type listed in default_location_counts, allowing for efficient spatial queries. The BallTree, along with the associated GeoDataFrame subset and its count, is stored in the ball_trees dictionary for each location type. \"\"\" # Iterate over each location type and its associated count for loc_type , count in self . default_location_counts . items (): # Filter the GeoDataFrame based on the current location type temp_gdf = self . gdf [ self . gdf [ 'activity' ] == loc_type ] # Extract the coordinates from the 'geometry' column of the filtered GeoDataFrame coords = [( point . x , point . y ) for point in temp_gdf [ 'geometry' ] . values ] # If there are coordinates (i.e., there are entries for this location type in the GeoDataFrame), # create a BallTree for them if coords : # Create a BallTree with the coordinates and use the euclidean metric for spatial queries tree = BallTree ( np . array ( coords ), metric = 'euclidean' ) # Store the BallTree, the subset of the GeoDataFrame, and the count in the ball_trees dictionary self . ball_trees [ loc_type ] = ( tree , temp_gdf , count ) set_grocery_data () Initialize and set the grocery-related data attributes. This method extracts the data related to the \"SHOPPING_GROCERY\" activity from the main GeoDataFrame. It sets up the grocery GeoDataFrame, the coordinates of the grocery locations, and their associated areas. Source code in tripsender\\location_assignment.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def set_grocery_data ( self ): \"\"\" Initialize and set the grocery-related data attributes. This method extracts the data related to the \"SHOPPING_GROCERY\" activity from the main GeoDataFrame. It sets up the grocery GeoDataFrame, the coordinates of the grocery locations, and their associated areas. \"\"\" logger . info ( \"Setting up grocery data...\" ) # Filter the main GeoDataFrame to extract only the rows related to \"SHOPPING_GROCERY\" activity self . grocery_gdf = self . gdf [ self . gdf [ 'activity' ] == \"SHOPPING_GROCERY\" ] # Extract the x and y coordinates from the 'geometry' column of the grocery GeoDataFrame self . grocery_coords = [( point . x , point . y ) for point in self . grocery_gdf [ 'geometry' ] . values ] # Extract the 'area' values corresponding to each grocery location self . grocery_areas = self . grocery_gdf [ 'area' ] . values assign_jobs_to_workers ( gdf_homes ) Assign job locations to workers residing in the buildings of gdf_homes. For each building in the GeoDataFrame, the function takes the potential job locations and assigns these to every worker residing in that building. gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It should have 'building' and 'potential_jobs' columns, where 'building' objects have a 'worker_list' attribute, and each worker in this list has a 'work_location' attribute. Returns: - None: The function modifies the 'work_location' attribute of each worker in-place. Source code in tripsender\\location_assignment.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 def assign_jobs_to_workers ( gdf_homes ): \"\"\" Assign job locations to workers residing in the buildings of gdf_homes. For each building in the GeoDataFrame, the function takes the potential job locations and assigns these to every worker residing in that building. Parameters: - gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It should have 'building' and 'potential_jobs' columns, where 'building' objects have a 'worker_list' attribute, and each worker in this list has a 'work_location' attribute. Returns: - None: The function modifies the 'work_location' attribute of each worker in-place. \"\"\" # Go through each row of the GeoDataFrame for _ , row in gdf_homes . iterrows (): building = row [ 'building' ] # Retrieve the building object job_locations = row [ 'potential_jobs' ] # Retrieve the potential job locations for this building # Iterate over each worker in the building for worker , job_point in zip ( building . worker_list , job_locations ): # Assign the job location to the worker's work_location attribute job_location = Location ( \"WORK\" , \"Work\" , job_point , \"WORK\" ) worker . work_location = job_location assign_workers_to_buildings () Assigns workers to buildings based on their primary status. Source code in tripsender\\location_assignment.py 478 479 480 481 482 483 484 485 486 487 488 489 490 491 def assign_workers_to_buildings (): \"\"\" Assigns workers to buildings based on their primary status. \"\"\" # Add workers to buildings for building in Building . instances : houses = building . houses for house in houses : household = house . household for member in household . members : # Workers is a list of workers with primary_status = \"WORK\" if member . primary_status == \"WORK\" : building . workers += 1 building . worker_list . append ( member ) compute_job_density ( file_path , radius = 1000 ) Computes job densities for each point in the GeoDataFrame using the given radius. The function loads a shapefile, calculates the centroid for each geometry and then computes the job density around each centroid using a given radius. The BallTree data structure is utilized for efficient spatial queries. Parameters: - file_path (str): Path to the shapefile. - radius (float): Radius in meters for which job density is calculated. Default is 1000 meters. Returns: - gdf_jobs (GeoDataFrame): Updated GeoDataFrame with job densities. Source code in tripsender\\location_assignment.py 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 def compute_job_density ( file_path , radius = 1000 ): \"\"\" Computes job densities for each point in the GeoDataFrame using the given radius. The function loads a shapefile, calculates the centroid for each geometry and then computes the job density around each centroid using a given radius. The BallTree data structure is utilized for efficient spatial queries. Parameters: - file_path (str): Path to the shapefile. - radius (float): Radius in meters for which job density is calculated. Default is 1000 meters. Returns: - gdf_jobs (GeoDataFrame): Updated GeoDataFrame with job densities. \"\"\" logger . info ( \"Computing job densities...\" ) # Load data from the shapefile gdf = gpd . read_file ( file_path ) # Compute centroids for each geometry in the GeoDataFrame gdf [ 'centroid' ] = gdf [ 'geometry' ] . centroid # Create a new GeoDataFrame with only the 'jobs' column and the computed centroids # Set the 'centroid' column as the geometry for this new GeoDataFrame gdf_jobs = gdf [[ 'jobs' , 'centroid' ]] . copy () gdf_jobs = gdf_jobs . set_geometry ( 'centroid' ) # Convert the GeoDataFrame's point geometries to a matrix format suitable for BallTree coordinates = np . array ( list ( zip ( gdf_jobs . geometry . x , gdf_jobs . geometry . y ))) # Construct a BallTree for efficient spatial queries ball_tree = BallTree ( coordinates ) # Define an inner function to perform spatial queries and calculate job density def job_density ( point ): \"\"\" Compute job density for a given point by querying nearby jobs within the specified radius. Parameters: - point (tuple): A tuple representing the x and y coordinates of the point. Returns: - float: Job density for the given point. \"\"\" # Get the indices of points within the given radius using the BallTree indices = ball_tree . query_radius ([ point ], r = radius , return_distance = False )[ 0 ] # Sum up the jobs for the queried points to compute the density return gdf_jobs . iloc [ indices ][ 'jobs' ] . sum () # Compute job densities for each point in the GeoDataFrame gdf_jobs [ 'job_density' ] = [ job_density ( point ) for point in coordinates ] return gdf_jobs compute_preferred_locations ( add_proposed_locations = False ) TODO This can be made faster by grouping buildings into chunks of 200x200m and assigning them together. Computes and assigns preferred locations for each building instance based on their coordinates. For each building in the list of instances, this function: 1. Determines the building's coordinate. 2. Finds the closest general locations to that coordinate. 3. Finds the closest grocery locations to that coordinate. 4. Merges the two lists of locations. 5. Initializes a PreferredLocations object using the combined locations. 6. Assigns the PreferredLocations object to the building's preferred_locations attribute. Source code in tripsender\\location_assignment.py 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 def compute_preferred_locations ( add_proposed_locations = False ): \"\"\" #TODO This can be made faster by grouping buildings into chunks of 200x200m and assigning them together. Computes and assigns preferred locations for each building instance based on their coordinates. For each building in the list of instances, this function: 1. Determines the building's coordinate. 2. Finds the closest general locations to that coordinate. 3. Finds the closest grocery locations to that coordinate. 4. Merges the two lists of locations. 5. Initializes a PreferredLocations object using the combined locations. 6. Assigns the PreferredLocations object to the building's preferred_locations attribute. \"\"\" logger . info ( \"Computing preferred locations...\" ) gdf_amenities = gpd . read_file ( ALL_AMENITIES_PATH ) if add_proposed_locations : # Check if the proposed amenities file exists if os . path . exists ( PROPOSED_AMENITIES_PATH ): # Load the proposed amenities GeoJSON file gdf_proposed_amenities = gpd . read_file ( PROPOSED_AMENITIES_PATH ) if len ( gdf_proposed_amenities ) > 0 : logger . info ( \"Proposed amenities file found. Combining amenities for location assignment\" ) # Set the CRS for the proposed amenities GeoDataFrame gdf_proposed_amenities . set_crs ( epsg = 3006 , inplace = True , allow_override = True ) # Concatenate the existing and proposed amenities into one GeoDataFrame gdf_amenities = pd . concat ([ gdf_amenities , gdf_proposed_amenities ], ignore_index = True ) logger . info ( gdf_proposed_amenities . activity . value_counts ()) else : logger . info ( \"Proposed amenities are empty or no proposed amenities file found. Proceeding with location assignment\" ) # Initialize the LocationFinder object outside the loop # (since it probably doesn't need to be re-initialized for each building). location_finder = LocationFinder ( gdf_amenities ) # Loop through all the building instances for building in Building . instances : # Extract the coordinate (centroid) of the building origin = building . coord # Find the closest general locations to the building's coordinate locations = location_finder . find_closest_locations ( origin ) # Find the closest grocery locations to the building's coordinate grocery_locations = location_finder . find_closest_grocery_locations ( origin ) # Initialize a PreferredLocations object using the combined lists of locations preferred_locations = PreferredLocations ( locations + grocery_locations ) preferred_locations . origin = origin # Assign the generated PreferredLocations object to the building's attribute building . preferred_locations = preferred_locations logger . info ( f \"Preferred locations computed for { len ( Building . instances ) } buildings.\" ) gravity_model_simulation ( gdf_homes , gdf_jobs , density_weight = 0.5 , distance_decay = 2.5 , plot = True ) Simulate job attraction based on the gravity model. The gravity model is a spatial interaction model that suggests that interaction between two places (for example, the number of people that commute from one place to another for work) is proportional to the product of the population of the two places and inversely proportional to the square of the distance between them. Parameters: - gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It must have 'footprint' and 'workers' columns. - gdf_jobs (GeoDataFrame): A GeoDataFrame containing job location data. It must have a 'job_density' column. - density_weight (float): The weight to apply to job density in the attraction calculation. Default is 1. - distance_decay (float): The power to which distance is raised in the attraction calculation. Default is 2. - plot (bool): Whether or not to plot the results. Default is True. Returns: - gdf_worker_jobs (GeoDataFrame): A GeoDataFrame representing the relationship between homes and potential job locations. To skew the attraction towards job density - increase the density_weight. To skew the attraction towards distance - increase the distance_decay. Source code in tripsender\\location_assignment.py 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def gravity_model_simulation ( gdf_homes , gdf_jobs , density_weight = 0.5 , distance_decay = 2.5 , plot = True ): \"\"\" Simulate job attraction based on the gravity model. The gravity model is a spatial interaction model that suggests that interaction between two places (for example, the number of people that commute from one place to another for work) is proportional to the product of the population of the two places and inversely proportional to the square of the distance between them. Parameters: - gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It must have 'footprint' and 'workers' columns. - gdf_jobs (GeoDataFrame): A GeoDataFrame containing job location data. It must have a 'job_density' column. - density_weight (float): The weight to apply to job density in the attraction calculation. Default is 1. - distance_decay (float): The power to which distance is raised in the attraction calculation. Default is 2. - plot (bool): Whether or not to plot the results. Default is True. Returns: - gdf_worker_jobs (GeoDataFrame): A GeoDataFrame representing the relationship between homes and potential job locations. To skew the attraction towards job density - increase the density_weight. To skew the attraction towards distance - increase the distance_decay. \"\"\" # 1. Calculate Distance Matrix # Extracting the coordinates of home and job centroids homes_coords = gdf_homes . footprint . centroid . apply ( lambda geom : ( geom . x , geom . y )) . tolist () jobs_coords = gdf_jobs . centroid . apply ( lambda geom : ( geom . x , geom . y )) . tolist () # Computing the distance matrix distance_matrix = pairwise_distances ( homes_coords , jobs_coords , metric = \"euclidean\" ) # 2. Gravity Model Calculation # Compute attraction based on job density and distance decay attraction_matrix = ( gdf_jobs [ 'job_density' ] . values ** density_weight ) / ( distance_matrix ** distance_decay ) def get_job_locations ( row_index , n_jobs ): \"\"\" For each home, get the most attractive job locations based on the gravity model. Parameters: - row_index (int): The index of the home row. - n_jobs (int): The number of jobs associated with the home. Returns: - list: A list of the most attractive job locations' centroids. \"\"\" # Getting the indices of job locations with the highest attraction top_jobs_indices = np . argsort ( attraction_matrix [ row_index ])[ - n_jobs :] unique_jobs = set () # Picking the top n_jobs from the list for idx in reversed ( top_jobs_indices ): if len ( unique_jobs ) < n_jobs : unique_jobs . add ( idx ) return gdf_jobs . iloc [ list ( unique_jobs )][ 'centroid' ] . tolist () # Assign potential job locations for each home based on number of workers and attraction gdf_homes [ 'potential_jobs' ] = [ get_job_locations ( idx , int ( workers )) for idx , workers in enumerate ( gdf_homes [ 'workers' ])] logger . info ( \"Assigning jobs to workers...\" ) # Assign job locations to workers assign_jobs_to_workers ( gdf_homes ) # Data aggregation # Constructing the resultant data data = [] for _ , home_row in gdf_homes . iterrows (): home_footprint = home_row . footprint home_centroid = home_row . footprint . centroid for job_point in home_row [ 'potential_jobs' ]: data . append ({ 'home_footprint' : home_footprint , 'home_centroid' : home_centroid , 'worker' : 1 , 'job_location' : job_point }) # Convert the list of dictionaries to a DataFrame and then to a GeoDataFrame df = pd . DataFrame ( data ) gdf_worker_jobs = gpd . GeoDataFrame ( df , geometry = 'job_location' , crs = gdf_homes . crs ) if plot : # Visualize the result fig , ax = plt . subplots ( figsize = ( 10 , 10 )) gpd . GeoSeries ( gdf_worker_jobs [ 'home_footprint' ]) . plot ( ax = ax , color = 'grey' , alpha = 0.5 ) gpd . GeoSeries ( gdf_worker_jobs [ 'home_centroid' ]) . plot ( ax = ax , color = 'red' , markersize = 1 ) gpd . GeoSeries ( gdf_worker_jobs [ 'job_location' ]) . plot ( ax = ax , color = 'blue' , markersize = 1 ) plt . show () return gdf_worker_jobs","title":"location_assignment"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder","text":"LocationFinder class helps in finding locations based on the given GeoDataFrame and location counts. This class uses BallTree data structure to efficiently query nearby locations. Different types of locations (like schools, playgrounds, healthcare, etc.) can be associated with different default counts to prioritize their significance. Source code in tripsender\\location_assignment.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 class LocationFinder : \"\"\" LocationFinder class helps in finding locations based on the given GeoDataFrame and location counts. This class uses BallTree data structure to efficiently query nearby locations. Different types of locations (like schools, playgrounds, healthcare, etc.) can be associated with different default counts to prioritize their significance. \"\"\" def __init__ ( self , gdf , location_counts = None ): \"\"\" Initialize the LocationFinder with a given GeoDataFrame and optional location counts. Parameters: - gdf (GeoDataFrame): The input GeoDataFrame containing location data. - location_counts (dict, optional): A dictionary specifying the counts for different location types. \"\"\" self . gdf = gdf self . ball_trees = {} # Dictionary to store BallTrees for different location types count_multiple = 3 # A multiplier for location counts # Default counts for various location types if none are provided self . default_location_counts = { \"EDUCATION_f\u00f6rskola\" : 1 , \"EDUCATION_f\u00f6rskoleklass\" : 1 , \"EDUCATION_grundskola\" : 1 , \"EDUCATION_gymnasieskola\" : 1 , \"EDUCATION_fritidshem\" : 1 , \"LEISURE_sports\" : count_multiple , \"LEISURE_playground\" : count_multiple , \"EDUCATION\" : count_multiple , \"SHOPPING_OTHER\" : count_multiple , # \"SHOPPING_GROCERY\" is handled separately \"LEISURE\" : count_multiple , \"HEALTHCARE\" : count_multiple } # If custom location counts are provided, update the default counts if location_counts : self . default_location_counts . update ( location_counts ) self . populate_ball_trees () # Create BallTrees for the location types self . set_grocery_data () # Handle grocery data separately (method implementation is not provided) def populate_ball_trees ( self ): \"\"\" Populate the BallTrees for the different location types based on the GeoDataFrame. This method creates a BallTree for each location type listed in default_location_counts, allowing for efficient spatial queries. The BallTree, along with the associated GeoDataFrame subset and its count, is stored in the ball_trees dictionary for each location type. \"\"\" # Iterate over each location type and its associated count for loc_type , count in self . default_location_counts . items (): # Filter the GeoDataFrame based on the current location type temp_gdf = self . gdf [ self . gdf [ 'activity' ] == loc_type ] # Extract the coordinates from the 'geometry' column of the filtered GeoDataFrame coords = [( point . x , point . y ) for point in temp_gdf [ 'geometry' ] . values ] # If there are coordinates (i.e., there are entries for this location type in the GeoDataFrame), # create a BallTree for them if coords : # Create a BallTree with the coordinates and use the euclidean metric for spatial queries tree = BallTree ( np . array ( coords ), metric = 'euclidean' ) # Store the BallTree, the subset of the GeoDataFrame, and the count in the ball_trees dictionary self . ball_trees [ loc_type ] = ( tree , temp_gdf , count ) def set_grocery_data ( self ): \"\"\" Initialize and set the grocery-related data attributes. This method extracts the data related to the \"SHOPPING_GROCERY\" activity from the main GeoDataFrame. It sets up the grocery GeoDataFrame, the coordinates of the grocery locations, and their associated areas. \"\"\" logger . info ( \"Setting up grocery data...\" ) # Filter the main GeoDataFrame to extract only the rows related to \"SHOPPING_GROCERY\" activity self . grocery_gdf = self . gdf [ self . gdf [ 'activity' ] == \"SHOPPING_GROCERY\" ] # Extract the x and y coordinates from the 'geometry' column of the grocery GeoDataFrame self . grocery_coords = [( point . x , point . y ) for point in self . grocery_gdf [ 'geometry' ] . values ] # Extract the 'area' values corresponding to each grocery location self . grocery_areas = self . grocery_gdf [ 'area' ] . values def find_closest_locations ( self , origin_point , k = None ): \"\"\" Find the closest locations to a given origin point for each location type. This method queries the BallTree for each location type to find the closest locations. The number of closest locations for each type is determined by the 'k' parameter or the default count associated with the location type. Parameters: - origin_point (Point): The origin point from which distances are measured. - k (int, optional): The number of closest locations to return for each location type. If not provided, the default count for each type is used. Returns: - results (list): A list containing Location objects for each of the closest locations. \"\"\" results = [] # List to store the resulting Location objects origin = ( origin_point . x , origin_point . y ) # Convert origin point to tuple format # Iterate over each location type and its associated BallTree, GeoDataFrame subset, and count for loc_type , ( tree , relevant_gdf , count ) in self . ball_trees . items (): #logger.info(f\"Fetching location for location type : {loc_type}\") # Determine the number of closest locations to query. Use provided k or default count. current_k = k if k is not None else count # Query the BallTree to find the closest locations distances , indices = tree . query ([ origin ], k = current_k ) # Extract location data from the relevant GeoDataFrame for each of the closest locations for distance , index in zip ( distances [ 0 ], indices [ 0 ]): closest_row = relevant_gdf . iloc [ index ] #logger.info(f\"Found a location for amenity {loc_type} : {closest_row['name']}, {distance}m away\") # Create a Location object and add it to the results list location = Location ( loc_type , closest_row [ 'name' ], closest_row [ 'geometry' ], closest_row [ 'amenity' ]) results . append ( location ) return results @staticmethod def gravity_score ( distance , area , alpha = 0 , beta = 2 ): \"\"\" Calculate the gravity-based score for a location based on its area and distance from an origin. The gravity model, used here, is a spatial interaction model which is based on the idea that the interaction between two places can be determined by the product of the size of one (or both) and divided by their separation distance raised to a power (distance decay). Parameters: - distance (float): The distance from the origin to the location. - area (float): The size (area) of the location. - alpha (float, optional): The exponent for the area (default is 1.5). - beta (float, optional): The exponent for the distance decay (default is 2). Returns: - float: The gravity score for the location. \"\"\" epsilon = 1e-10 # Small constant to prevent division by zero # Calculate the gravity score using the formula: (area^alpha) / (distance + epsilon)^beta return 1 / (( distance + epsilon ) ** beta ) def find_closest_grocery_locations ( self , origin_point , k = 2 ): \"\"\" Find the closest grocery locations to a given origin point based on a gravity-based scoring system. This method first computes the euclidean distance between the origin point and each grocery location. It then calculates a gravity-based score for each grocery location using the gravity_score method. The top 'k' grocery locations with the highest gravity scores are returned. Parameters: - origin_point (Point): The origin point from which distances and scores are calculated. - k (int, optional): The number of top-scoring grocery locations to return (default is 3). Returns: - results (list): A list containing Location objects for each of the top 'k' grocery locations. \"\"\" # Convert the origin point to a list format [x, y] origin = [ origin_point . x , origin_point . y ] # Calculate the pairwise euclidean distances between the origin and each grocery location dist_metric = DistanceMetric . get_metric ( 'euclidean' ) distances = dist_metric . pairwise ([ origin ], self . grocery_coords ) . flatten () areas = self . grocery_areas # Get the areas of the grocery locations # Set all areas to 1 to neutralize their effect areas = [ 1 ] * len ( distances ) # Assuming there is one area value for each distance calculated # Compute gravity scores for each grocery location scores = [ self . gravity_score ( dist , area ) for dist , area in zip ( distances , areas )] # Get the indices of the top 'k' grocery locations based on the gravity scores top_indices = sorted ( range ( len ( scores )), key = lambda i : scores [ i ], reverse = True )[: k ] results = [] # List to store the resulting Location objects # Extract location data from the grocery GeoDataFrame for each of the top 'k' locations for index in top_indices : row = self . grocery_gdf . iloc [ index ] # Create a Location object and add it to the results list location = Location ( \"SHOPPING_GROCERY\" , row [ 'name' ], row [ 'geometry' ], row [ 'amenity' ]) results . append ( location ) return results","title":"LocationFinder"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder.__init__","text":"Initialize the LocationFinder with a given GeoDataFrame and optional location counts. Parameters: - gdf (GeoDataFrame): The input GeoDataFrame containing location data. - location_counts (dict, optional): A dictionary specifying the counts for different location types. Source code in tripsender\\location_assignment.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def __init__ ( self , gdf , location_counts = None ): \"\"\" Initialize the LocationFinder with a given GeoDataFrame and optional location counts. Parameters: - gdf (GeoDataFrame): The input GeoDataFrame containing location data. - location_counts (dict, optional): A dictionary specifying the counts for different location types. \"\"\" self . gdf = gdf self . ball_trees = {} # Dictionary to store BallTrees for different location types count_multiple = 3 # A multiplier for location counts # Default counts for various location types if none are provided self . default_location_counts = { \"EDUCATION_f\u00f6rskola\" : 1 , \"EDUCATION_f\u00f6rskoleklass\" : 1 , \"EDUCATION_grundskola\" : 1 , \"EDUCATION_gymnasieskola\" : 1 , \"EDUCATION_fritidshem\" : 1 , \"LEISURE_sports\" : count_multiple , \"LEISURE_playground\" : count_multiple , \"EDUCATION\" : count_multiple , \"SHOPPING_OTHER\" : count_multiple , # \"SHOPPING_GROCERY\" is handled separately \"LEISURE\" : count_multiple , \"HEALTHCARE\" : count_multiple } # If custom location counts are provided, update the default counts if location_counts : self . default_location_counts . update ( location_counts ) self . populate_ball_trees () # Create BallTrees for the location types self . set_grocery_data () # Handle grocery data separately (method implementation is not provided)","title":"__init__"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder.find_closest_grocery_locations","text":"Find the closest grocery locations to a given origin point based on a gravity-based scoring system. This method first computes the euclidean distance between the origin point and each grocery location. It then calculates a gravity-based score for each grocery location using the gravity_score method. The top 'k' grocery locations with the highest gravity scores are returned. Parameters: - origin_point (Point): The origin point from which distances and scores are calculated. - k (int, optional): The number of top-scoring grocery locations to return (default is 3). Returns: - results (list): A list containing Location objects for each of the top 'k' grocery locations. Source code in tripsender\\location_assignment.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def find_closest_grocery_locations ( self , origin_point , k = 2 ): \"\"\" Find the closest grocery locations to a given origin point based on a gravity-based scoring system. This method first computes the euclidean distance between the origin point and each grocery location. It then calculates a gravity-based score for each grocery location using the gravity_score method. The top 'k' grocery locations with the highest gravity scores are returned. Parameters: - origin_point (Point): The origin point from which distances and scores are calculated. - k (int, optional): The number of top-scoring grocery locations to return (default is 3). Returns: - results (list): A list containing Location objects for each of the top 'k' grocery locations. \"\"\" # Convert the origin point to a list format [x, y] origin = [ origin_point . x , origin_point . y ] # Calculate the pairwise euclidean distances between the origin and each grocery location dist_metric = DistanceMetric . get_metric ( 'euclidean' ) distances = dist_metric . pairwise ([ origin ], self . grocery_coords ) . flatten () areas = self . grocery_areas # Get the areas of the grocery locations # Set all areas to 1 to neutralize their effect areas = [ 1 ] * len ( distances ) # Assuming there is one area value for each distance calculated # Compute gravity scores for each grocery location scores = [ self . gravity_score ( dist , area ) for dist , area in zip ( distances , areas )] # Get the indices of the top 'k' grocery locations based on the gravity scores top_indices = sorted ( range ( len ( scores )), key = lambda i : scores [ i ], reverse = True )[: k ] results = [] # List to store the resulting Location objects # Extract location data from the grocery GeoDataFrame for each of the top 'k' locations for index in top_indices : row = self . grocery_gdf . iloc [ index ] # Create a Location object and add it to the results list location = Location ( \"SHOPPING_GROCERY\" , row [ 'name' ], row [ 'geometry' ], row [ 'amenity' ]) results . append ( location ) return results","title":"find_closest_grocery_locations"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder.find_closest_locations","text":"Find the closest locations to a given origin point for each location type. This method queries the BallTree for each location type to find the closest locations. The number of closest locations for each type is determined by the 'k' parameter or the default count associated with the location type. Parameters: - origin_point (Point): The origin point from which distances are measured. - k (int, optional): The number of closest locations to return for each location type. If not provided, the default count for each type is used. Returns: - results (list): A list containing Location objects for each of the closest locations. Source code in tripsender\\location_assignment.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def find_closest_locations ( self , origin_point , k = None ): \"\"\" Find the closest locations to a given origin point for each location type. This method queries the BallTree for each location type to find the closest locations. The number of closest locations for each type is determined by the 'k' parameter or the default count associated with the location type. Parameters: - origin_point (Point): The origin point from which distances are measured. - k (int, optional): The number of closest locations to return for each location type. If not provided, the default count for each type is used. Returns: - results (list): A list containing Location objects for each of the closest locations. \"\"\" results = [] # List to store the resulting Location objects origin = ( origin_point . x , origin_point . y ) # Convert origin point to tuple format # Iterate over each location type and its associated BallTree, GeoDataFrame subset, and count for loc_type , ( tree , relevant_gdf , count ) in self . ball_trees . items (): #logger.info(f\"Fetching location for location type : {loc_type}\") # Determine the number of closest locations to query. Use provided k or default count. current_k = k if k is not None else count # Query the BallTree to find the closest locations distances , indices = tree . query ([ origin ], k = current_k ) # Extract location data from the relevant GeoDataFrame for each of the closest locations for distance , index in zip ( distances [ 0 ], indices [ 0 ]): closest_row = relevant_gdf . iloc [ index ] #logger.info(f\"Found a location for amenity {loc_type} : {closest_row['name']}, {distance}m away\") # Create a Location object and add it to the results list location = Location ( loc_type , closest_row [ 'name' ], closest_row [ 'geometry' ], closest_row [ 'amenity' ]) results . append ( location ) return results","title":"find_closest_locations"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder.gravity_score","text":"Calculate the gravity-based score for a location based on its area and distance from an origin. The gravity model, used here, is a spatial interaction model which is based on the idea that the interaction between two places can be determined by the product of the size of one (or both) and divided by their separation distance raised to a power (distance decay). Parameters: - distance (float): The distance from the origin to the location. - area (float): The size (area) of the location. - alpha (float, optional): The exponent for the area (default is 1.5). - beta (float, optional): The exponent for the distance decay (default is 2). Returns: - float: The gravity score for the location. Source code in tripsender\\location_assignment.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 @staticmethod def gravity_score ( distance , area , alpha = 0 , beta = 2 ): \"\"\" Calculate the gravity-based score for a location based on its area and distance from an origin. The gravity model, used here, is a spatial interaction model which is based on the idea that the interaction between two places can be determined by the product of the size of one (or both) and divided by their separation distance raised to a power (distance decay). Parameters: - distance (float): The distance from the origin to the location. - area (float): The size (area) of the location. - alpha (float, optional): The exponent for the area (default is 1.5). - beta (float, optional): The exponent for the distance decay (default is 2). Returns: - float: The gravity score for the location. \"\"\" epsilon = 1e-10 # Small constant to prevent division by zero # Calculate the gravity score using the formula: (area^alpha) / (distance + epsilon)^beta return 1 / (( distance + epsilon ) ** beta )","title":"gravity_score"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder.populate_ball_trees","text":"Populate the BallTrees for the different location types based on the GeoDataFrame. This method creates a BallTree for each location type listed in default_location_counts, allowing for efficient spatial queries. The BallTree, along with the associated GeoDataFrame subset and its count, is stored in the ball_trees dictionary for each location type. Source code in tripsender\\location_assignment.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def populate_ball_trees ( self ): \"\"\" Populate the BallTrees for the different location types based on the GeoDataFrame. This method creates a BallTree for each location type listed in default_location_counts, allowing for efficient spatial queries. The BallTree, along with the associated GeoDataFrame subset and its count, is stored in the ball_trees dictionary for each location type. \"\"\" # Iterate over each location type and its associated count for loc_type , count in self . default_location_counts . items (): # Filter the GeoDataFrame based on the current location type temp_gdf = self . gdf [ self . gdf [ 'activity' ] == loc_type ] # Extract the coordinates from the 'geometry' column of the filtered GeoDataFrame coords = [( point . x , point . y ) for point in temp_gdf [ 'geometry' ] . values ] # If there are coordinates (i.e., there are entries for this location type in the GeoDataFrame), # create a BallTree for them if coords : # Create a BallTree with the coordinates and use the euclidean metric for spatial queries tree = BallTree ( np . array ( coords ), metric = 'euclidean' ) # Store the BallTree, the subset of the GeoDataFrame, and the count in the ball_trees dictionary self . ball_trees [ loc_type ] = ( tree , temp_gdf , count )","title":"populate_ball_trees"},{"location":"location_assignment/#tripsender.location_assignment.LocationFinder.set_grocery_data","text":"Initialize and set the grocery-related data attributes. This method extracts the data related to the \"SHOPPING_GROCERY\" activity from the main GeoDataFrame. It sets up the grocery GeoDataFrame, the coordinates of the grocery locations, and their associated areas. Source code in tripsender\\location_assignment.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def set_grocery_data ( self ): \"\"\" Initialize and set the grocery-related data attributes. This method extracts the data related to the \"SHOPPING_GROCERY\" activity from the main GeoDataFrame. It sets up the grocery GeoDataFrame, the coordinates of the grocery locations, and their associated areas. \"\"\" logger . info ( \"Setting up grocery data...\" ) # Filter the main GeoDataFrame to extract only the rows related to \"SHOPPING_GROCERY\" activity self . grocery_gdf = self . gdf [ self . gdf [ 'activity' ] == \"SHOPPING_GROCERY\" ] # Extract the x and y coordinates from the 'geometry' column of the grocery GeoDataFrame self . grocery_coords = [( point . x , point . y ) for point in self . grocery_gdf [ 'geometry' ] . values ] # Extract the 'area' values corresponding to each grocery location self . grocery_areas = self . grocery_gdf [ 'area' ] . values","title":"set_grocery_data"},{"location":"location_assignment/#tripsender.location_assignment.assign_jobs_to_workers","text":"Assign job locations to workers residing in the buildings of gdf_homes. For each building in the GeoDataFrame, the function takes the potential job locations and assigns these to every worker residing in that building. gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It should have 'building' and 'potential_jobs' columns, where 'building' objects have a 'worker_list' attribute, and each worker in this list has a 'work_location' attribute. Returns: - None: The function modifies the 'work_location' attribute of each worker in-place. Source code in tripsender\\location_assignment.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 def assign_jobs_to_workers ( gdf_homes ): \"\"\" Assign job locations to workers residing in the buildings of gdf_homes. For each building in the GeoDataFrame, the function takes the potential job locations and assigns these to every worker residing in that building. Parameters: - gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It should have 'building' and 'potential_jobs' columns, where 'building' objects have a 'worker_list' attribute, and each worker in this list has a 'work_location' attribute. Returns: - None: The function modifies the 'work_location' attribute of each worker in-place. \"\"\" # Go through each row of the GeoDataFrame for _ , row in gdf_homes . iterrows (): building = row [ 'building' ] # Retrieve the building object job_locations = row [ 'potential_jobs' ] # Retrieve the potential job locations for this building # Iterate over each worker in the building for worker , job_point in zip ( building . worker_list , job_locations ): # Assign the job location to the worker's work_location attribute job_location = Location ( \"WORK\" , \"Work\" , job_point , \"WORK\" ) worker . work_location = job_location","title":"assign_jobs_to_workers"},{"location":"location_assignment/#tripsender.location_assignment.assign_workers_to_buildings","text":"Assigns workers to buildings based on their primary status. Source code in tripsender\\location_assignment.py 478 479 480 481 482 483 484 485 486 487 488 489 490 491 def assign_workers_to_buildings (): \"\"\" Assigns workers to buildings based on their primary status. \"\"\" # Add workers to buildings for building in Building . instances : houses = building . houses for house in houses : household = house . household for member in household . members : # Workers is a list of workers with primary_status = \"WORK\" if member . primary_status == \"WORK\" : building . workers += 1 building . worker_list . append ( member )","title":"assign_workers_to_buildings"},{"location":"location_assignment/#tripsender.location_assignment.compute_job_density","text":"Computes job densities for each point in the GeoDataFrame using the given radius. The function loads a shapefile, calculates the centroid for each geometry and then computes the job density around each centroid using a given radius. The BallTree data structure is utilized for efficient spatial queries. Parameters: - file_path (str): Path to the shapefile. - radius (float): Radius in meters for which job density is calculated. Default is 1000 meters. Returns: - gdf_jobs (GeoDataFrame): Updated GeoDataFrame with job densities. Source code in tripsender\\location_assignment.py 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 def compute_job_density ( file_path , radius = 1000 ): \"\"\" Computes job densities for each point in the GeoDataFrame using the given radius. The function loads a shapefile, calculates the centroid for each geometry and then computes the job density around each centroid using a given radius. The BallTree data structure is utilized for efficient spatial queries. Parameters: - file_path (str): Path to the shapefile. - radius (float): Radius in meters for which job density is calculated. Default is 1000 meters. Returns: - gdf_jobs (GeoDataFrame): Updated GeoDataFrame with job densities. \"\"\" logger . info ( \"Computing job densities...\" ) # Load data from the shapefile gdf = gpd . read_file ( file_path ) # Compute centroids for each geometry in the GeoDataFrame gdf [ 'centroid' ] = gdf [ 'geometry' ] . centroid # Create a new GeoDataFrame with only the 'jobs' column and the computed centroids # Set the 'centroid' column as the geometry for this new GeoDataFrame gdf_jobs = gdf [[ 'jobs' , 'centroid' ]] . copy () gdf_jobs = gdf_jobs . set_geometry ( 'centroid' ) # Convert the GeoDataFrame's point geometries to a matrix format suitable for BallTree coordinates = np . array ( list ( zip ( gdf_jobs . geometry . x , gdf_jobs . geometry . y ))) # Construct a BallTree for efficient spatial queries ball_tree = BallTree ( coordinates ) # Define an inner function to perform spatial queries and calculate job density def job_density ( point ): \"\"\" Compute job density for a given point by querying nearby jobs within the specified radius. Parameters: - point (tuple): A tuple representing the x and y coordinates of the point. Returns: - float: Job density for the given point. \"\"\" # Get the indices of points within the given radius using the BallTree indices = ball_tree . query_radius ([ point ], r = radius , return_distance = False )[ 0 ] # Sum up the jobs for the queried points to compute the density return gdf_jobs . iloc [ indices ][ 'jobs' ] . sum () # Compute job densities for each point in the GeoDataFrame gdf_jobs [ 'job_density' ] = [ job_density ( point ) for point in coordinates ] return gdf_jobs","title":"compute_job_density"},{"location":"location_assignment/#tripsender.location_assignment.compute_preferred_locations","text":"","title":"compute_preferred_locations"},{"location":"location_assignment/#tripsender.location_assignment.compute_preferred_locations--todo-this-can-be-made-faster-by-grouping-buildings-into-chunks-of-200x200m-and-assigning-them-together","text":"Computes and assigns preferred locations for each building instance based on their coordinates. For each building in the list of instances, this function: 1. Determines the building's coordinate. 2. Finds the closest general locations to that coordinate. 3. Finds the closest grocery locations to that coordinate. 4. Merges the two lists of locations. 5. Initializes a PreferredLocations object using the combined locations. 6. Assigns the PreferredLocations object to the building's preferred_locations attribute. Source code in tripsender\\location_assignment.py 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 def compute_preferred_locations ( add_proposed_locations = False ): \"\"\" #TODO This can be made faster by grouping buildings into chunks of 200x200m and assigning them together. Computes and assigns preferred locations for each building instance based on their coordinates. For each building in the list of instances, this function: 1. Determines the building's coordinate. 2. Finds the closest general locations to that coordinate. 3. Finds the closest grocery locations to that coordinate. 4. Merges the two lists of locations. 5. Initializes a PreferredLocations object using the combined locations. 6. Assigns the PreferredLocations object to the building's preferred_locations attribute. \"\"\" logger . info ( \"Computing preferred locations...\" ) gdf_amenities = gpd . read_file ( ALL_AMENITIES_PATH ) if add_proposed_locations : # Check if the proposed amenities file exists if os . path . exists ( PROPOSED_AMENITIES_PATH ): # Load the proposed amenities GeoJSON file gdf_proposed_amenities = gpd . read_file ( PROPOSED_AMENITIES_PATH ) if len ( gdf_proposed_amenities ) > 0 : logger . info ( \"Proposed amenities file found. Combining amenities for location assignment\" ) # Set the CRS for the proposed amenities GeoDataFrame gdf_proposed_amenities . set_crs ( epsg = 3006 , inplace = True , allow_override = True ) # Concatenate the existing and proposed amenities into one GeoDataFrame gdf_amenities = pd . concat ([ gdf_amenities , gdf_proposed_amenities ], ignore_index = True ) logger . info ( gdf_proposed_amenities . activity . value_counts ()) else : logger . info ( \"Proposed amenities are empty or no proposed amenities file found. Proceeding with location assignment\" ) # Initialize the LocationFinder object outside the loop # (since it probably doesn't need to be re-initialized for each building). location_finder = LocationFinder ( gdf_amenities ) # Loop through all the building instances for building in Building . instances : # Extract the coordinate (centroid) of the building origin = building . coord # Find the closest general locations to the building's coordinate locations = location_finder . find_closest_locations ( origin ) # Find the closest grocery locations to the building's coordinate grocery_locations = location_finder . find_closest_grocery_locations ( origin ) # Initialize a PreferredLocations object using the combined lists of locations preferred_locations = PreferredLocations ( locations + grocery_locations ) preferred_locations . origin = origin # Assign the generated PreferredLocations object to the building's attribute building . preferred_locations = preferred_locations logger . info ( f \"Preferred locations computed for { len ( Building . instances ) } buildings.\" )","title":"TODO This can be made faster by grouping buildings into chunks of 200x200m and assigning them together."},{"location":"location_assignment/#tripsender.location_assignment.gravity_model_simulation","text":"Simulate job attraction based on the gravity model. The gravity model is a spatial interaction model that suggests that interaction between two places (for example, the number of people that commute from one place to another for work) is proportional to the product of the population of the two places and inversely proportional to the square of the distance between them. Parameters: - gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It must have 'footprint' and 'workers' columns. - gdf_jobs (GeoDataFrame): A GeoDataFrame containing job location data. It must have a 'job_density' column. - density_weight (float): The weight to apply to job density in the attraction calculation. Default is 1. - distance_decay (float): The power to which distance is raised in the attraction calculation. Default is 2. - plot (bool): Whether or not to plot the results. Default is True. Returns: - gdf_worker_jobs (GeoDataFrame): A GeoDataFrame representing the relationship between homes and potential job locations. To skew the attraction towards job density - increase the density_weight. To skew the attraction towards distance - increase the distance_decay. Source code in tripsender\\location_assignment.py 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def gravity_model_simulation ( gdf_homes , gdf_jobs , density_weight = 0.5 , distance_decay = 2.5 , plot = True ): \"\"\" Simulate job attraction based on the gravity model. The gravity model is a spatial interaction model that suggests that interaction between two places (for example, the number of people that commute from one place to another for work) is proportional to the product of the population of the two places and inversely proportional to the square of the distance between them. Parameters: - gdf_homes (GeoDataFrame): A GeoDataFrame containing home data. It must have 'footprint' and 'workers' columns. - gdf_jobs (GeoDataFrame): A GeoDataFrame containing job location data. It must have a 'job_density' column. - density_weight (float): The weight to apply to job density in the attraction calculation. Default is 1. - distance_decay (float): The power to which distance is raised in the attraction calculation. Default is 2. - plot (bool): Whether or not to plot the results. Default is True. Returns: - gdf_worker_jobs (GeoDataFrame): A GeoDataFrame representing the relationship between homes and potential job locations. To skew the attraction towards job density - increase the density_weight. To skew the attraction towards distance - increase the distance_decay. \"\"\" # 1. Calculate Distance Matrix # Extracting the coordinates of home and job centroids homes_coords = gdf_homes . footprint . centroid . apply ( lambda geom : ( geom . x , geom . y )) . tolist () jobs_coords = gdf_jobs . centroid . apply ( lambda geom : ( geom . x , geom . y )) . tolist () # Computing the distance matrix distance_matrix = pairwise_distances ( homes_coords , jobs_coords , metric = \"euclidean\" ) # 2. Gravity Model Calculation # Compute attraction based on job density and distance decay attraction_matrix = ( gdf_jobs [ 'job_density' ] . values ** density_weight ) / ( distance_matrix ** distance_decay ) def get_job_locations ( row_index , n_jobs ): \"\"\" For each home, get the most attractive job locations based on the gravity model. Parameters: - row_index (int): The index of the home row. - n_jobs (int): The number of jobs associated with the home. Returns: - list: A list of the most attractive job locations' centroids. \"\"\" # Getting the indices of job locations with the highest attraction top_jobs_indices = np . argsort ( attraction_matrix [ row_index ])[ - n_jobs :] unique_jobs = set () # Picking the top n_jobs from the list for idx in reversed ( top_jobs_indices ): if len ( unique_jobs ) < n_jobs : unique_jobs . add ( idx ) return gdf_jobs . iloc [ list ( unique_jobs )][ 'centroid' ] . tolist () # Assign potential job locations for each home based on number of workers and attraction gdf_homes [ 'potential_jobs' ] = [ get_job_locations ( idx , int ( workers )) for idx , workers in enumerate ( gdf_homes [ 'workers' ])] logger . info ( \"Assigning jobs to workers...\" ) # Assign job locations to workers assign_jobs_to_workers ( gdf_homes ) # Data aggregation # Constructing the resultant data data = [] for _ , home_row in gdf_homes . iterrows (): home_footprint = home_row . footprint home_centroid = home_row . footprint . centroid for job_point in home_row [ 'potential_jobs' ]: data . append ({ 'home_footprint' : home_footprint , 'home_centroid' : home_centroid , 'worker' : 1 , 'job_location' : job_point }) # Convert the list of dictionaries to a DataFrame and then to a GeoDataFrame df = pd . DataFrame ( data ) gdf_worker_jobs = gpd . GeoDataFrame ( df , geometry = 'job_location' , crs = gdf_homes . crs ) if plot : # Visualize the result fig , ax = plt . subplots ( figsize = ( 10 , 10 )) gpd . GeoSeries ( gdf_worker_jobs [ 'home_footprint' ]) . plot ( ax = ax , color = 'grey' , alpha = 0.5 ) gpd . GeoSeries ( gdf_worker_jobs [ 'home_centroid' ]) . plot ( ax = ax , color = 'red' , markersize = 1 ) gpd . GeoSeries ( gdf_worker_jobs [ 'job_location' ]) . plot ( ax = ax , color = 'blue' , markersize = 1 ) plt . show () return gdf_worker_jobs","title":"gravity_model_simulation"},{"location":"logconfig/","text":"Timer A simple timer class for profiling. Source code in tripsender\\logconfig.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class Timer : \"\"\" A simple timer class for profiling. \"\"\" def __init__ ( self ): self . start_time = None def start ( self , enable_profiling ): if enable_profiling : self . start_time = time . time () def end ( self , function_name , enable_profiling ): if enable_profiling : end_time = time . time () elapsed_time = end_time - self . start_time logger . info ( \" \\n {} took \\n {:.4f} ms to complete\" . format ( function_name , round ( elapsed_time * 1000 , 4 )))","title":"Logconfig"},{"location":"logconfig/#tripsender.logconfig.Timer","text":"A simple timer class for profiling. Source code in tripsender\\logconfig.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class Timer : \"\"\" A simple timer class for profiling. \"\"\" def __init__ ( self ): self . start_time = None def start ( self , enable_profiling ): if enable_profiling : self . start_time = time . time () def end ( self , function_name , enable_profiling ): if enable_profiling : end_time = time . time () elapsed_time = end_time - self . start_time logger . info ( \" \\n {} took \\n {:.4f} ms to complete\" . format ( function_name , round ( elapsed_time * 1000 , 4 )))","title":"Timer"},{"location":"main/","text":"","title":"Main"},{"location":"modes/","text":"","title":"Modes"},{"location":"nhts/","text":"preprocess_data ( df , variables_of_interest = variables_of_interest , weekday = True , unique_trips_only = False , process_durations = False ) Preprocess the NHTS data. Parameters: Name Type Description Default df DataFrame The input dataframe containing NHTS data. required variables_of_interest dict A dictionary specifying the variables of interest and their types (categorical, numerical, time). variables_of_interest weekday bool If True, processes data for weekdays; if False, processes data for weekends. Defaults to True. True unique_trips_only bool If True, removes duplicate trips based on id, start_time, and end_time. Defaults to False. False process_durations bool If True, processes the durations of activities and travels. Defaults to False. False Returns: Type Description pd.DataFrame: The preprocessed dataframe. Notes The function replaces specific values indicating no data with NaN and drops rows with NaN values. It filters the dataframe to include only the specified variables of interest. The function processes categorical, numerical, and time variables according to their specified types. It renames columns to standardize names and drops certain columns not needed for further analysis. If unique_trips_only is True, duplicate trips are removed. If process_durations is True, the function calculates the travel and activity durations. Examples: >>> variables_of_interest = { ... 'K\u00f6n' : { 'type' : 'categorical' , 'categories' : { 1 : 'Male' , 2 : 'Female' }}, ... '\u00c5ldersgrupp' : { 'type' : 'categorical' , 'categories' : { 1 : '0-17' , 2 : '18-34' , 3 : '35-64' , 4 : '65+' }}, ... 'Starttid' : { 'type' : 'time' }, ... 'Sluttid' : { 'type' : 'time' }, ... 'Resl\u00e4ngd' : { 'type' : 'numerical' }, ... # additional variables... ... } >>> df = preprocess_data ( df , variables_of_interest , weekday = True , unique_trips_only = True , process_durations = True ) Source code in tripsender\\nhts.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def preprocess_data ( df , variables_of_interest = variables_of_interest , weekday = True , unique_trips_only = False , process_durations = False ): \"\"\" Preprocess the NHTS data. Args: df (pd.DataFrame): The input dataframe containing NHTS data. variables_of_interest (dict): A dictionary specifying the variables of interest and their types (categorical, numerical, time). weekday (bool): If True, processes data for weekdays; if False, processes data for weekends. Defaults to True. unique_trips_only (bool): If True, removes duplicate trips based on id, start_time, and end_time. Defaults to False. process_durations (bool): If True, processes the durations of activities and travels. Defaults to False. Returns: pd.DataFrame: The preprocessed dataframe. Notes: - The function replaces specific values indicating no data with NaN and drops rows with NaN values. - It filters the dataframe to include only the specified variables of interest. - The function processes categorical, numerical, and time variables according to their specified types. - It renames columns to standardize names and drops certain columns not needed for further analysis. - If `unique_trips_only` is True, duplicate trips are removed. - If `process_durations` is True, the function calculates the travel and activity durations. Examples: >>> variables_of_interest = { ... 'K\u00f6n': {'type': 'categorical', 'categories': {1: 'Male', 2: 'Female'}}, ... '\u00c5ldersgrupp': {'type': 'categorical', 'categories': {1: '0-17', 2: '18-34', 3: '35-64', 4: '65+'}}, ... 'Starttid': {'type': 'time'}, ... 'Sluttid': {'type': 'time'}, ... 'Resl\u00e4ngd': {'type': 'numerical'}, ... # additional variables... ... } >>> df = preprocess_data(df, variables_of_interest, weekday=True, unique_trips_only=True, process_durations=True) \"\"\" if weekday : wd = 1 else : wd = 2 # Replace ',' with '.' in 'Resl\u00e4ngd' df [ 'Resl\u00e4ngd' ] = df [ 'Resl\u00e4ngd' ] . str . replace ( ',' , '.' ) # Replace ',' with '.' in 'VIKT_individ' df [ 'VIKT_individ' ] = df [ 'VIKT_individ' ] . str . replace ( ',' , '.' ) # Filter df to only include variables of interest df = df [ list ( variables_of_interest . keys ())] . reset_index ( drop = True ) # Replace no data with NaN (-111, 99998, '', blank) df = df . replace ([ - 111 , 999998 , 99998 , '' , ' ' ], float ( 'NaN' )) # Drop rows with NaN df = df . dropna () . reset_index ( drop = True ) # Sort by age #VARDAG_HELG == 1 for weekday #VARDAG_HELG == 2 for weekend df = df [ df [ 'VARDAG_HELG' ] == wd ] . reset_index ( drop = True ) #Antal_resor_per_pers > 1 df = df [ df [ 'Antal_resor_per_pers' ] > 1 ] . reset_index ( drop = True ) #TODO - Remove entries for an LPNR with \"Home\" not the last trip #Arende == 8 not the last trip # Replace categorical values with strings for variable in variables_of_interest : if variables_of_interest [ variable ][ 'type' ] == 'categorical' : # Change data type to int df [ variable ] = df [ variable ] . astype ( float ) # Replace values with strings df [ variable ] = df [ variable ] . replace ( variables_of_interest [ variable ][ 'categories' ]) elif variables_of_interest [ variable ][ 'type' ] == 'numerical' : # Change data type to int df [ variable ] = df [ variable ] . astype ( float ) elif variables_of_interest [ variable ][ 'type' ] == 'time' : # Change data type to datetime with format HH:MM:SS df [ variable ] = pd . to_datetime ( df [ variable ], format = '%H:%M:%S' ) # Only show hour and minute #df[variable] = df[variable].dt.strftime('%H:%M') # Set year, month and day to Today from datetime df [ variable ] = df [ variable ] . apply ( lambda dt : dt . replace ( year = year , month = month , day = day )) # Rename columns - k\u00f6n to kon \u00c5lder to alder df = df . rename ( columns = { 'LPNR' : 'id' , 'K\u00f6n' : 'sex' , '\u00c5ldersgrupp' : 'age_group' , 'Bostadstyp' : 'house_type' , 'Hush\u00e5llstyp' : 'household_type' , 'Antal_barn' : 'child_count' , 'Antal_bilar' : 'car_count' , 'Antal_vuxna' : 'adult_count' , 'Starttid' : 'start_time' , 'Huvud_fm' : 'mode' , 'Sluttid' : 'end_time' , 'Resl\u00e4ngd' : 'distance_km' , 'Arende' : 'purpose' , 'VIKT_individ' : 'weight_individual' }) #Drop 'VARDAG_HELG' and 'Antal_resor_per_pers' df = df . drop ([ 'VARDAG_HELG' , 'Antal_resor_per_pers' ], axis = 1 ) df = df . sort_values ( by = [ 'id' , 'start_time' ]) # Create a column called activity_sequence which is the activity number starting from 0 for each id df [ 'activity_sequence' ] = df . groupby ( 'id' ) . cumcount () # create a column called duration of previous activity # This is the time between end_time of previous activity and start_time of current activity # If there is no previous activity, then duration is 0 # If there is no next activity, then duration is 0 # Sort dataframe based on id and activity_sequence df = df . sort_values ( by = [ 'id' , 'start_time' ]) if unique_trips_only : # Drop duplicates based on id, start_time and end_time df = df . drop_duplicates ( subset = [ 'id' , 'start_time' , 'end_time' ]) . reset_index ( drop = True ) if process_durations : # Create the necessary columns for the entire dataframe df [ 'travel_duration_minutes' ] = df [ 'end_time' ] - df [ 'start_time' ] # Shift the start times within each group df [ 'next_travel_start_time' ] = df . groupby ( 'id' )[ 'start_time' ] . shift ( - 1 ) # Calculate activity durations df [ 'activity_duration_minutes' ] = df [ 'next_travel_start_time' ] - df [ 'end_time' ] # Fill NaN values in 'next_travel_start_time' and 'activity_duration_minutes' if required df [ 'next_travel_start_time' ] = df [ 'next_travel_start_time' ] . fillna ( method = 'ffill' ) df [ 'activity_duration_minutes' ] = df [ 'activity_duration_minutes' ] . fillna ( pd . Timedelta ( seconds = 0 )) return df","title":"nhts"},{"location":"nhts/#tripsender.nhts.preprocess_data","text":"Preprocess the NHTS data. Parameters: Name Type Description Default df DataFrame The input dataframe containing NHTS data. required variables_of_interest dict A dictionary specifying the variables of interest and their types (categorical, numerical, time). variables_of_interest weekday bool If True, processes data for weekdays; if False, processes data for weekends. Defaults to True. True unique_trips_only bool If True, removes duplicate trips based on id, start_time, and end_time. Defaults to False. False process_durations bool If True, processes the durations of activities and travels. Defaults to False. False Returns: Type Description pd.DataFrame: The preprocessed dataframe. Notes The function replaces specific values indicating no data with NaN and drops rows with NaN values. It filters the dataframe to include only the specified variables of interest. The function processes categorical, numerical, and time variables according to their specified types. It renames columns to standardize names and drops certain columns not needed for further analysis. If unique_trips_only is True, duplicate trips are removed. If process_durations is True, the function calculates the travel and activity durations. Examples: >>> variables_of_interest = { ... 'K\u00f6n' : { 'type' : 'categorical' , 'categories' : { 1 : 'Male' , 2 : 'Female' }}, ... '\u00c5ldersgrupp' : { 'type' : 'categorical' , 'categories' : { 1 : '0-17' , 2 : '18-34' , 3 : '35-64' , 4 : '65+' }}, ... 'Starttid' : { 'type' : 'time' }, ... 'Sluttid' : { 'type' : 'time' }, ... 'Resl\u00e4ngd' : { 'type' : 'numerical' }, ... # additional variables... ... } >>> df = preprocess_data ( df , variables_of_interest , weekday = True , unique_trips_only = True , process_durations = True ) Source code in tripsender\\nhts.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def preprocess_data ( df , variables_of_interest = variables_of_interest , weekday = True , unique_trips_only = False , process_durations = False ): \"\"\" Preprocess the NHTS data. Args: df (pd.DataFrame): The input dataframe containing NHTS data. variables_of_interest (dict): A dictionary specifying the variables of interest and their types (categorical, numerical, time). weekday (bool): If True, processes data for weekdays; if False, processes data for weekends. Defaults to True. unique_trips_only (bool): If True, removes duplicate trips based on id, start_time, and end_time. Defaults to False. process_durations (bool): If True, processes the durations of activities and travels. Defaults to False. Returns: pd.DataFrame: The preprocessed dataframe. Notes: - The function replaces specific values indicating no data with NaN and drops rows with NaN values. - It filters the dataframe to include only the specified variables of interest. - The function processes categorical, numerical, and time variables according to their specified types. - It renames columns to standardize names and drops certain columns not needed for further analysis. - If `unique_trips_only` is True, duplicate trips are removed. - If `process_durations` is True, the function calculates the travel and activity durations. Examples: >>> variables_of_interest = { ... 'K\u00f6n': {'type': 'categorical', 'categories': {1: 'Male', 2: 'Female'}}, ... '\u00c5ldersgrupp': {'type': 'categorical', 'categories': {1: '0-17', 2: '18-34', 3: '35-64', 4: '65+'}}, ... 'Starttid': {'type': 'time'}, ... 'Sluttid': {'type': 'time'}, ... 'Resl\u00e4ngd': {'type': 'numerical'}, ... # additional variables... ... } >>> df = preprocess_data(df, variables_of_interest, weekday=True, unique_trips_only=True, process_durations=True) \"\"\" if weekday : wd = 1 else : wd = 2 # Replace ',' with '.' in 'Resl\u00e4ngd' df [ 'Resl\u00e4ngd' ] = df [ 'Resl\u00e4ngd' ] . str . replace ( ',' , '.' ) # Replace ',' with '.' in 'VIKT_individ' df [ 'VIKT_individ' ] = df [ 'VIKT_individ' ] . str . replace ( ',' , '.' ) # Filter df to only include variables of interest df = df [ list ( variables_of_interest . keys ())] . reset_index ( drop = True ) # Replace no data with NaN (-111, 99998, '', blank) df = df . replace ([ - 111 , 999998 , 99998 , '' , ' ' ], float ( 'NaN' )) # Drop rows with NaN df = df . dropna () . reset_index ( drop = True ) # Sort by age #VARDAG_HELG == 1 for weekday #VARDAG_HELG == 2 for weekend df = df [ df [ 'VARDAG_HELG' ] == wd ] . reset_index ( drop = True ) #Antal_resor_per_pers > 1 df = df [ df [ 'Antal_resor_per_pers' ] > 1 ] . reset_index ( drop = True ) #TODO - Remove entries for an LPNR with \"Home\" not the last trip #Arende == 8 not the last trip # Replace categorical values with strings for variable in variables_of_interest : if variables_of_interest [ variable ][ 'type' ] == 'categorical' : # Change data type to int df [ variable ] = df [ variable ] . astype ( float ) # Replace values with strings df [ variable ] = df [ variable ] . replace ( variables_of_interest [ variable ][ 'categories' ]) elif variables_of_interest [ variable ][ 'type' ] == 'numerical' : # Change data type to int df [ variable ] = df [ variable ] . astype ( float ) elif variables_of_interest [ variable ][ 'type' ] == 'time' : # Change data type to datetime with format HH:MM:SS df [ variable ] = pd . to_datetime ( df [ variable ], format = '%H:%M:%S' ) # Only show hour and minute #df[variable] = df[variable].dt.strftime('%H:%M') # Set year, month and day to Today from datetime df [ variable ] = df [ variable ] . apply ( lambda dt : dt . replace ( year = year , month = month , day = day )) # Rename columns - k\u00f6n to kon \u00c5lder to alder df = df . rename ( columns = { 'LPNR' : 'id' , 'K\u00f6n' : 'sex' , '\u00c5ldersgrupp' : 'age_group' , 'Bostadstyp' : 'house_type' , 'Hush\u00e5llstyp' : 'household_type' , 'Antal_barn' : 'child_count' , 'Antal_bilar' : 'car_count' , 'Antal_vuxna' : 'adult_count' , 'Starttid' : 'start_time' , 'Huvud_fm' : 'mode' , 'Sluttid' : 'end_time' , 'Resl\u00e4ngd' : 'distance_km' , 'Arende' : 'purpose' , 'VIKT_individ' : 'weight_individual' }) #Drop 'VARDAG_HELG' and 'Antal_resor_per_pers' df = df . drop ([ 'VARDAG_HELG' , 'Antal_resor_per_pers' ], axis = 1 ) df = df . sort_values ( by = [ 'id' , 'start_time' ]) # Create a column called activity_sequence which is the activity number starting from 0 for each id df [ 'activity_sequence' ] = df . groupby ( 'id' ) . cumcount () # create a column called duration of previous activity # This is the time between end_time of previous activity and start_time of current activity # If there is no previous activity, then duration is 0 # If there is no next activity, then duration is 0 # Sort dataframe based on id and activity_sequence df = df . sort_values ( by = [ 'id' , 'start_time' ]) if unique_trips_only : # Drop duplicates based on id, start_time and end_time df = df . drop_duplicates ( subset = [ 'id' , 'start_time' , 'end_time' ]) . reset_index ( drop = True ) if process_durations : # Create the necessary columns for the entire dataframe df [ 'travel_duration_minutes' ] = df [ 'end_time' ] - df [ 'start_time' ] # Shift the start times within each group df [ 'next_travel_start_time' ] = df . groupby ( 'id' )[ 'start_time' ] . shift ( - 1 ) # Calculate activity durations df [ 'activity_duration_minutes' ] = df [ 'next_travel_start_time' ] - df [ 'end_time' ] # Fill NaN values in 'next_travel_start_time' and 'activity_duration_minutes' if required df [ 'next_travel_start_time' ] = df [ 'next_travel_start_time' ] . fillna ( method = 'ffill' ) df [ 'activity_duration_minutes' ] = df [ 'activity_duration_minutes' ] . fillna ( pd . Timedelta ( seconds = 0 )) return df","title":"preprocess_data"},{"location":"od/","text":"ODMatrix Source code in tripsender\\od.py 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 class ODMatrix (): def __init__ ( self , df_matrix ): self . matrix = df_matrix self . activity_sequences = None def compute_routes ( self , nrc_drive , nrc_bike , nrc_walk , nrc_transit ): \"\"\" This function computes the routes and durations for the OD matrix based on the mode of transport. The function iterates over the rows of the OD matrix and computes the route and duration based on the mode of transport. It user the NetworkRoutingComputer objects for each mode of transport to compute the route and duration. :param nrc_drive: (NetworkRoutingComputer) A NetworkRoutingComputer object for driving :param nrc_bike: (NetworkRoutingComputer) A NetworkRoutingComputer object for biking :param nrc_walk: (NetworkRoutingComputer) A NetworkRoutingComputer object for walking :param nrc_transit: (NetworkRoutingComputer) A NetworkRoutingComputer object for transit \"\"\" for index , row in self . matrix . iterrows (): mode = row [ 'mode' ] origin = row [ 'O' ] destination = row [ 'D' ] activity_sequence = row [ 'activity_sequence' ] transit_activity = row [ 'transit_activity' ] # Initialize route and duration variables route , duration = None , None # Compute route and duration based on the mode if mode in [ 'Car' , 'Taxi' , 'Moped' , 'Other' , 'Transportation service' , 'Flight' ]: route , duration = nrc_drive . compute_route ( origin , destination ) #route = \"This came from drive\" #print(\"Route:\", route) elif mode in [ \"Bicycle/E-bike\" ]: route , duration = nrc_bike . compute_route ( origin , destination ) #route = \"This came from bike\" #print(\"Route:\", route) elif mode in [ 'Walking' ]: route , duration = nrc_walk . compute_route ( origin , destination ) #route = \"This came from walk\" #print(\"Route:\", route) elif mode in [ 'Train/Tram' , 'Bus' , 'Boat' ]: route , duration = nrc_transit . compute_route ( origin , destination ) #route = \"This came from transit\" #print(\"Route:\", route) # Here if the route and duration is None it is because either the origin or destination is same # or the purpose was travel and there is no specific location for travel # In such cases, we will assign the origin and destination as the route and duration as 0 transit_activity . route = route transit_activity . calculated_duration = duration transit_activity . origin_coordinates = origin transit_activity . destination_coordinates = destination compute_routes ( nrc_drive , nrc_bike , nrc_walk , nrc_transit ) This function computes the routes and durations for the OD matrix based on the mode of transport. The function iterates over the rows of the OD matrix and computes the route and duration based on the mode of transport. It user the NetworkRoutingComputer objects for each mode of transport to compute the route and duration. :param nrc_drive: (NetworkRoutingComputer) A NetworkRoutingComputer object for driving :param nrc_bike: (NetworkRoutingComputer) A NetworkRoutingComputer object for biking :param nrc_walk: (NetworkRoutingComputer) A NetworkRoutingComputer object for walking :param nrc_transit: (NetworkRoutingComputer) A NetworkRoutingComputer object for transit Source code in tripsender\\od.py 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 def compute_routes ( self , nrc_drive , nrc_bike , nrc_walk , nrc_transit ): \"\"\" This function computes the routes and durations for the OD matrix based on the mode of transport. The function iterates over the rows of the OD matrix and computes the route and duration based on the mode of transport. It user the NetworkRoutingComputer objects for each mode of transport to compute the route and duration. :param nrc_drive: (NetworkRoutingComputer) A NetworkRoutingComputer object for driving :param nrc_bike: (NetworkRoutingComputer) A NetworkRoutingComputer object for biking :param nrc_walk: (NetworkRoutingComputer) A NetworkRoutingComputer object for walking :param nrc_transit: (NetworkRoutingComputer) A NetworkRoutingComputer object for transit \"\"\" for index , row in self . matrix . iterrows (): mode = row [ 'mode' ] origin = row [ 'O' ] destination = row [ 'D' ] activity_sequence = row [ 'activity_sequence' ] transit_activity = row [ 'transit_activity' ] # Initialize route and duration variables route , duration = None , None # Compute route and duration based on the mode if mode in [ 'Car' , 'Taxi' , 'Moped' , 'Other' , 'Transportation service' , 'Flight' ]: route , duration = nrc_drive . compute_route ( origin , destination ) #route = \"This came from drive\" #print(\"Route:\", route) elif mode in [ \"Bicycle/E-bike\" ]: route , duration = nrc_bike . compute_route ( origin , destination ) #route = \"This came from bike\" #print(\"Route:\", route) elif mode in [ 'Walking' ]: route , duration = nrc_walk . compute_route ( origin , destination ) #route = \"This came from walk\" #print(\"Route:\", route) elif mode in [ 'Train/Tram' , 'Bus' , 'Boat' ]: route , duration = nrc_transit . compute_route ( origin , destination ) #route = \"This came from transit\" #print(\"Route:\", route) # Here if the route and duration is None it is because either the origin or destination is same # or the purpose was travel and there is no specific location for travel # In such cases, we will assign the origin and destination as the route and duration as 0 transit_activity . route = route transit_activity . calculated_duration = duration transit_activity . origin_coordinates = origin transit_activity . destination_coordinates = destination assign_households_to_buildings ( gdf_residential , area_per_person = 32 ) This function assigns the households to the buildings based on the area_per_person parameter. Source code in tripsender\\od.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 def assign_households_to_buildings ( gdf_residential , area_per_person = 32 ): \"\"\" This function assigns the households to the buildings based on the area_per_person parameter. \"\"\" House . clear_instances () logger . info ( \"Processing residential buildings\" ) logger . info ( \"Fetching single and multi family housesholds\" ) households_in_single_family_house , households_in_multi_family_house = sort_households_by_type_and_count () logger . info ( \"Fetching single and multi family buildings\" ) single_family_buildings , multi_family_buildings = sort_buildings_by_type_and_population () logger . info ( f \"Number of single family buildings: { len ( single_family_buildings ) } for { len ( households_in_single_family_house ) } households\" ) logger . info ( f \"Number of multi family buildings: { len ( multi_family_buildings ) } for { len ( households_in_multi_family_house ) } households\" ) # If no buildings are found in single and multi family houses, raise an error if len ( single_family_buildings ) == 0 and len ( households_in_single_family_house ) != 0 : raise Exception ( \"No buildings found in single family houses while there are households in single family houses\" ) if len ( multi_family_buildings ) == 0 and len ( households_in_multi_family_house ) != 0 : raise Exception ( \"No buildings found in multi family houses while there are households in multi family houses\" ) if single_family_buildings and households_in_single_family_house : logger . info ( \"Processing single family houses\" ) assign_to_single_family_buildings ( households_in_single_family_house , single_family_buildings ) if multi_family_buildings and households_in_multi_family_house : logger . info ( \"Processing multi family houses\" ) assign_to_multi_family_buildings ( households_in_multi_family_house , multi_family_buildings , area_per_person ) logger . info ( \"Marking empty buildings\" ) # Update the house_type at the person level to match the house_type at the Household level for person in Person . instances : person . house_type = person . household . house_type mark_empty_buildings () assign_to_multi_family_buildings ( households , buildings , area_per_person ) This function assigns the households to multi family buildings. Source code in tripsender\\od.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 def assign_to_multi_family_buildings ( households , buildings , area_per_person ): \"\"\" This function assigns the households to multi family buildings. \"\"\" num_buildings = len ( buildings ) if num_buildings == 0 : logger . info ( \"assign_to_multi_family_buildings: No buildings left to assign multi family households to\" ) return num_households = len ( households ) cycles = num_households // num_buildings remaining_households = num_households % num_buildings for cycle in range ( cycles ): for building in buildings : household = households . pop ( 0 ) remaining_capacity = area_per_person * building . built_up_area - building . population_total if remaining_capacity > len ( household . members ): house = House ( household , building ) remaining_capacity -= len ( household . members ) else : households . insert ( 0 , household ) for i in range ( remaining_households ): building = buildings [ i ] household = households . pop ( 0 ) remaining_capacity = area_per_person * building . built_up_area - building . population_total if remaining_capacity > len ( household . members ): house = House ( household , building ) remaining_capacity -= len ( household . members ) else : households . insert ( 0 , household ) assign_to_single_family_buildings ( households , buildings ) This function assigns the households to single family buildings. Source code in tripsender\\od.py 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 def assign_to_single_family_buildings ( households , buildings ): \"\"\" This function assigns the households to single family buildings. \"\"\" if len ( households ) < len ( buildings ): # If there are more buildings than households, assign one household to each building # Every building will have atleast 1 single family house buildings = buildings [: len ( households )] for i , household in enumerate ( households ): building = buildings [ i ] house = House ( household , building ) house . area = building . area logger . info ( f \"assign_to_single_family_buildings: Assgned { len ( households ) } single family households to { len ( buildings ) } buildings\" ) else : pass create_location_mapping ( person , random_location = False ) Helper function to create a mapping of activity purposes to locations. It is possible to select random locations for each activity purpose by setting the random_location flag to True. If random_location is False, the first location from the preferred locations is selected for each activity purpose. Source code in tripsender\\od.py 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 def create_location_mapping ( person , random_location = False ): \"\"\"Helper function to create a mapping of activity purposes to locations. It is possible to select random locations for each activity purpose by setting the random_location flag to True. If random_location is False, the first location from the preferred locations is selected for each activity purpose. \"\"\" preferred_locations = person . household . house . building . preferred_locations # Location assignments home_location = person . origin work_location = person . work_location . location_coordinates if person . work_location else None # Selecting locations based on the random flag if random_location : education_location = random . choice ( preferred_locations . EDUCATION ) . location_coordinates shopping_location = random . choice ( preferred_locations . SHOPPING_OTHER ) . location_coordinates shopping_groceries_location = random . choice ( preferred_locations . SHOPPING_GROCERY ) . location_coordinates leisure_location = random . choice ( preferred_locations . LEISURE ) . location_coordinates healthcare_location = preferred_locations . HEALTHCARE [ 0 ] . location_coordinates #healthcare_location = random.choice(preferred_locations.HEALTHCARE).location_coordinates else : education_location = preferred_locations . EDUCATION [ 0 ] . location_coordinates shopping_location = preferred_locations . SHOPPING_OTHER [ 0 ] . location_coordinates shopping_groceries_location = preferred_locations . SHOPPING_GROCERY [ 0 ] . location_coordinates leisure_location = preferred_locations . LEISURE [ 0 ] . location_coordinates healthcare_location = preferred_locations . HEALTHCARE [ 0 ] . location_coordinates # Handling other random location which is common between random and non-random selection other_location = preferred_locations . random_location () travel_location = person . origin # Assuming there's no specific location for 'Travel' children_location = preferred_locations . EDUCATION_f\u00f6rskola . location_coordinates location_mapping = { \"Home\" : home_location , \"Work\" : work_location , \"Education\" : education_location , \"Shopping\" : shopping_location , \"Grocery\" : shopping_groceries_location , \"Leisure\" : leisure_location , \"Other\" : other_location , \"Healthcare\" : healthcare_location , \"Travel\" : travel_location , \"Pickup/Dropoff child\" : children_location } person . location_mapping = location_mapping return location_mapping generate_od_matrix ( num_samples = None , random_location = False ) This function generates an OD matrix based on the activity sequences of the persons. The process of generating the OD matrix is as follows: 1 - Identify all the adults in the households 2 - For each adult, identify the activity sequence 3 - Get the location_mapping dictionary for the person 4 - For each activity, identify the origin, destination and mode of transport 4.1 - First origin is the home location 4.2 - Last destination is the home location 4.3 - Mode of transport is the mode of transport for the activity 5 - Append the origin, destination, mode, person and activity sequence to the OD_pairs list 6 - Create a dataframe from the OD_pairs list 7 - Create an ODMatrix object from the dataframe 8 - Return the ODMatrix object Some caveats: - If the destination purpose is Travel, the destination is set to None. This is done by the create_location_mapping function Source code in tripsender\\od.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 def generate_od_matrix ( num_samples = None , random_location = False ): \"\"\" This function generates an OD matrix based on the activity sequences of the persons. The process of generating the OD matrix is as follows: 1 - Identify all the adults in the households 2 - For each adult, identify the activity sequence 3 - Get the location_mapping dictionary for the person 4 - For each activity, identify the origin, destination and mode of transport 4.1 - First origin is the home location 4.2 - Last destination is the home location 4.3 - Mode of transport is the mode of transport for the activity 5 - Append the origin, destination, mode, person and activity sequence to the OD_pairs list 6 - Create a dataframe from the OD_pairs list 7 - Create an ODMatrix object from the dataframe 8 - Return the ODMatrix object Some caveats: - If the destination purpose is Travel, the destination is set to None. This is done by the create_location_mapping function \"\"\" logger . info ( \"Generating OD Matrix...\" ) activity_sequences = [] OD_pairs = [] person_list = [] activity_sequence_list = [] if num_samples is None : num_samples = len ( Person . instances ) buildings = Building . instances houses = [ house for building in buildings for house in building . houses ] households = [ house . household for house in houses ] persons = [ person for household in households for person in household . members ] adults = [ person for person in persons if person . age >= 18 ][ 0 : num_samples ] for person in adults : activity_sequence = person . activity_sequence activity_sequences . append ( activity_sequence ) if activity_sequence is not None : location_mapping = create_location_mapping ( person , random_location = random_location ) activities = activity_sequence . activities if activities : last_non_none_location = person . origin # Initialize with home location for i in range ( 0 , len ( activities ) - 2 , 2 ): origin_activity = activities [ i ] mode_activity = activities [ i + 1 ] destination_activity = activities [ i + 2 ] if i + 2 < len ( activities ) else origin_activity # Assigning locations origin = location_mapping . get ( origin_activity . purpose , last_non_none_location ) destination = location_mapping . get ( destination_activity . purpose ) # If destination is None due to \"Travel\", keep last_non_none_location for next origin if destination is not None : last_non_none_location = destination mode = mode_activity . mode # Append to OD pairs OD_pairs . append ([ origin , destination , mode , mode_activity , origin_activity . purpose , destination_activity . purpose ]) person_list . append ( person ) activity_sequence_list . append ( activity_sequence ) df = pd . DataFrame ( OD_pairs , columns = [ 'O' , 'D' , 'mode' , \"transit_activity\" , 'O_purpose' , 'D_purpose' ]) df [ 'person' ] = person_list df [ 'activity_sequence' ] = activity_sequence_list od_matrix = ODMatrix ( df ) od_matrix . activity_sequences = activity_sequences logger . info ( \"OD Matrix successfully created...\" ) return od_matrix get_gdf ( area , feature , KEY = '' , VAL = '' , title = 'Data from Server' , filter = False , local = True , web = True , plot = False , save = True ) A function to fetch spatial geometry from the PostGIS server as GeoPandas GeoDataFrame . This function is simply a wrapper for the psycopg2 module. It constructs an SQL query based on the the params provided and requests data from the server. :param area: (str) The name of the Primary area in the Model naming format. :param feature: (str) The feature name to select from the PostGIS database. (Refer to PostGIS naming convention) :param KEY: (str: Optional) An optional attribute to filter from the data at the server level :param VAL: (str: Optional) An optional value for a given key to match from the data at the server level :param title: (str: Optional) An optional title for the plot :param filter: (bool: Optional) An optional input to specify if the data must be filtered at the server level :param local: (bool: Optional) Which server to fetch the data from :param web: (bool: Optional) If True , the result will be reprojected :param plot: (bool: Optional) If True , the result will be plotted :return: (GeoPandas GeoDataFrame, plot(Optional)) The resulting GeoPandas GeoDataFrame . Source code in tripsender\\od.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def get_gdf ( area , #TODO Fix area naming convention to match PXWEB naming feature , KEY = '' , VAL = '' , title = 'Data from Server' , filter = False , local = True , web = True , plot = False , save = True ): \"\"\" A function to fetch spatial geometry from the ``PostGIS`` server as ``GeoPandas GeoDataFrame``. This function is simply a wrapper for the ``psycopg2`` module. It constructs an ``SQL`` query based on the the params provided and requests data from the server. :param area: (str) The name of the Primary area in the Model naming format. :param feature: (str) The feature name to select from the ``PostGIS`` database. (Refer to PostGIS naming convention) :param KEY: (str: Optional) An optional attribute to filter from the data at the server level :param VAL: (str: Optional) An optional value for a given key to match from the data at the server level :param title: (str: Optional) An optional title for the plot :param filter: (bool: Optional) An optional input to specify if the data must be filtered at the server level :param local: (bool: Optional) Which server to fetch the data from :param web: (bool: Optional) If ``True``, the result will be reprojected :param plot: (bool: Optional) If ``True``, the result will be plotted :return: (GeoPandas GeoDataFrame, plot(Optional)) The resulting `GeoPandas GeoDataFrame`. \"\"\" # If area has numbers in it, use re.search(r\"\\d+\\s*(.*)\", area).group(1) # Clean area name if any ( char . isdigit () for char in area ): area = re . search ( r \"\\d+\\s*(.*)\" , area ) . group ( 1 ) else : pass layer = '' if feature == 0 : layer = \"se_got_trs_roads_tv\" elif feature == 1 : layer = \"se_got_phy_buildingfootprint_lm\" selectInString = 'SELECT ' + layer + '.geom' for k in KEY : selectOutString = selectInString + ' , ' + layer + '.' + k selectInString = selectOutString SELECT = selectInString # Adding conditionals if filter : COND = ' \\' AND ' + layer + '.' + KEY [ 0 ] + ' = \\' ' + VAL else : COND = '' # Building SQL FROM = ' FROM ' + layer JOIN = ' JOIN se_got_bnd_admin10_osm ON ' CONTAIN = 'ST_Contains(se_got_bnd_admin10_osm.geom,' + layer + '.geom)' WHERE = ' WHERE se_got_bnd_admin10_osm.name = \\' ' + area + COND + ' \\' ;' sql = SELECT + FROM + JOIN + CONTAIN + WHERE ####logger.info(sql) # Get secrets con = get_pgcon ( local = local ) gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) # Switching database if web : result = gdf . to_crs ( \"EPSG:4326\" ) else : result = gdf # Plotting if plot : fig , ax = plt . subplots ( figsize = ( 10 , 10 )) fig . subplots_adjust ( right = 0.7 ) col = result . columns [ 1 ] title = area + ' ' + title ax . set_title ( title ) result . plot ( column = col , legend = True , legend_kwds = dict ( loc = 'upper left' , bbox_to_anchor = ( 1 , 1 )), ax = ax ) if save : plt . savefig ( 'static/' + area + '.png' ) return result get_landuse ( local = False , web = False , clip = None , buffer_distance = 1000 ) A function to fetch land use data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param clip: Geometry to clip the natural features. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the land use data. Source code in tripsender\\od.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def get_landuse ( local = False , web = False , clip = None , buffer_distance = 1000 ): \"\"\" A function to fetch land use data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param clip: Geometry to clip the natural features. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the land use data. \"\"\" con = get_pgcon ( local = local ) # Start with base SQL query to select all columns sql = 'SELECT * FROM se_got_phy_naturalfeatures_lm' # If a clipping polygon is provided, modify the SQL query to include a WHERE clause if clip is not None : # Validate the clip object is a Polygon and buffer it if isinstance ( clip , shapely . geometry . Polygon ): wkt = clip . buffer ( buffer_distance ) . wkt sql += f ' WHERE ST_Intersects(geom, ST_GeomFromText( \\' { wkt } \\' , 3006))' else : raise ValueError ( 'The clip parameter must be a Shapely Polygon.' ) # Fetch the data from the database try : gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) except Exception as e : raise ConnectionError ( f \"An error occurred while connecting to the database: { e } \" ) # Reproject if web is True if web : gdf = gdf . to_crs ( \"EPSG:4326\" ) return gdf get_pg_query ( sql , local = True , web = True ) A utility function that fetches any data using an SQL query from the PostGIS Server This function is a basic wrapper for the psycopg2 module with secrets included. :param sql: (str) An SQL query string :param local: (bool: Optional) If True , data will be fetched from the local server :param web: (bool: Optional) If True , result will be reprojected to EPSG:4326 :return: Source code in tripsender\\od.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 def get_pg_query ( sql , local = True , web = True ): \"\"\" A utility function that fetches any data using an ``SQL`` query from the ``PostGIS`` Server This function is a basic wrapper for the ``psycopg2`` module with secrets included. :param sql: (str) An SQL query string :param local: (bool: Optional) If ``True``, data will be fetched from the local server :param web: (bool: Optional) If ``True``, result will be reprojected to ``EPSG:4326`` :return: \"\"\" con = get_pgcon ( local = local ) ####logger.info(sql) gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) if web : result = gdf . to_crs ( \"EPSG:4326\" ) else : result = gdf return result get_pgcon ( local = True ) A helper function to read the .pgpass file. This is the authentication file for the PostGIS server. The function reads the file and returns a connection object to the PostGIS server. The server contains the spatial data for the region, including the road network and building footprints. :param local: (bool: Optional) If True , the function will connect to the local server. :return: (psycopg2 connection) A connection object to the PostGIS server. Source code in tripsender\\od.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_pgcon ( local = True ): \"\"\" A helper function to read the `.pgpass` file. This is the authentication file for the `PostGIS` server. The function reads the file and returns a connection object to the `PostGIS` server. The server contains the spatial data for the region, including the road network and building footprints. :param local: (bool: Optional) If ``True``, the function will connect to the local server. :return: (psycopg2 connection) A connection object to the `PostGIS` server. \"\"\" host , port , database , user , password = '' , '' , '' , '' , '' f = open ( \"secrets/.pgpass\" , \"r\" ) for i , line in enumerate ( f ): if i == local : host , port , database , user , password = line . split ( ':' ) # Create connection string con = psycopg2 . connect ( database = database . strip (), user = user . strip (), password = password . strip (), host = host . strip ()) return con get_road ( local = True , web = True , ped = True , clip = None , buffer_distance = 1000 ) A function to fetch road data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param ped: If True, pedestrian roads will be included in the result. :param clip: Geometry to clip the road data. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the road data. Source code in tripsender\\od.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def get_road ( local = True , web = True , ped = True , clip = None , buffer_distance = 1000 ): \"\"\" A function to fetch road data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param ped: If True, pedestrian roads will be included in the result. :param clip: Geometry to clip the road data. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the road data. \"\"\" con = get_pgcon ( local = local ) # Initialize a list to hold individual queries queries = [] # Base SQL query for roads road_query = 'SELECT geom FROM se_got_trs_roads_tv' queries . append ( road_query ) # Add pedestrian roads if needed if ped : ped_query = 'SELECT geom FROM se_got_trs_path_tv' queries . append ( ped_query ) # Modify individual queries to clip with provided polygon if clip is not None : wkt = clip . buffer ( buffer_distance ) . wkt # Buffer 1km and convert Shapely Polygon to WKT # Apply the WHERE clause to each query queries = [ q + f \" WHERE ST_Intersects(geom, ST_GeomFromText(' { wkt } ', 3006))\" for q in queries ] # Combine the queries with UNION ALL sql = ' UNION ALL ' . join ( queries ) #print(\"Final SQL Query:\", sql) # Debugging line gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) if web : gdf = gdf . to_crs ( \"EPSG:4326\" ) return gdf mark_empty_buildings () This function marks the buildings as empty if the population_total is 0. Source code in tripsender\\od.py 415 416 417 418 419 420 421 def mark_empty_buildings (): \"\"\" This function marks the buildings as empty if the population_total is 0. \"\"\" for building in Building . instances : if building . population_total == 0 : building . isEmpty = True process_residential_buildings ( gdf_building , area_per_person = 36 ) This function processes the residential buildings to calculate the number of people living in each building. The function filters the buildings based on the area_per_person parameter and calculates the number of people living in each building. The function also calculates the number of floors in each building and the total Built-up Area (BTA) of each building. The function also assigns a UUID to each building. The data for the area_per_person parameter is based on the average living area per person in Sweden. Reference: https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ A service area factor is applied to the area of the building based on the building type. The service area factor is 0.85 for 'Flerfamiljshus' and 0.9 for all other building types. :param gdf_building: (GeoPandas GeoDataFrame) A GeoDataFrame containing the building footprints. :param area_per_person: (int: Optional) The area per person in square meters. Default is 36 m2. :return: (GeoPandas GeoDataFrame) A GeoDataFrame containing the processed residential buildings. Source code in tripsender\\od.py 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 def process_residential_buildings ( gdf_building , area_per_person = 36 ): \"\"\" This function processes the residential buildings to calculate the number of people living in each building. The function filters the buildings based on the area_per_person parameter and calculates the number of people living in each building. The function also calculates the number of floors in each building and the total Built-up Area (BTA) of each building. The function also assigns a UUID to each building. The data for the area_per_person parameter is based on the average living area per person in Sweden. Reference: https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ A service area factor is applied to the area of the building based on the building type. The service area factor is 0.85 for 'Flerfamiljshus' and 0.9 for all other building types. :param gdf_building: (GeoPandas GeoDataFrame) A GeoDataFrame containing the building footprints. :param area_per_person: (int: Optional) The area per person in square meters. Default is 36 m2. :return: (GeoPandas GeoDataFrame) A GeoDataFrame containing the processed residential buildings. \"\"\" # Average living area per person # https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ # Split andamal_1t by ';' and create a new column for each value, new columns are byggnadstyp and byggnadsundergrupp gdf_building [ 'byggnadstyp' ] = gdf_building [ 'andamal_1t' ] . str . split ( ';' ) . str [ 0 ] gdf_building [ 'byggnadsundergrupp' ] = gdf_building [ 'andamal_1t' ] . str . split ( '; ' ) . str [ 1 ] # Filter Bostad only gdf_residential = gdf_building [ gdf_building [ 'byggnadstyp' ] == 'Bostad' ] # Remove buildings with area less than area_per_person m2 gdf_residential = gdf_residential [ gdf_residential [ 'geom' ] . area > area_per_person ] # Plot the counts of each byggnadsundergrupp in gdf_residential #gdf_residential['byggnadsundergrupp'].value_counts().plot(kind='bar') # Get number of floors from height where each floor is 3m high and round up such that minimum floors is 1 gdf_residential [ 'floors' ] = gdf_residential [ 'height' ] . apply ( lambda x : round ( x / 3.5 , 0 )) . apply ( lambda x : max ( x , 1 )) # Get BTA by calculating area of the shape and multiply by number of floors and round down gdf_residential [ 'area' ] = gdf_residential [ 'geom' ] . area # Histo gram of areas for each byggnadsundergrupp #gdf_residential.hist(column='area', by='byggnadsundergrupp', bins=50, figsize=(20,15)) # If house is 'Flerfamiljshus', multiply by 0.85 to account for service areas gdf_residential . loc [ gdf_residential [ 'byggnadsundergrupp' ] == 'Flerfamiljshus' , 'area' ] = gdf_residential [ 'area' ] * 0.7 # For all other houses, multiply by 0.9 to account for service areas gdf_residential . loc [ gdf_residential [ 'byggnadsundergrupp' ] != 'Flerfamiljshus' , 'area' ] = gdf_residential [ 'area' ] * 0.8 # Get BTA by calculating area of the shape and multiply by number of floors and round down gdf_residential [ 'BTA' ] = gdf_residential [ 'area' ] * gdf_residential [ 'floors' ] . apply ( lambda x : round ( x )) # Add a column for number of people living in each building level (footprint_area/area_per_person) and round down gdf_residential [ 'population_per_floor' ] = gdf_residential [ 'area' ] . apply ( lambda x : round ( x / area_per_person )) # Add a column for number of people living in each building (people_per_floor * number of floors) gdf_residential [ 'population_total' ] = gdf_residential [ 'population_per_floor' ] * gdf_residential [ 'floors' ] # Add a uuid for each building using uuid4 # Added automatically on creating he class #gdf_residential['uuid'] = gdf_residential.apply(lambda x: uuid.uuid4(), axis=1) #gdf_residential.head() return gdf_residential sort_buildings_by_type_and_population () This function sorts the buildings by type and population into single family and multi family buildings Buildings are sorted by population in descending order. Note: Population is calculated as the number of people living in the building based on the area_per_person parameter. Returns: single_family_buildings (list): A list of single family buildings sorted by population multi_family_buildings (list): A list of multi family buildings sorted by population Source code in tripsender\\od.py 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 def sort_buildings_by_type_and_population (): \"\"\" This function sorts the buildings by type and population into single family and multi family buildings Buildings are sorted by population in descending order. Note: Population is calculated as the number of people living in the building based on the area_per_person parameter. Returns: single_family_buildings (list): A list of single family buildings sorted by population multi_family_buildings (list): A list of multi family buildings sorted by population \"\"\" single_family_house = [ 'Sm\u00e5hus friliggande' , 'Sm\u00e5hus kedjehus' , 'Sm\u00e5hus radhus' , 'Sm\u00e5hus med flera l\u00e4genheter' ] multi_family_house = [ 'Flerfamiljshus' ] single_family_buildings = [ building for building in Building . instances if building . type in single_family_house ] single_family_buildings . sort ( key = lambda x : x . population_total , reverse = True ) multi_family_buildings = [ building for building in Building . instances if building . type in multi_family_house ] multi_family_buildings . sort ( key = lambda x : x . population_total , reverse = True ) if len ( multi_family_buildings ) == 0 : ValueError ( \"No multi family buildings found\" ) if len ( single_family_buildings ) == 0 : ValueError ( \"No single family buildings found\" ) return single_family_buildings , multi_family_buildings sort_households_by_type_and_count () This function sorts the households by type and population into single family and multi family households Households are sorted by population in descending order. Returns: households_in_single_family_house (list): A list of single family households sorted by population households_in_multi_family_house (list): A list of multi family households sorted by population Source code in tripsender\\od.py 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 def sort_households_by_type_and_count (): \"\"\" This function sorts the households by type and population into single family and multi family households Households are sorted by population in descending order. Returns: households_in_single_family_house (list): A list of single family households sorted by population households_in_multi_family_house (list): A list of multi family households sorted by population \"\"\" households_in_single_family_house = [ household for household in Household . instances if household . house_type == 'Villa' ] households_in_single_family_house . sort ( key = lambda x : len ( x . members ), reverse = True ) households_in_multi_family_house = [ household for household in Household . instances if household . house_type in [ 'Apartment' , 'Other' ]] households_in_multi_family_house . sort ( key = lambda x : len ( x . members ), reverse = True ) return households_in_single_family_house , households_in_multi_family_house","title":"od"},{"location":"od/#tripsender.od.ODMatrix","text":"Source code in tripsender\\od.py 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 class ODMatrix (): def __init__ ( self , df_matrix ): self . matrix = df_matrix self . activity_sequences = None def compute_routes ( self , nrc_drive , nrc_bike , nrc_walk , nrc_transit ): \"\"\" This function computes the routes and durations for the OD matrix based on the mode of transport. The function iterates over the rows of the OD matrix and computes the route and duration based on the mode of transport. It user the NetworkRoutingComputer objects for each mode of transport to compute the route and duration. :param nrc_drive: (NetworkRoutingComputer) A NetworkRoutingComputer object for driving :param nrc_bike: (NetworkRoutingComputer) A NetworkRoutingComputer object for biking :param nrc_walk: (NetworkRoutingComputer) A NetworkRoutingComputer object for walking :param nrc_transit: (NetworkRoutingComputer) A NetworkRoutingComputer object for transit \"\"\" for index , row in self . matrix . iterrows (): mode = row [ 'mode' ] origin = row [ 'O' ] destination = row [ 'D' ] activity_sequence = row [ 'activity_sequence' ] transit_activity = row [ 'transit_activity' ] # Initialize route and duration variables route , duration = None , None # Compute route and duration based on the mode if mode in [ 'Car' , 'Taxi' , 'Moped' , 'Other' , 'Transportation service' , 'Flight' ]: route , duration = nrc_drive . compute_route ( origin , destination ) #route = \"This came from drive\" #print(\"Route:\", route) elif mode in [ \"Bicycle/E-bike\" ]: route , duration = nrc_bike . compute_route ( origin , destination ) #route = \"This came from bike\" #print(\"Route:\", route) elif mode in [ 'Walking' ]: route , duration = nrc_walk . compute_route ( origin , destination ) #route = \"This came from walk\" #print(\"Route:\", route) elif mode in [ 'Train/Tram' , 'Bus' , 'Boat' ]: route , duration = nrc_transit . compute_route ( origin , destination ) #route = \"This came from transit\" #print(\"Route:\", route) # Here if the route and duration is None it is because either the origin or destination is same # or the purpose was travel and there is no specific location for travel # In such cases, we will assign the origin and destination as the route and duration as 0 transit_activity . route = route transit_activity . calculated_duration = duration transit_activity . origin_coordinates = origin transit_activity . destination_coordinates = destination","title":"ODMatrix"},{"location":"od/#tripsender.od.ODMatrix.compute_routes","text":"This function computes the routes and durations for the OD matrix based on the mode of transport. The function iterates over the rows of the OD matrix and computes the route and duration based on the mode of transport. It user the NetworkRoutingComputer objects for each mode of transport to compute the route and duration. :param nrc_drive: (NetworkRoutingComputer) A NetworkRoutingComputer object for driving :param nrc_bike: (NetworkRoutingComputer) A NetworkRoutingComputer object for biking :param nrc_walk: (NetworkRoutingComputer) A NetworkRoutingComputer object for walking :param nrc_transit: (NetworkRoutingComputer) A NetworkRoutingComputer object for transit Source code in tripsender\\od.py 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 def compute_routes ( self , nrc_drive , nrc_bike , nrc_walk , nrc_transit ): \"\"\" This function computes the routes and durations for the OD matrix based on the mode of transport. The function iterates over the rows of the OD matrix and computes the route and duration based on the mode of transport. It user the NetworkRoutingComputer objects for each mode of transport to compute the route and duration. :param nrc_drive: (NetworkRoutingComputer) A NetworkRoutingComputer object for driving :param nrc_bike: (NetworkRoutingComputer) A NetworkRoutingComputer object for biking :param nrc_walk: (NetworkRoutingComputer) A NetworkRoutingComputer object for walking :param nrc_transit: (NetworkRoutingComputer) A NetworkRoutingComputer object for transit \"\"\" for index , row in self . matrix . iterrows (): mode = row [ 'mode' ] origin = row [ 'O' ] destination = row [ 'D' ] activity_sequence = row [ 'activity_sequence' ] transit_activity = row [ 'transit_activity' ] # Initialize route and duration variables route , duration = None , None # Compute route and duration based on the mode if mode in [ 'Car' , 'Taxi' , 'Moped' , 'Other' , 'Transportation service' , 'Flight' ]: route , duration = nrc_drive . compute_route ( origin , destination ) #route = \"This came from drive\" #print(\"Route:\", route) elif mode in [ \"Bicycle/E-bike\" ]: route , duration = nrc_bike . compute_route ( origin , destination ) #route = \"This came from bike\" #print(\"Route:\", route) elif mode in [ 'Walking' ]: route , duration = nrc_walk . compute_route ( origin , destination ) #route = \"This came from walk\" #print(\"Route:\", route) elif mode in [ 'Train/Tram' , 'Bus' , 'Boat' ]: route , duration = nrc_transit . compute_route ( origin , destination ) #route = \"This came from transit\" #print(\"Route:\", route) # Here if the route and duration is None it is because either the origin or destination is same # or the purpose was travel and there is no specific location for travel # In such cases, we will assign the origin and destination as the route and duration as 0 transit_activity . route = route transit_activity . calculated_duration = duration transit_activity . origin_coordinates = origin transit_activity . destination_coordinates = destination","title":"compute_routes"},{"location":"od/#tripsender.od.assign_households_to_buildings","text":"This function assigns the households to the buildings based on the area_per_person parameter. Source code in tripsender\\od.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 def assign_households_to_buildings ( gdf_residential , area_per_person = 32 ): \"\"\" This function assigns the households to the buildings based on the area_per_person parameter. \"\"\" House . clear_instances () logger . info ( \"Processing residential buildings\" ) logger . info ( \"Fetching single and multi family housesholds\" ) households_in_single_family_house , households_in_multi_family_house = sort_households_by_type_and_count () logger . info ( \"Fetching single and multi family buildings\" ) single_family_buildings , multi_family_buildings = sort_buildings_by_type_and_population () logger . info ( f \"Number of single family buildings: { len ( single_family_buildings ) } for { len ( households_in_single_family_house ) } households\" ) logger . info ( f \"Number of multi family buildings: { len ( multi_family_buildings ) } for { len ( households_in_multi_family_house ) } households\" ) # If no buildings are found in single and multi family houses, raise an error if len ( single_family_buildings ) == 0 and len ( households_in_single_family_house ) != 0 : raise Exception ( \"No buildings found in single family houses while there are households in single family houses\" ) if len ( multi_family_buildings ) == 0 and len ( households_in_multi_family_house ) != 0 : raise Exception ( \"No buildings found in multi family houses while there are households in multi family houses\" ) if single_family_buildings and households_in_single_family_house : logger . info ( \"Processing single family houses\" ) assign_to_single_family_buildings ( households_in_single_family_house , single_family_buildings ) if multi_family_buildings and households_in_multi_family_house : logger . info ( \"Processing multi family houses\" ) assign_to_multi_family_buildings ( households_in_multi_family_house , multi_family_buildings , area_per_person ) logger . info ( \"Marking empty buildings\" ) # Update the house_type at the person level to match the house_type at the Household level for person in Person . instances : person . house_type = person . household . house_type mark_empty_buildings ()","title":"assign_households_to_buildings"},{"location":"od/#tripsender.od.assign_to_multi_family_buildings","text":"This function assigns the households to multi family buildings. Source code in tripsender\\od.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 def assign_to_multi_family_buildings ( households , buildings , area_per_person ): \"\"\" This function assigns the households to multi family buildings. \"\"\" num_buildings = len ( buildings ) if num_buildings == 0 : logger . info ( \"assign_to_multi_family_buildings: No buildings left to assign multi family households to\" ) return num_households = len ( households ) cycles = num_households // num_buildings remaining_households = num_households % num_buildings for cycle in range ( cycles ): for building in buildings : household = households . pop ( 0 ) remaining_capacity = area_per_person * building . built_up_area - building . population_total if remaining_capacity > len ( household . members ): house = House ( household , building ) remaining_capacity -= len ( household . members ) else : households . insert ( 0 , household ) for i in range ( remaining_households ): building = buildings [ i ] household = households . pop ( 0 ) remaining_capacity = area_per_person * building . built_up_area - building . population_total if remaining_capacity > len ( household . members ): house = House ( household , building ) remaining_capacity -= len ( household . members ) else : households . insert ( 0 , household )","title":"assign_to_multi_family_buildings"},{"location":"od/#tripsender.od.assign_to_single_family_buildings","text":"This function assigns the households to single family buildings. Source code in tripsender\\od.py 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 def assign_to_single_family_buildings ( households , buildings ): \"\"\" This function assigns the households to single family buildings. \"\"\" if len ( households ) < len ( buildings ): # If there are more buildings than households, assign one household to each building # Every building will have atleast 1 single family house buildings = buildings [: len ( households )] for i , household in enumerate ( households ): building = buildings [ i ] house = House ( household , building ) house . area = building . area logger . info ( f \"assign_to_single_family_buildings: Assgned { len ( households ) } single family households to { len ( buildings ) } buildings\" ) else : pass","title":"assign_to_single_family_buildings"},{"location":"od/#tripsender.od.create_location_mapping","text":"Helper function to create a mapping of activity purposes to locations. It is possible to select random locations for each activity purpose by setting the random_location flag to True. If random_location is False, the first location from the preferred locations is selected for each activity purpose. Source code in tripsender\\od.py 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 def create_location_mapping ( person , random_location = False ): \"\"\"Helper function to create a mapping of activity purposes to locations. It is possible to select random locations for each activity purpose by setting the random_location flag to True. If random_location is False, the first location from the preferred locations is selected for each activity purpose. \"\"\" preferred_locations = person . household . house . building . preferred_locations # Location assignments home_location = person . origin work_location = person . work_location . location_coordinates if person . work_location else None # Selecting locations based on the random flag if random_location : education_location = random . choice ( preferred_locations . EDUCATION ) . location_coordinates shopping_location = random . choice ( preferred_locations . SHOPPING_OTHER ) . location_coordinates shopping_groceries_location = random . choice ( preferred_locations . SHOPPING_GROCERY ) . location_coordinates leisure_location = random . choice ( preferred_locations . LEISURE ) . location_coordinates healthcare_location = preferred_locations . HEALTHCARE [ 0 ] . location_coordinates #healthcare_location = random.choice(preferred_locations.HEALTHCARE).location_coordinates else : education_location = preferred_locations . EDUCATION [ 0 ] . location_coordinates shopping_location = preferred_locations . SHOPPING_OTHER [ 0 ] . location_coordinates shopping_groceries_location = preferred_locations . SHOPPING_GROCERY [ 0 ] . location_coordinates leisure_location = preferred_locations . LEISURE [ 0 ] . location_coordinates healthcare_location = preferred_locations . HEALTHCARE [ 0 ] . location_coordinates # Handling other random location which is common between random and non-random selection other_location = preferred_locations . random_location () travel_location = person . origin # Assuming there's no specific location for 'Travel' children_location = preferred_locations . EDUCATION_f\u00f6rskola . location_coordinates location_mapping = { \"Home\" : home_location , \"Work\" : work_location , \"Education\" : education_location , \"Shopping\" : shopping_location , \"Grocery\" : shopping_groceries_location , \"Leisure\" : leisure_location , \"Other\" : other_location , \"Healthcare\" : healthcare_location , \"Travel\" : travel_location , \"Pickup/Dropoff child\" : children_location } person . location_mapping = location_mapping return location_mapping","title":"create_location_mapping"},{"location":"od/#tripsender.od.generate_od_matrix","text":"This function generates an OD matrix based on the activity sequences of the persons. The process of generating the OD matrix is as follows: 1 - Identify all the adults in the households 2 - For each adult, identify the activity sequence 3 - Get the location_mapping dictionary for the person 4 - For each activity, identify the origin, destination and mode of transport 4.1 - First origin is the home location 4.2 - Last destination is the home location 4.3 - Mode of transport is the mode of transport for the activity 5 - Append the origin, destination, mode, person and activity sequence to the OD_pairs list 6 - Create a dataframe from the OD_pairs list 7 - Create an ODMatrix object from the dataframe 8 - Return the ODMatrix object Some caveats: - If the destination purpose is Travel, the destination is set to None. This is done by the create_location_mapping function Source code in tripsender\\od.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 def generate_od_matrix ( num_samples = None , random_location = False ): \"\"\" This function generates an OD matrix based on the activity sequences of the persons. The process of generating the OD matrix is as follows: 1 - Identify all the adults in the households 2 - For each adult, identify the activity sequence 3 - Get the location_mapping dictionary for the person 4 - For each activity, identify the origin, destination and mode of transport 4.1 - First origin is the home location 4.2 - Last destination is the home location 4.3 - Mode of transport is the mode of transport for the activity 5 - Append the origin, destination, mode, person and activity sequence to the OD_pairs list 6 - Create a dataframe from the OD_pairs list 7 - Create an ODMatrix object from the dataframe 8 - Return the ODMatrix object Some caveats: - If the destination purpose is Travel, the destination is set to None. This is done by the create_location_mapping function \"\"\" logger . info ( \"Generating OD Matrix...\" ) activity_sequences = [] OD_pairs = [] person_list = [] activity_sequence_list = [] if num_samples is None : num_samples = len ( Person . instances ) buildings = Building . instances houses = [ house for building in buildings for house in building . houses ] households = [ house . household for house in houses ] persons = [ person for household in households for person in household . members ] adults = [ person for person in persons if person . age >= 18 ][ 0 : num_samples ] for person in adults : activity_sequence = person . activity_sequence activity_sequences . append ( activity_sequence ) if activity_sequence is not None : location_mapping = create_location_mapping ( person , random_location = random_location ) activities = activity_sequence . activities if activities : last_non_none_location = person . origin # Initialize with home location for i in range ( 0 , len ( activities ) - 2 , 2 ): origin_activity = activities [ i ] mode_activity = activities [ i + 1 ] destination_activity = activities [ i + 2 ] if i + 2 < len ( activities ) else origin_activity # Assigning locations origin = location_mapping . get ( origin_activity . purpose , last_non_none_location ) destination = location_mapping . get ( destination_activity . purpose ) # If destination is None due to \"Travel\", keep last_non_none_location for next origin if destination is not None : last_non_none_location = destination mode = mode_activity . mode # Append to OD pairs OD_pairs . append ([ origin , destination , mode , mode_activity , origin_activity . purpose , destination_activity . purpose ]) person_list . append ( person ) activity_sequence_list . append ( activity_sequence ) df = pd . DataFrame ( OD_pairs , columns = [ 'O' , 'D' , 'mode' , \"transit_activity\" , 'O_purpose' , 'D_purpose' ]) df [ 'person' ] = person_list df [ 'activity_sequence' ] = activity_sequence_list od_matrix = ODMatrix ( df ) od_matrix . activity_sequences = activity_sequences logger . info ( \"OD Matrix successfully created...\" ) return od_matrix","title":"generate_od_matrix"},{"location":"od/#tripsender.od.get_gdf","text":"A function to fetch spatial geometry from the PostGIS server as GeoPandas GeoDataFrame . This function is simply a wrapper for the psycopg2 module. It constructs an SQL query based on the the params provided and requests data from the server. :param area: (str) The name of the Primary area in the Model naming format. :param feature: (str) The feature name to select from the PostGIS database. (Refer to PostGIS naming convention) :param KEY: (str: Optional) An optional attribute to filter from the data at the server level :param VAL: (str: Optional) An optional value for a given key to match from the data at the server level :param title: (str: Optional) An optional title for the plot :param filter: (bool: Optional) An optional input to specify if the data must be filtered at the server level :param local: (bool: Optional) Which server to fetch the data from :param web: (bool: Optional) If True , the result will be reprojected :param plot: (bool: Optional) If True , the result will be plotted :return: (GeoPandas GeoDataFrame, plot(Optional)) The resulting GeoPandas GeoDataFrame . Source code in tripsender\\od.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def get_gdf ( area , #TODO Fix area naming convention to match PXWEB naming feature , KEY = '' , VAL = '' , title = 'Data from Server' , filter = False , local = True , web = True , plot = False , save = True ): \"\"\" A function to fetch spatial geometry from the ``PostGIS`` server as ``GeoPandas GeoDataFrame``. This function is simply a wrapper for the ``psycopg2`` module. It constructs an ``SQL`` query based on the the params provided and requests data from the server. :param area: (str) The name of the Primary area in the Model naming format. :param feature: (str) The feature name to select from the ``PostGIS`` database. (Refer to PostGIS naming convention) :param KEY: (str: Optional) An optional attribute to filter from the data at the server level :param VAL: (str: Optional) An optional value for a given key to match from the data at the server level :param title: (str: Optional) An optional title for the plot :param filter: (bool: Optional) An optional input to specify if the data must be filtered at the server level :param local: (bool: Optional) Which server to fetch the data from :param web: (bool: Optional) If ``True``, the result will be reprojected :param plot: (bool: Optional) If ``True``, the result will be plotted :return: (GeoPandas GeoDataFrame, plot(Optional)) The resulting `GeoPandas GeoDataFrame`. \"\"\" # If area has numbers in it, use re.search(r\"\\d+\\s*(.*)\", area).group(1) # Clean area name if any ( char . isdigit () for char in area ): area = re . search ( r \"\\d+\\s*(.*)\" , area ) . group ( 1 ) else : pass layer = '' if feature == 0 : layer = \"se_got_trs_roads_tv\" elif feature == 1 : layer = \"se_got_phy_buildingfootprint_lm\" selectInString = 'SELECT ' + layer + '.geom' for k in KEY : selectOutString = selectInString + ' , ' + layer + '.' + k selectInString = selectOutString SELECT = selectInString # Adding conditionals if filter : COND = ' \\' AND ' + layer + '.' + KEY [ 0 ] + ' = \\' ' + VAL else : COND = '' # Building SQL FROM = ' FROM ' + layer JOIN = ' JOIN se_got_bnd_admin10_osm ON ' CONTAIN = 'ST_Contains(se_got_bnd_admin10_osm.geom,' + layer + '.geom)' WHERE = ' WHERE se_got_bnd_admin10_osm.name = \\' ' + area + COND + ' \\' ;' sql = SELECT + FROM + JOIN + CONTAIN + WHERE ####logger.info(sql) # Get secrets con = get_pgcon ( local = local ) gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) # Switching database if web : result = gdf . to_crs ( \"EPSG:4326\" ) else : result = gdf # Plotting if plot : fig , ax = plt . subplots ( figsize = ( 10 , 10 )) fig . subplots_adjust ( right = 0.7 ) col = result . columns [ 1 ] title = area + ' ' + title ax . set_title ( title ) result . plot ( column = col , legend = True , legend_kwds = dict ( loc = 'upper left' , bbox_to_anchor = ( 1 , 1 )), ax = ax ) if save : plt . savefig ( 'static/' + area + '.png' ) return result","title":"get_gdf"},{"location":"od/#tripsender.od.get_landuse","text":"A function to fetch land use data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param clip: Geometry to clip the natural features. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the land use data. Source code in tripsender\\od.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def get_landuse ( local = False , web = False , clip = None , buffer_distance = 1000 ): \"\"\" A function to fetch land use data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param clip: Geometry to clip the natural features. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the land use data. \"\"\" con = get_pgcon ( local = local ) # Start with base SQL query to select all columns sql = 'SELECT * FROM se_got_phy_naturalfeatures_lm' # If a clipping polygon is provided, modify the SQL query to include a WHERE clause if clip is not None : # Validate the clip object is a Polygon and buffer it if isinstance ( clip , shapely . geometry . Polygon ): wkt = clip . buffer ( buffer_distance ) . wkt sql += f ' WHERE ST_Intersects(geom, ST_GeomFromText( \\' { wkt } \\' , 3006))' else : raise ValueError ( 'The clip parameter must be a Shapely Polygon.' ) # Fetch the data from the database try : gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) except Exception as e : raise ConnectionError ( f \"An error occurred while connecting to the database: { e } \" ) # Reproject if web is True if web : gdf = gdf . to_crs ( \"EPSG:4326\" ) return gdf","title":"get_landuse"},{"location":"od/#tripsender.od.get_pg_query","text":"A utility function that fetches any data using an SQL query from the PostGIS Server This function is a basic wrapper for the psycopg2 module with secrets included. :param sql: (str) An SQL query string :param local: (bool: Optional) If True , data will be fetched from the local server :param web: (bool: Optional) If True , result will be reprojected to EPSG:4326 :return: Source code in tripsender\\od.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 def get_pg_query ( sql , local = True , web = True ): \"\"\" A utility function that fetches any data using an ``SQL`` query from the ``PostGIS`` Server This function is a basic wrapper for the ``psycopg2`` module with secrets included. :param sql: (str) An SQL query string :param local: (bool: Optional) If ``True``, data will be fetched from the local server :param web: (bool: Optional) If ``True``, result will be reprojected to ``EPSG:4326`` :return: \"\"\" con = get_pgcon ( local = local ) ####logger.info(sql) gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) if web : result = gdf . to_crs ( \"EPSG:4326\" ) else : result = gdf return result","title":"get_pg_query"},{"location":"od/#tripsender.od.get_pgcon","text":"A helper function to read the .pgpass file. This is the authentication file for the PostGIS server. The function reads the file and returns a connection object to the PostGIS server. The server contains the spatial data for the region, including the road network and building footprints. :param local: (bool: Optional) If True , the function will connect to the local server. :return: (psycopg2 connection) A connection object to the PostGIS server. Source code in tripsender\\od.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_pgcon ( local = True ): \"\"\" A helper function to read the `.pgpass` file. This is the authentication file for the `PostGIS` server. The function reads the file and returns a connection object to the `PostGIS` server. The server contains the spatial data for the region, including the road network and building footprints. :param local: (bool: Optional) If ``True``, the function will connect to the local server. :return: (psycopg2 connection) A connection object to the `PostGIS` server. \"\"\" host , port , database , user , password = '' , '' , '' , '' , '' f = open ( \"secrets/.pgpass\" , \"r\" ) for i , line in enumerate ( f ): if i == local : host , port , database , user , password = line . split ( ':' ) # Create connection string con = psycopg2 . connect ( database = database . strip (), user = user . strip (), password = password . strip (), host = host . strip ()) return con","title":"get_pgcon"},{"location":"od/#tripsender.od.get_road","text":"A function to fetch road data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param ped: If True, pedestrian roads will be included in the result. :param clip: Geometry to clip the road data. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the road data. Source code in tripsender\\od.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def get_road ( local = True , web = True , ped = True , clip = None , buffer_distance = 1000 ): \"\"\" A function to fetch road data as a GeoPandas GeoDataFrame, with an option to clip it using a provided geometry and buffer the clip. :param local: If True, data will be fetched from the local server. :param web: If True, result will be reprojected to EPSG:4326. :param ped: If True, pedestrian roads will be included in the result. :param clip: Geometry to clip the road data. Expected to be a Shapely Polygon. :param buffer_distance: The distance to buffer around the clip geometry, default is 1000 meters. :return: A GeoDataFrame containing the road data. \"\"\" con = get_pgcon ( local = local ) # Initialize a list to hold individual queries queries = [] # Base SQL query for roads road_query = 'SELECT geom FROM se_got_trs_roads_tv' queries . append ( road_query ) # Add pedestrian roads if needed if ped : ped_query = 'SELECT geom FROM se_got_trs_path_tv' queries . append ( ped_query ) # Modify individual queries to clip with provided polygon if clip is not None : wkt = clip . buffer ( buffer_distance ) . wkt # Buffer 1km and convert Shapely Polygon to WKT # Apply the WHERE clause to each query queries = [ q + f \" WHERE ST_Intersects(geom, ST_GeomFromText(' { wkt } ', 3006))\" for q in queries ] # Combine the queries with UNION ALL sql = ' UNION ALL ' . join ( queries ) #print(\"Final SQL Query:\", sql) # Debugging line gdf = gpd . read_postgis ( sql = sql , con = con , geom_col = 'geom' ) if web : gdf = gdf . to_crs ( \"EPSG:4326\" ) return gdf","title":"get_road"},{"location":"od/#tripsender.od.mark_empty_buildings","text":"This function marks the buildings as empty if the population_total is 0. Source code in tripsender\\od.py 415 416 417 418 419 420 421 def mark_empty_buildings (): \"\"\" This function marks the buildings as empty if the population_total is 0. \"\"\" for building in Building . instances : if building . population_total == 0 : building . isEmpty = True","title":"mark_empty_buildings"},{"location":"od/#tripsender.od.process_residential_buildings","text":"This function processes the residential buildings to calculate the number of people living in each building. The function filters the buildings based on the area_per_person parameter and calculates the number of people living in each building. The function also calculates the number of floors in each building and the total Built-up Area (BTA) of each building. The function also assigns a UUID to each building. The data for the area_per_person parameter is based on the average living area per person in Sweden. Reference: https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ A service area factor is applied to the area of the building based on the building type. The service area factor is 0.85 for 'Flerfamiljshus' and 0.9 for all other building types. :param gdf_building: (GeoPandas GeoDataFrame) A GeoDataFrame containing the building footprints. :param area_per_person: (int: Optional) The area per person in square meters. Default is 36 m2. :return: (GeoPandas GeoDataFrame) A GeoDataFrame containing the processed residential buildings. Source code in tripsender\\od.py 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 def process_residential_buildings ( gdf_building , area_per_person = 36 ): \"\"\" This function processes the residential buildings to calculate the number of people living in each building. The function filters the buildings based on the area_per_person parameter and calculates the number of people living in each building. The function also calculates the number of floors in each building and the total Built-up Area (BTA) of each building. The function also assigns a UUID to each building. The data for the area_per_person parameter is based on the average living area per person in Sweden. Reference: https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ A service area factor is applied to the area of the building based on the building type. The service area factor is 0.85 for 'Flerfamiljshus' and 0.9 for all other building types. :param gdf_building: (GeoPandas GeoDataFrame) A GeoDataFrame containing the building footprints. :param area_per_person: (int: Optional) The area per person in square meters. Default is 36 m2. :return: (GeoPandas GeoDataFrame) A GeoDataFrame containing the processed residential buildings. \"\"\" # Average living area per person # https://www.scb.se/en/finding-statistics/statistics-by-subject-area/household-finances/income-and-income-distribution/households-housing/pong/statistical-news/households-housing-2019/ # Split andamal_1t by ';' and create a new column for each value, new columns are byggnadstyp and byggnadsundergrupp gdf_building [ 'byggnadstyp' ] = gdf_building [ 'andamal_1t' ] . str . split ( ';' ) . str [ 0 ] gdf_building [ 'byggnadsundergrupp' ] = gdf_building [ 'andamal_1t' ] . str . split ( '; ' ) . str [ 1 ] # Filter Bostad only gdf_residential = gdf_building [ gdf_building [ 'byggnadstyp' ] == 'Bostad' ] # Remove buildings with area less than area_per_person m2 gdf_residential = gdf_residential [ gdf_residential [ 'geom' ] . area > area_per_person ] # Plot the counts of each byggnadsundergrupp in gdf_residential #gdf_residential['byggnadsundergrupp'].value_counts().plot(kind='bar') # Get number of floors from height where each floor is 3m high and round up such that minimum floors is 1 gdf_residential [ 'floors' ] = gdf_residential [ 'height' ] . apply ( lambda x : round ( x / 3.5 , 0 )) . apply ( lambda x : max ( x , 1 )) # Get BTA by calculating area of the shape and multiply by number of floors and round down gdf_residential [ 'area' ] = gdf_residential [ 'geom' ] . area # Histo gram of areas for each byggnadsundergrupp #gdf_residential.hist(column='area', by='byggnadsundergrupp', bins=50, figsize=(20,15)) # If house is 'Flerfamiljshus', multiply by 0.85 to account for service areas gdf_residential . loc [ gdf_residential [ 'byggnadsundergrupp' ] == 'Flerfamiljshus' , 'area' ] = gdf_residential [ 'area' ] * 0.7 # For all other houses, multiply by 0.9 to account for service areas gdf_residential . loc [ gdf_residential [ 'byggnadsundergrupp' ] != 'Flerfamiljshus' , 'area' ] = gdf_residential [ 'area' ] * 0.8 # Get BTA by calculating area of the shape and multiply by number of floors and round down gdf_residential [ 'BTA' ] = gdf_residential [ 'area' ] * gdf_residential [ 'floors' ] . apply ( lambda x : round ( x )) # Add a column for number of people living in each building level (footprint_area/area_per_person) and round down gdf_residential [ 'population_per_floor' ] = gdf_residential [ 'area' ] . apply ( lambda x : round ( x / area_per_person )) # Add a column for number of people living in each building (people_per_floor * number of floors) gdf_residential [ 'population_total' ] = gdf_residential [ 'population_per_floor' ] * gdf_residential [ 'floors' ] # Add a uuid for each building using uuid4 # Added automatically on creating he class #gdf_residential['uuid'] = gdf_residential.apply(lambda x: uuid.uuid4(), axis=1) #gdf_residential.head() return gdf_residential","title":"process_residential_buildings"},{"location":"od/#tripsender.od.sort_buildings_by_type_and_population","text":"This function sorts the buildings by type and population into single family and multi family buildings Buildings are sorted by population in descending order. Note: Population is calculated as the number of people living in the building based on the area_per_person parameter. Returns: single_family_buildings (list): A list of single family buildings sorted by population multi_family_buildings (list): A list of multi family buildings sorted by population Source code in tripsender\\od.py 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 def sort_buildings_by_type_and_population (): \"\"\" This function sorts the buildings by type and population into single family and multi family buildings Buildings are sorted by population in descending order. Note: Population is calculated as the number of people living in the building based on the area_per_person parameter. Returns: single_family_buildings (list): A list of single family buildings sorted by population multi_family_buildings (list): A list of multi family buildings sorted by population \"\"\" single_family_house = [ 'Sm\u00e5hus friliggande' , 'Sm\u00e5hus kedjehus' , 'Sm\u00e5hus radhus' , 'Sm\u00e5hus med flera l\u00e4genheter' ] multi_family_house = [ 'Flerfamiljshus' ] single_family_buildings = [ building for building in Building . instances if building . type in single_family_house ] single_family_buildings . sort ( key = lambda x : x . population_total , reverse = True ) multi_family_buildings = [ building for building in Building . instances if building . type in multi_family_house ] multi_family_buildings . sort ( key = lambda x : x . population_total , reverse = True ) if len ( multi_family_buildings ) == 0 : ValueError ( \"No multi family buildings found\" ) if len ( single_family_buildings ) == 0 : ValueError ( \"No single family buildings found\" ) return single_family_buildings , multi_family_buildings","title":"sort_buildings_by_type_and_population"},{"location":"od/#tripsender.od.sort_households_by_type_and_count","text":"This function sorts the households by type and population into single family and multi family households Households are sorted by population in descending order. Returns: households_in_single_family_house (list): A list of single family households sorted by population households_in_multi_family_house (list): A list of multi family households sorted by population Source code in tripsender\\od.py 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 def sort_households_by_type_and_count (): \"\"\" This function sorts the households by type and population into single family and multi family households Households are sorted by population in descending order. Returns: households_in_single_family_house (list): A list of single family households sorted by population households_in_multi_family_house (list): A list of multi family households sorted by population \"\"\" households_in_single_family_house = [ household for household in Household . instances if household . house_type == 'Villa' ] households_in_single_family_house . sort ( key = lambda x : len ( x . members ), reverse = True ) households_in_multi_family_house = [ household for household in Household . instances if household . house_type in [ 'Apartment' , 'Other' ]] households_in_multi_family_house . sort ( key = lambda x : len ( x . members ), reverse = True ) return households_in_single_family_house , households_in_multi_family_house","title":"sort_households_by_type_and_count"},{"location":"person/","text":"Person Represents an individual with attributes like age, gender, household status, etc. A person object consists of demographic attributes such as age, sex, household type, and primary status (studying, working or inactive) and a unique identifier. Further, the person object is equipped with relational attributes such as a household identifier, the origin of the building they belong to, a parent identifier and a work location. Attributes: Name Type Description uuid UUID Unique identifier for the person. household_uuid Optional [ UUID ] Identifier for the person's household. parent_uuid List [ UUID ] Identifiers for the person's parents. age int Age of the person. sex str Gender of the person. household_type str Type of household the person belongs to. household Optional [ Household ] Household instance the person is part of. has_car bool Whether the person owns a car. child_count int Number of children the person has. is_head bool If the person is the head of the household. is_child bool If the person is a child in the household. origin Optional [ Point ] Origin of the person. activity_sequence Optional [ ActivitySequence ] Activity sequence associated with the person. instances list [ Person ] Class attribute to track all person instances. Source code in tripsender\\person.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 class Person : \"\"\" Represents an individual with attributes like age, gender, household status, etc. A person object consists of demographic attributes such as age, sex, household type, and primary status (studying, working or inactive) and a unique identifier. Further, the person object is equipped with relational attributes such as a household identifier, the origin of the building they belong to, a parent identifier and a work location. Attributes: uuid (uuid.UUID): Unique identifier for the person. household_uuid (Optional[uuid.UUID]): Identifier for the person's household. parent_uuid (List[uuid.UUID]): Identifiers for the person's parents. age (int): Age of the person. sex (str): Gender of the person. household_type (str): Type of household the person belongs to. household (Optional[Household]): Household instance the person is part of. has_car (bool): Whether the person owns a car. child_count (int): Number of children the person has. is_head (bool): If the person is the head of the household. is_child (bool): If the person is a child in the household. origin (Optional[Point]): Origin of the person. activity_sequence (Optional[ActivitySequence]): Activity sequence associated with the person. instances (list[Person]): Class attribute to track all person instances. \"\"\" instances : List [ 'Person' ] = [] def __init__ ( self , age : str , sex : str , household_type : str ): \"\"\"Initialize the Person with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . household_uuid : Optional [ uuid . UUID ] = None self . parent_uuid : List [ uuid . UUID ] = [] self . age : int = self . sample_from_bounds ( age ) self . sex : str = sex self . household_type : str = household_type # TODO: Rename to household_status? self . household : Optional [ Household ] = None self . has_car : bool = False # TODO: Check car logic self . child_count : int = 0 # TODO: Verify child count logic self . is_head : bool = False self . is_child : bool = False self . origin : Optional [ Point ] = None self . activity_sequence : Optional [ ActivitySequence ] = None self . primary_status : Optional [ str ] = None self . instances . append ( self ) self . age_group = age_group_from_age ( self . age ) self . work_location : Optional [ Point ] = None self . house_type = None self . has_child = False self . location_mapping = None def __repr__ ( self ): \"\"\"Representation of the Person instance.\"\"\" return f \"A { self . age } year old { self . sex } with { self . household_type } household status.\" def __str__ ( self ): \"\"\"String representation of the Person instance.\"\"\" sex = \"Male\" if self . sex == \"M\u00e4n\" else \"Female\" return f \"A { self . age } year old { sex } .\" def info ( self ): \"\"\"Retrieve a dictionary containing information about the person.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Household UUID\" : self . household_uuid , \"Parent UUID\" : self . parent_uuid , \"Age\" : self . age , \"Sex\" : self . sex , \"Household Type\" : self . household_type , \"Household\" : self . household . uuid if self . household else None , \"Is Head of household\" : self . is_head , \"Has Car\" : self . has_car , \"Has Child\" : self . has_child , \"Child Count\" : self . child_count , \"Origin\" : self . origin } return info_dict @classmethod def clear_instances ( cls ): \"\"\"Class method to clear all instances stored in the class.\"\"\" cls . instances = [] @classmethod def get_adults ( cls ): \"\"\"Class method to get all persons above 17 years of age.\"\"\" return [ person for person in cls . instances if person . age >= 17 ] @classmethod def return_adults_df ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" adult_df = pd . DataFrame ([ vars ( person ) for person in cls . get_adults ()]) # Create a column called Person that contains the Person instance adult_df [ 'Person' ] = cls . get_adults () return adult_df @classmethod def get_female ( cls ): \"\"\"Class method to get all female instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"Kvinnor\" ] @classmethod def get_male ( cls ): \"\"\"Class method to get all male instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"M\u00e4n\" ] @classmethod def return_dataframe ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" return pd . DataFrame ([ vars ( person ) for person in cls . instances ]) @staticmethod def sample_from_bounds ( bounds : str ) -> int : \"\"\" Static method to sample an age from a given range. Parameters: ----------- bounds : str A string representing the age range (e.g., '20-30'). Returns: -------- int A random age sampled from the given range. \"\"\" numbers = re . findall ( r '\\d+' , bounds ) if not numbers : raise ValueError ( f \"Invalid age bounds: { bounds } \" ) lower_bound = int ( numbers [ 0 ]) upper_bound = int ( numbers [ 1 ]) if len ( numbers ) > 1 else 100 return np . random . randint ( lower_bound , upper_bound + 1 ) __init__ ( age , sex , household_type ) Initialize the Person with given attributes. Source code in tripsender\\person.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def __init__ ( self , age : str , sex : str , household_type : str ): \"\"\"Initialize the Person with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . household_uuid : Optional [ uuid . UUID ] = None self . parent_uuid : List [ uuid . UUID ] = [] self . age : int = self . sample_from_bounds ( age ) self . sex : str = sex self . household_type : str = household_type # TODO: Rename to household_status? self . household : Optional [ Household ] = None self . has_car : bool = False # TODO: Check car logic self . child_count : int = 0 # TODO: Verify child count logic self . is_head : bool = False self . is_child : bool = False self . origin : Optional [ Point ] = None self . activity_sequence : Optional [ ActivitySequence ] = None self . primary_status : Optional [ str ] = None self . instances . append ( self ) self . age_group = age_group_from_age ( self . age ) self . work_location : Optional [ Point ] = None self . house_type = None self . has_child = False self . location_mapping = None __repr__ () Representation of the Person instance. Source code in tripsender\\person.py 82 83 84 def __repr__ ( self ): \"\"\"Representation of the Person instance.\"\"\" return f \"A { self . age } year old { self . sex } with { self . household_type } household status.\" __str__ () String representation of the Person instance. Source code in tripsender\\person.py 86 87 88 89 def __str__ ( self ): \"\"\"String representation of the Person instance.\"\"\" sex = \"Male\" if self . sex == \"M\u00e4n\" else \"Female\" return f \"A { self . age } year old { sex } .\" clear_instances () classmethod Class method to clear all instances stored in the class. Source code in tripsender\\person.py 110 111 112 113 @classmethod def clear_instances ( cls ): \"\"\"Class method to clear all instances stored in the class.\"\"\" cls . instances = [] get_adults () classmethod Class method to get all persons above 17 years of age. Source code in tripsender\\person.py 115 116 117 118 @classmethod def get_adults ( cls ): \"\"\"Class method to get all persons above 17 years of age.\"\"\" return [ person for person in cls . instances if person . age >= 17 ] get_female () classmethod Class method to get all female instances of the class. Source code in tripsender\\person.py 128 129 130 131 @classmethod def get_female ( cls ): \"\"\"Class method to get all female instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"Kvinnor\" ] get_male () classmethod Class method to get all male instances of the class. Source code in tripsender\\person.py 133 134 135 136 @classmethod def get_male ( cls ): \"\"\"Class method to get all male instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"M\u00e4n\" ] info () Retrieve a dictionary containing information about the person. Source code in tripsender\\person.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def info ( self ): \"\"\"Retrieve a dictionary containing information about the person.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Household UUID\" : self . household_uuid , \"Parent UUID\" : self . parent_uuid , \"Age\" : self . age , \"Sex\" : self . sex , \"Household Type\" : self . household_type , \"Household\" : self . household . uuid if self . household else None , \"Is Head of household\" : self . is_head , \"Has Car\" : self . has_car , \"Has Child\" : self . has_child , \"Child Count\" : self . child_count , \"Origin\" : self . origin } return info_dict return_adults_df () classmethod Class method to return a dataframe of all Person instances. Source code in tripsender\\person.py 120 121 122 123 124 125 126 @classmethod def return_adults_df ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" adult_df = pd . DataFrame ([ vars ( person ) for person in cls . get_adults ()]) # Create a column called Person that contains the Person instance adult_df [ 'Person' ] = cls . get_adults () return adult_df return_dataframe () classmethod Class method to return a dataframe of all Person instances. Source code in tripsender\\person.py 138 139 140 141 @classmethod def return_dataframe ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" return pd . DataFrame ([ vars ( person ) for person in cls . instances ]) sample_from_bounds ( bounds ) staticmethod Static method to sample an age from a given range. Parameters: bounds : str A string representing the age range (e.g., '20-30'). Returns: int A random age sampled from the given range. Source code in tripsender\\person.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 @staticmethod def sample_from_bounds ( bounds : str ) -> int : \"\"\" Static method to sample an age from a given range. Parameters: ----------- bounds : str A string representing the age range (e.g., '20-30'). Returns: -------- int A random age sampled from the given range. \"\"\" numbers = re . findall ( r '\\d+' , bounds ) if not numbers : raise ValueError ( f \"Invalid age bounds: { bounds } \" ) lower_bound = int ( numbers [ 0 ]) upper_bound = int ( numbers [ 1 ]) if len ( numbers ) > 1 else 100 return np . random . randint ( lower_bound , upper_bound + 1 )","title":"person"},{"location":"person/#tripsender.person.Person","text":"Represents an individual with attributes like age, gender, household status, etc. A person object consists of demographic attributes such as age, sex, household type, and primary status (studying, working or inactive) and a unique identifier. Further, the person object is equipped with relational attributes such as a household identifier, the origin of the building they belong to, a parent identifier and a work location. Attributes: Name Type Description uuid UUID Unique identifier for the person. household_uuid Optional [ UUID ] Identifier for the person's household. parent_uuid List [ UUID ] Identifiers for the person's parents. age int Age of the person. sex str Gender of the person. household_type str Type of household the person belongs to. household Optional [ Household ] Household instance the person is part of. has_car bool Whether the person owns a car. child_count int Number of children the person has. is_head bool If the person is the head of the household. is_child bool If the person is a child in the household. origin Optional [ Point ] Origin of the person. activity_sequence Optional [ ActivitySequence ] Activity sequence associated with the person. instances list [ Person ] Class attribute to track all person instances. Source code in tripsender\\person.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 class Person : \"\"\" Represents an individual with attributes like age, gender, household status, etc. A person object consists of demographic attributes such as age, sex, household type, and primary status (studying, working or inactive) and a unique identifier. Further, the person object is equipped with relational attributes such as a household identifier, the origin of the building they belong to, a parent identifier and a work location. Attributes: uuid (uuid.UUID): Unique identifier for the person. household_uuid (Optional[uuid.UUID]): Identifier for the person's household. parent_uuid (List[uuid.UUID]): Identifiers for the person's parents. age (int): Age of the person. sex (str): Gender of the person. household_type (str): Type of household the person belongs to. household (Optional[Household]): Household instance the person is part of. has_car (bool): Whether the person owns a car. child_count (int): Number of children the person has. is_head (bool): If the person is the head of the household. is_child (bool): If the person is a child in the household. origin (Optional[Point]): Origin of the person. activity_sequence (Optional[ActivitySequence]): Activity sequence associated with the person. instances (list[Person]): Class attribute to track all person instances. \"\"\" instances : List [ 'Person' ] = [] def __init__ ( self , age : str , sex : str , household_type : str ): \"\"\"Initialize the Person with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . household_uuid : Optional [ uuid . UUID ] = None self . parent_uuid : List [ uuid . UUID ] = [] self . age : int = self . sample_from_bounds ( age ) self . sex : str = sex self . household_type : str = household_type # TODO: Rename to household_status? self . household : Optional [ Household ] = None self . has_car : bool = False # TODO: Check car logic self . child_count : int = 0 # TODO: Verify child count logic self . is_head : bool = False self . is_child : bool = False self . origin : Optional [ Point ] = None self . activity_sequence : Optional [ ActivitySequence ] = None self . primary_status : Optional [ str ] = None self . instances . append ( self ) self . age_group = age_group_from_age ( self . age ) self . work_location : Optional [ Point ] = None self . house_type = None self . has_child = False self . location_mapping = None def __repr__ ( self ): \"\"\"Representation of the Person instance.\"\"\" return f \"A { self . age } year old { self . sex } with { self . household_type } household status.\" def __str__ ( self ): \"\"\"String representation of the Person instance.\"\"\" sex = \"Male\" if self . sex == \"M\u00e4n\" else \"Female\" return f \"A { self . age } year old { sex } .\" def info ( self ): \"\"\"Retrieve a dictionary containing information about the person.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Household UUID\" : self . household_uuid , \"Parent UUID\" : self . parent_uuid , \"Age\" : self . age , \"Sex\" : self . sex , \"Household Type\" : self . household_type , \"Household\" : self . household . uuid if self . household else None , \"Is Head of household\" : self . is_head , \"Has Car\" : self . has_car , \"Has Child\" : self . has_child , \"Child Count\" : self . child_count , \"Origin\" : self . origin } return info_dict @classmethod def clear_instances ( cls ): \"\"\"Class method to clear all instances stored in the class.\"\"\" cls . instances = [] @classmethod def get_adults ( cls ): \"\"\"Class method to get all persons above 17 years of age.\"\"\" return [ person for person in cls . instances if person . age >= 17 ] @classmethod def return_adults_df ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" adult_df = pd . DataFrame ([ vars ( person ) for person in cls . get_adults ()]) # Create a column called Person that contains the Person instance adult_df [ 'Person' ] = cls . get_adults () return adult_df @classmethod def get_female ( cls ): \"\"\"Class method to get all female instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"Kvinnor\" ] @classmethod def get_male ( cls ): \"\"\"Class method to get all male instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"M\u00e4n\" ] @classmethod def return_dataframe ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" return pd . DataFrame ([ vars ( person ) for person in cls . instances ]) @staticmethod def sample_from_bounds ( bounds : str ) -> int : \"\"\" Static method to sample an age from a given range. Parameters: ----------- bounds : str A string representing the age range (e.g., '20-30'). Returns: -------- int A random age sampled from the given range. \"\"\" numbers = re . findall ( r '\\d+' , bounds ) if not numbers : raise ValueError ( f \"Invalid age bounds: { bounds } \" ) lower_bound = int ( numbers [ 0 ]) upper_bound = int ( numbers [ 1 ]) if len ( numbers ) > 1 else 100 return np . random . randint ( lower_bound , upper_bound + 1 )","title":"Person"},{"location":"person/#tripsender.person.Person.__init__","text":"Initialize the Person with given attributes. Source code in tripsender\\person.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def __init__ ( self , age : str , sex : str , household_type : str ): \"\"\"Initialize the Person with given attributes.\"\"\" self . uuid : uuid . UUID = uuid . uuid4 () self . household_uuid : Optional [ uuid . UUID ] = None self . parent_uuid : List [ uuid . UUID ] = [] self . age : int = self . sample_from_bounds ( age ) self . sex : str = sex self . household_type : str = household_type # TODO: Rename to household_status? self . household : Optional [ Household ] = None self . has_car : bool = False # TODO: Check car logic self . child_count : int = 0 # TODO: Verify child count logic self . is_head : bool = False self . is_child : bool = False self . origin : Optional [ Point ] = None self . activity_sequence : Optional [ ActivitySequence ] = None self . primary_status : Optional [ str ] = None self . instances . append ( self ) self . age_group = age_group_from_age ( self . age ) self . work_location : Optional [ Point ] = None self . house_type = None self . has_child = False self . location_mapping = None","title":"__init__"},{"location":"person/#tripsender.person.Person.__repr__","text":"Representation of the Person instance. Source code in tripsender\\person.py 82 83 84 def __repr__ ( self ): \"\"\"Representation of the Person instance.\"\"\" return f \"A { self . age } year old { self . sex } with { self . household_type } household status.\"","title":"__repr__"},{"location":"person/#tripsender.person.Person.__str__","text":"String representation of the Person instance. Source code in tripsender\\person.py 86 87 88 89 def __str__ ( self ): \"\"\"String representation of the Person instance.\"\"\" sex = \"Male\" if self . sex == \"M\u00e4n\" else \"Female\" return f \"A { self . age } year old { sex } .\"","title":"__str__"},{"location":"person/#tripsender.person.Person.clear_instances","text":"Class method to clear all instances stored in the class. Source code in tripsender\\person.py 110 111 112 113 @classmethod def clear_instances ( cls ): \"\"\"Class method to clear all instances stored in the class.\"\"\" cls . instances = []","title":"clear_instances"},{"location":"person/#tripsender.person.Person.get_adults","text":"Class method to get all persons above 17 years of age. Source code in tripsender\\person.py 115 116 117 118 @classmethod def get_adults ( cls ): \"\"\"Class method to get all persons above 17 years of age.\"\"\" return [ person for person in cls . instances if person . age >= 17 ]","title":"get_adults"},{"location":"person/#tripsender.person.Person.get_female","text":"Class method to get all female instances of the class. Source code in tripsender\\person.py 128 129 130 131 @classmethod def get_female ( cls ): \"\"\"Class method to get all female instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"Kvinnor\" ]","title":"get_female"},{"location":"person/#tripsender.person.Person.get_male","text":"Class method to get all male instances of the class. Source code in tripsender\\person.py 133 134 135 136 @classmethod def get_male ( cls ): \"\"\"Class method to get all male instances of the class.\"\"\" return [ person for person in cls . instances if person . sex == \"M\u00e4n\" ]","title":"get_male"},{"location":"person/#tripsender.person.Person.info","text":"Retrieve a dictionary containing information about the person. Source code in tripsender\\person.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def info ( self ): \"\"\"Retrieve a dictionary containing information about the person.\"\"\" info_dict = { \"UUID\" : self . uuid , \"Household UUID\" : self . household_uuid , \"Parent UUID\" : self . parent_uuid , \"Age\" : self . age , \"Sex\" : self . sex , \"Household Type\" : self . household_type , \"Household\" : self . household . uuid if self . household else None , \"Is Head of household\" : self . is_head , \"Has Car\" : self . has_car , \"Has Child\" : self . has_child , \"Child Count\" : self . child_count , \"Origin\" : self . origin } return info_dict","title":"info"},{"location":"person/#tripsender.person.Person.return_adults_df","text":"Class method to return a dataframe of all Person instances. Source code in tripsender\\person.py 120 121 122 123 124 125 126 @classmethod def return_adults_df ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" adult_df = pd . DataFrame ([ vars ( person ) for person in cls . get_adults ()]) # Create a column called Person that contains the Person instance adult_df [ 'Person' ] = cls . get_adults () return adult_df","title":"return_adults_df"},{"location":"person/#tripsender.person.Person.return_dataframe","text":"Class method to return a dataframe of all Person instances. Source code in tripsender\\person.py 138 139 140 141 @classmethod def return_dataframe ( cls ): \"\"\"Class method to return a dataframe of all Person instances.\"\"\" return pd . DataFrame ([ vars ( person ) for person in cls . instances ])","title":"return_dataframe"},{"location":"person/#tripsender.person.Person.sample_from_bounds","text":"Static method to sample an age from a given range.","title":"sample_from_bounds"},{"location":"person/#tripsender.person.Person.sample_from_bounds--parameters","text":"bounds : str A string representing the age range (e.g., '20-30').","title":"Parameters:"},{"location":"person/#tripsender.person.Person.sample_from_bounds--returns","text":"int A random age sampled from the given range. Source code in tripsender\\person.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 @staticmethod def sample_from_bounds ( bounds : str ) -> int : \"\"\" Static method to sample an age from a given range. Parameters: ----------- bounds : str A string representing the age range (e.g., '20-30'). Returns: -------- int A random age sampled from the given range. \"\"\" numbers = re . findall ( r '\\d+' , bounds ) if not numbers : raise ValueError ( f \"Invalid age bounds: { bounds } \" ) lower_bound = int ( numbers [ 0 ]) upper_bound = int ( numbers [ 1 ]) if len ( numbers ) > 1 else 100 return np . random . randint ( lower_bound , upper_bound + 1 )","title":"Returns:"},{"location":"population/","text":"Population A class that represents population data for a specific year and area. This class facilitates the representation and manipulation of population data. It offers methods to initialize population arrays and provides easy access to various population metrics such as age, household type, sex, etc. Attributes: Name Type Description year int The year for which the population data is represented. area str The geographical area for which the population data is represented. variables List [ str ] List of variables associated with the population data. variable_categories List [ str ] List of categories for each variable. comment str Additional comments or notes associated with the population data. array_age_household_sex ndarray 3D array representing population data by age, household, and sex. array_age_sex ndarray 2D array representing population data by age and sex. array_age_household ndarray 2D array representing population data by age and household. Class Attributes instances (List[Population]): List to keep track of all instances of the Population class. Example population_2022_haga = Population(2023, \"Haga\") print(population_2022_haga.year) 2022 print(population_2022_haga.area) \"Haga\" Source code in tripsender\\population.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 class Population : \"\"\" A class that represents population data for a specific year and area. This class facilitates the representation and manipulation of population data. It offers methods to initialize population arrays and provides easy access to various population metrics such as age, household type, sex, etc. Attributes: year (int): The year for which the population data is represented. area (str): The geographical area for which the population data is represented. variables (List[str]): List of variables associated with the population data. variable_categories (List[str]): List of categories for each variable. comment (str): Additional comments or notes associated with the population data. array_age_household_sex (np.ndarray): 3D array representing population data by age, household, and sex. array_age_sex (np.ndarray): 2D array representing population data by age and sex. array_age_household (np.ndarray): 2D array representing population data by age and household. Other arrays... Class Attributes: instances (List[Population]): List to keep track of all instances of the Population class. Example: >>> population_2022_haga = Population(2023, \"Haga\") >>> print(population_2022_haga.year) 2022 >>> print(population_2022_haga.area) \"Haga\" \"\"\" instances : List [ 'Population' ] = [] def __init__ ( self , year : int , area : str ) -> None : \"\"\" Initializes the Population object by fetching the relevant data. Parameters: - year (int): The year for which the population data is required. - area (str): The geographical area for which the population data is required. Returns: None \"\"\" logger . info ( f \"Initializing Population object for year { year } and area { area } \" ) result : Dict [ str , Any ] = fetcher . fetch_population_data ( year , area ) data , year , area , variables , variable_categories , comment = self . _get_population_params ( result ) self . year : int = year self . area : str = area self . variables : List [ str ] = variables self . variable_categories : List [ str ] = variable_categories self . comment : str = comment # Initialize arrays self . array_age_household_sex : np . ndarray = np . array ([]) self . array_age_sex : np . ndarray = np . array ([]) self . array_age_household : np . ndarray = np . array ([]) self . array_sex_household : np . ndarray = np . array ([]) self . array_age_household_male : np . ndarray = np . array ([]) self . array_age_household_female : np . ndarray = np . array ([]) self . total_population : int = 0 self . instances . append ( self ) self . _instantiate ( data ) @classmethod def clear_instances ( cls ): cls . instances = [] @classmethod def info ( cls ): info = { \"description\" : \"A population class with information about the population in a given area and year\" , \"year\" : cls . instances [ 0 ] . year , \"area\" : cls . instances [ 0 ] . area , \"variables\" : cls . instances [ 0 ] . variables , \"variable_categories\" : cls . instances [ 0 ] . variable_categories , \"comment\" : cls . instances [ 0 ] . comment , \"total_population\" : cls . instances [ 0 ] . total_population } return info def _create_2d_array ( self , data , dimension1 , dimension2 , dimension3 = None ): categories_dim1 = np . unique ([ item [ 'key' ][ dimension1 ] for item in data ]) categories_dim2 = np . unique ([ item [ 'key' ][ dimension2 ] for item in data ]) if dimension3 != None : categories_dim3 = np . unique ([ item [ 'key' ][ dimension3 ] for item in data ]) if dimension3 else [ None ] array_2d = np . zeros (( len ( categories_dim1 ), len ( categories_dim2 ), len ( categories_dim3 )), dtype = int ) for item in data : if not dimension3 or item [ 'key' ][ dimension3 ] in categories_dim3 : index_dim1 = np . where ( categories_dim1 == item [ 'key' ][ dimension1 ])[ 0 ][ 0 ] index_dim2 = np . where ( categories_dim2 == item [ 'key' ][ dimension2 ])[ 0 ][ 0 ] index_dim3 = np . where ( categories_dim3 == item [ 'key' ][ dimension3 ])[ 0 ][ 0 ] if dimension3 else 0 array_2d [ index_dim1 , index_dim2 , index_dim3 ] += int ( item [ 'values' ][ 0 ]) else : categories_dim3 = [ None ] array_2d = np . zeros (( len ( categories_dim1 ), len ( categories_dim2 )), dtype = int ) for item in data : index_dim1 = np . where ( categories_dim1 == item [ 'key' ][ dimension1 ])[ 0 ][ 0 ] index_dim2 = np . where ( categories_dim2 == item [ 'key' ][ dimension2 ])[ 0 ][ 0 ] array_2d [ index_dim1 , index_dim2 ] += int ( item [ 'values' ][ 0 ]) return array_2d def _instantiate ( self , data : Dict [ str , Any ]) -> None : self . array_age_sex = self . _create_2d_array ( data , dimension1 = 1 , dimension2 = 2 ) self . array_age_household = self . _create_2d_array ( data , dimension1 = 1 , dimension2 = 3 ) self . array_sex_household = self . _create_2d_array ( data , dimension1 = 2 , dimension2 = 3 ) self . array_age_household_sex = self . _create_2d_array ( data , dimension1 = 1 , dimension2 = 3 , dimension3 = 2 ) self . array_age_household_female = self . array_age_household_sex [:,:, 0 ] self . array_age_household_male = self . array_age_household_sex [:,:, 1 ] # Calculate the total population by summing all the values in each array total_alder_kon = np . sum ( self . array_age_sex ) total_alder_hushall = np . sum ( self . array_age_household ) total_kon_hushall = np . sum ( self . array_sex_household ) # Checking if the totals are equal if total_alder_kon == total_alder_hushall and total_alder_kon == total_kon_hushall : self . total_population = total_alder_kon else : self . total_population = None logger . info ( \"Total population could not be calculated\" ) def _get_population_params ( self , result : Dict [ str , Any ]) -> Tuple : \"\"\" Extracts population parameters from the given result. Parameters: - result (Dict[str, Any]): The fetched result containing population data. Returns: Tuple: Extracted data, year, area, variables, variable_categories, and comment. \"\"\" json_data = result # Extract the relevant data from the JSON data = json_data [ \"data\" ] logger . info ( data ) # Extract additional attributes year = data [ 0 ][ 'key' ][ 4 ] area = data [ 0 ][ 'key' ][ 0 ] variables = [ column [ 'code' ] for column in json_data [ 'columns' ] if column [ 'type' ] == 'd' ] variable_categories = { column [ 'code' ]: np . unique ([ item [ 'key' ][ i ] for item in data ]) for i , column in enumerate ( json_data [ 'columns' ]) if column [ 'type' ] == 'd' } comment = json_data [ 'columns' ][ 3 ][ 'comment' ] return data , year , area , variables , variable_categories , comment __init__ ( year , area ) Initializes the Population object by fetching the relevant data. Parameters: - year (int): The year for which the population data is required. - area (str): The geographical area for which the population data is required. Returns: None Source code in tripsender\\population.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def __init__ ( self , year : int , area : str ) -> None : \"\"\" Initializes the Population object by fetching the relevant data. Parameters: - year (int): The year for which the population data is required. - area (str): The geographical area for which the population data is required. Returns: None \"\"\" logger . info ( f \"Initializing Population object for year { year } and area { area } \" ) result : Dict [ str , Any ] = fetcher . fetch_population_data ( year , area ) data , year , area , variables , variable_categories , comment = self . _get_population_params ( result ) self . year : int = year self . area : str = area self . variables : List [ str ] = variables self . variable_categories : List [ str ] = variable_categories self . comment : str = comment # Initialize arrays self . array_age_household_sex : np . ndarray = np . array ([]) self . array_age_sex : np . ndarray = np . array ([]) self . array_age_household : np . ndarray = np . array ([]) self . array_sex_household : np . ndarray = np . array ([]) self . array_age_household_male : np . ndarray = np . array ([]) self . array_age_household_female : np . ndarray = np . array ([]) self . total_population : int = 0 self . instances . append ( self ) self . _instantiate ( data )","title":"population"},{"location":"population/#tripsender.population.Population","text":"A class that represents population data for a specific year and area. This class facilitates the representation and manipulation of population data. It offers methods to initialize population arrays and provides easy access to various population metrics such as age, household type, sex, etc. Attributes: Name Type Description year int The year for which the population data is represented. area str The geographical area for which the population data is represented. variables List [ str ] List of variables associated with the population data. variable_categories List [ str ] List of categories for each variable. comment str Additional comments or notes associated with the population data. array_age_household_sex ndarray 3D array representing population data by age, household, and sex. array_age_sex ndarray 2D array representing population data by age and sex. array_age_household ndarray 2D array representing population data by age and household. Class Attributes instances (List[Population]): List to keep track of all instances of the Population class. Example population_2022_haga = Population(2023, \"Haga\") print(population_2022_haga.year) 2022 print(population_2022_haga.area) \"Haga\" Source code in tripsender\\population.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 class Population : \"\"\" A class that represents population data for a specific year and area. This class facilitates the representation and manipulation of population data. It offers methods to initialize population arrays and provides easy access to various population metrics such as age, household type, sex, etc. Attributes: year (int): The year for which the population data is represented. area (str): The geographical area for which the population data is represented. variables (List[str]): List of variables associated with the population data. variable_categories (List[str]): List of categories for each variable. comment (str): Additional comments or notes associated with the population data. array_age_household_sex (np.ndarray): 3D array representing population data by age, household, and sex. array_age_sex (np.ndarray): 2D array representing population data by age and sex. array_age_household (np.ndarray): 2D array representing population data by age and household. Other arrays... Class Attributes: instances (List[Population]): List to keep track of all instances of the Population class. Example: >>> population_2022_haga = Population(2023, \"Haga\") >>> print(population_2022_haga.year) 2022 >>> print(population_2022_haga.area) \"Haga\" \"\"\" instances : List [ 'Population' ] = [] def __init__ ( self , year : int , area : str ) -> None : \"\"\" Initializes the Population object by fetching the relevant data. Parameters: - year (int): The year for which the population data is required. - area (str): The geographical area for which the population data is required. Returns: None \"\"\" logger . info ( f \"Initializing Population object for year { year } and area { area } \" ) result : Dict [ str , Any ] = fetcher . fetch_population_data ( year , area ) data , year , area , variables , variable_categories , comment = self . _get_population_params ( result ) self . year : int = year self . area : str = area self . variables : List [ str ] = variables self . variable_categories : List [ str ] = variable_categories self . comment : str = comment # Initialize arrays self . array_age_household_sex : np . ndarray = np . array ([]) self . array_age_sex : np . ndarray = np . array ([]) self . array_age_household : np . ndarray = np . array ([]) self . array_sex_household : np . ndarray = np . array ([]) self . array_age_household_male : np . ndarray = np . array ([]) self . array_age_household_female : np . ndarray = np . array ([]) self . total_population : int = 0 self . instances . append ( self ) self . _instantiate ( data ) @classmethod def clear_instances ( cls ): cls . instances = [] @classmethod def info ( cls ): info = { \"description\" : \"A population class with information about the population in a given area and year\" , \"year\" : cls . instances [ 0 ] . year , \"area\" : cls . instances [ 0 ] . area , \"variables\" : cls . instances [ 0 ] . variables , \"variable_categories\" : cls . instances [ 0 ] . variable_categories , \"comment\" : cls . instances [ 0 ] . comment , \"total_population\" : cls . instances [ 0 ] . total_population } return info def _create_2d_array ( self , data , dimension1 , dimension2 , dimension3 = None ): categories_dim1 = np . unique ([ item [ 'key' ][ dimension1 ] for item in data ]) categories_dim2 = np . unique ([ item [ 'key' ][ dimension2 ] for item in data ]) if dimension3 != None : categories_dim3 = np . unique ([ item [ 'key' ][ dimension3 ] for item in data ]) if dimension3 else [ None ] array_2d = np . zeros (( len ( categories_dim1 ), len ( categories_dim2 ), len ( categories_dim3 )), dtype = int ) for item in data : if not dimension3 or item [ 'key' ][ dimension3 ] in categories_dim3 : index_dim1 = np . where ( categories_dim1 == item [ 'key' ][ dimension1 ])[ 0 ][ 0 ] index_dim2 = np . where ( categories_dim2 == item [ 'key' ][ dimension2 ])[ 0 ][ 0 ] index_dim3 = np . where ( categories_dim3 == item [ 'key' ][ dimension3 ])[ 0 ][ 0 ] if dimension3 else 0 array_2d [ index_dim1 , index_dim2 , index_dim3 ] += int ( item [ 'values' ][ 0 ]) else : categories_dim3 = [ None ] array_2d = np . zeros (( len ( categories_dim1 ), len ( categories_dim2 )), dtype = int ) for item in data : index_dim1 = np . where ( categories_dim1 == item [ 'key' ][ dimension1 ])[ 0 ][ 0 ] index_dim2 = np . where ( categories_dim2 == item [ 'key' ][ dimension2 ])[ 0 ][ 0 ] array_2d [ index_dim1 , index_dim2 ] += int ( item [ 'values' ][ 0 ]) return array_2d def _instantiate ( self , data : Dict [ str , Any ]) -> None : self . array_age_sex = self . _create_2d_array ( data , dimension1 = 1 , dimension2 = 2 ) self . array_age_household = self . _create_2d_array ( data , dimension1 = 1 , dimension2 = 3 ) self . array_sex_household = self . _create_2d_array ( data , dimension1 = 2 , dimension2 = 3 ) self . array_age_household_sex = self . _create_2d_array ( data , dimension1 = 1 , dimension2 = 3 , dimension3 = 2 ) self . array_age_household_female = self . array_age_household_sex [:,:, 0 ] self . array_age_household_male = self . array_age_household_sex [:,:, 1 ] # Calculate the total population by summing all the values in each array total_alder_kon = np . sum ( self . array_age_sex ) total_alder_hushall = np . sum ( self . array_age_household ) total_kon_hushall = np . sum ( self . array_sex_household ) # Checking if the totals are equal if total_alder_kon == total_alder_hushall and total_alder_kon == total_kon_hushall : self . total_population = total_alder_kon else : self . total_population = None logger . info ( \"Total population could not be calculated\" ) def _get_population_params ( self , result : Dict [ str , Any ]) -> Tuple : \"\"\" Extracts population parameters from the given result. Parameters: - result (Dict[str, Any]): The fetched result containing population data. Returns: Tuple: Extracted data, year, area, variables, variable_categories, and comment. \"\"\" json_data = result # Extract the relevant data from the JSON data = json_data [ \"data\" ] logger . info ( data ) # Extract additional attributes year = data [ 0 ][ 'key' ][ 4 ] area = data [ 0 ][ 'key' ][ 0 ] variables = [ column [ 'code' ] for column in json_data [ 'columns' ] if column [ 'type' ] == 'd' ] variable_categories = { column [ 'code' ]: np . unique ([ item [ 'key' ][ i ] for item in data ]) for i , column in enumerate ( json_data [ 'columns' ]) if column [ 'type' ] == 'd' } comment = json_data [ 'columns' ][ 3 ][ 'comment' ] return data , year , area , variables , variable_categories , comment","title":"Population"},{"location":"population/#tripsender.population.Population.__init__","text":"Initializes the Population object by fetching the relevant data. Parameters: - year (int): The year for which the population data is required. - area (str): The geographical area for which the population data is required. Returns: None Source code in tripsender\\population.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def __init__ ( self , year : int , area : str ) -> None : \"\"\" Initializes the Population object by fetching the relevant data. Parameters: - year (int): The year for which the population data is required. - area (str): The geographical area for which the population data is required. Returns: None \"\"\" logger . info ( f \"Initializing Population object for year { year } and area { area } \" ) result : Dict [ str , Any ] = fetcher . fetch_population_data ( year , area ) data , year , area , variables , variable_categories , comment = self . _get_population_params ( result ) self . year : int = year self . area : str = area self . variables : List [ str ] = variables self . variable_categories : List [ str ] = variable_categories self . comment : str = comment # Initialize arrays self . array_age_household_sex : np . ndarray = np . array ([]) self . array_age_sex : np . ndarray = np . array ([]) self . array_age_household : np . ndarray = np . array ([]) self . array_sex_household : np . ndarray = np . array ([]) self . array_age_household_male : np . ndarray = np . array ([]) self . array_age_household_female : np . ndarray = np . array ([]) self . total_population : int = 0 self . instances . append ( self ) self . _instantiate ( data )","title":"__init__"},{"location":"routing/","text":"NetworkRoutingComputer A class to compute network routes based on a specified mode of transportation. This class provides methods to find the closest source and target nodes, compute routes, and manage the graph structure for routing. Attributes: Name Type Description mode str The mode of transportation ('walk', 'bike', 'drive'). G_ig Graph The graph representing the transportation network. v_coordinates list List of vertex coordinates in the graph. A ndarray Array of vertex coordinates. tree cKDTree KDTree for spatial indexing of vertex coordinates. names list List of vertex names. weights list List of edge weights in the graph. route_cache dict Cache to store computed routes. speed_factor int Factor to adjust travel speed based on the mode of transportation. Methods: Name Description get_closest_source_target Find the closest source and target nodes in the graph for the given coordinates. path_to_linestring Convert a path in the graph to a LineString. compute_route Compute the route and travel time between source and target coordinates. Source code in tripsender\\routing.py 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 class NetworkRoutingComputer : \"\"\" A class to compute network routes based on a specified mode of transportation. This class provides methods to find the closest source and target nodes, compute routes, and manage the graph structure for routing. Attributes: mode (str): The mode of transportation ('walk', 'bike', 'drive'). G_ig (igraph.Graph): The graph representing the transportation network. v_coordinates (list): List of vertex coordinates in the graph. A (ndarray): Array of vertex coordinates. tree (cKDTree): KDTree for spatial indexing of vertex coordinates. names (list): List of vertex names. weights (list): List of edge weights in the graph. route_cache (dict): Cache to store computed routes. speed_factor (int): Factor to adjust travel speed based on the mode of transportation. Methods: get_closest_source_target(source_coord, target_coord): Find the closest source and target nodes in the graph for the given coordinates. path_to_linestring(path_indices, G_ig, s, t): Convert a path in the graph to a LineString. compute_route(source_coord, target_coord, mode='walk'): Compute the route and travel time between source and target coordinates. \"\"\" def __init__ ( self , mode , speed_factor = 4 ): self . mode = mode self . G_ig = io . fetch_igraph ( mode ) self . v_coordinates = get_vertex_coords ( self . G_ig ) self . A = np . array ( self . v_coordinates ) self . tree = cKDTree ( self . A ) self . names = [ f \"( { x } , { y } )\" for x , y in self . v_coordinates ] self . G_ig . vs [ \"name\" ] = self . names if mode in [ 'active' , 'walk' , 'bike' ]: self . edge_length = get_edge_lengths ( self . G_ig ) self . weights = self . edge_length elif mode == 'drive' : self . edge_travel_time = get_edge_travel_time ( self . G_ig ) self . weights = self . edge_travel_time else : raise ValueError ( f \"Mode must be one of 'walk', 'bike' or 'drive', got { mode } instead.\" ) self . G_ig . es [ \"weight\" ] = self . weights self . route_cache = {} self . speed_factor = speed_factor def get_closest_source_target ( self , source_coord , target_coord ): # Convert the POINT object to a list of coordinates for the source. source = [ source_coord . x , source_coord . y ] # Query the KDTree to find the index of the closest node to the source. _ , source_index = self . tree . query ([ source ], k = 1 ) target = [ target_coord . x , target_coord . y ] # Query the KDTree to find the indices of the closest nodes to the targets. _ , target_index = self . tree . query ([ target ], k = 1 ) # Retrieve the closest source and target nodes from the graph using indices closest_source = self . G_ig . vs [ source_index [ 0 ]][ \"name\" ] closest_target = self . G_ig . vs [ target_index [ 0 ]][ \"name\" ] return closest_source , closest_target def path_to_linestring ( self , path_indices , G_ig , s , t ): # End the script if the path is empty or has only one point. if not path_indices : raise ValueError ( \"path_to_linestring: The routing has returned an empty path or a single point, which is not sufficient for creating a LineString\" ) # Extract the coordinates of the path vertices = G_ig . vs [ path_indices ] x = vertices [ \"x\" ] y = vertices [ \"y\" ] if len ( x ) < 2 : # Check if source and destination are the same if s == t : return Point ( x [ 0 ], y [ 0 ]) else : raise ValueError ( f \"path_to_linestring: The routing has returned a path with only one point. { s , t } \" ) # Create the LineString for the path line = LineString ( zip ( x , y )) return line def compute_route ( self , source_coord , target_coord , mode = 'walk' ): linestring , travel_time = None , None # Default values in case of early return # Check if any of the coordinates is None if source_coord is None or target_coord is None : #logger.info(f\"One of the coordinates is None. Returning None for linestring and travel time. Got {source_coord} and {target_coord} instead.\") return linestring , travel_time # Check if source and target coordinates are the same if source_coord == target_coord : # Create a linestring with 10m length and 0 travel time dummy_target = Point ( target_coord . x + 0.0001 , target_coord . y + 0.0001 ) linestring = LineString ([ source_coord , dummy_target ]) travel_time = 0 #logger.info(f\"Source and target coordinates are the same. Returning a point for linestring and 0 for travel time. Got {source_coord} and {target_coord} instead.\") return linestring , travel_time # Check if source and target are of type Point if not isinstance ( source_coord , Point ) or not isinstance ( target_coord , Point ): #logger.info(f\"Source and target coordinates must be of type Point. Returning None for linestring and travel time. Got {source_coord} and {target_coord} instead.\") return linestring , travel_time # Main route computation block try : closest_source , closest_target = self . get_closest_source_target ( source_coord , target_coord ) path_indices = self . G_ig . get_shortest_path ( closest_source , closest_target , weights = \"weight\" , mode = \"out\" , output = \"vpath\" ) linestring = self . path_to_linestring ( path_indices , self . G_ig , closest_source , closest_target ) linestring = complete_linestring ( linestring , source_coord , target_coord ) distance = linestring . length travel_time = (( distance / 1000 ) / ( self . speed_factor )) * 60 #travel_time = speed_factor * distance / 1000 except Exception as e : logger . error ( f \"Error computing route: { e } between { source_coord } and { target_coord } \" ) # Optionally, set linestring and travel_time to None or a default value here return linestring , travel_time TransitMatrixComputer Source code in tripsender\\routing.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 class TransitMatrixComputer : def __init__ ( self , hdf5_path = hdf5_path , origins_gdf = origins_gdf ): \"\"\" A class to compute and manage a transit matrix, providing travel times between origin-destination pairs. This class preprocesses data from an HDF5 file and uses a KDTree for fast lookup of travel times. It also provides methods to query travel times and compute routes between coordinates. Attributes: hdf5_path (str): Path to the HDF5 file containing the transit data. travel_times_dict (dict): Dictionary to store travel times between origin-destination pairs. origins_gdf (GeoDataFrame): GeoDataFrame containing origin points. points (ndarray): Array of coordinates extracted from the origins_gdf. tree (KDTree): KDTree for spatial indexing of origin points. ids (ndarray): Array of IDs corresponding to the origin points. Methods: preprocess_data(): Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. get_closest_id_tree(lat, lon): Get the closest origin ID to the given latitude and longitude using the KDTree. query_travel_time(o, d): Query the travel time between two coordinates. compute_route(source_coord, target_coord): Compute the route and travel time between source and target coordinates. \"\"\" self . hdf5_path = hdf5_path self . travel_times_dict = {} self . origins_gdf = origins_gdf self . points = np . array ( self . origins_gdf [[ 'geometry' ]] . apply ( lambda x : [ x [ 0 ] . x , x [ 0 ] . y ], axis = 1 ) . tolist ()) self . tree = KDTree ( self . points ) self . ids = self . origins_gdf [ 'id' ] . to_numpy () self . preprocess_data () def preprocess_data ( self ): \"\"\"Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups.\"\"\" with h5py . File ( self . hdf5_path , 'r' ) as hdf5_file : # Proceed with the existing logic if datasets are present dataset_size = hdf5_file [ 'from_id' ] . shape [ 0 ] batch_size = 10000 # Adjust based on your system's memory capacity for i in range ( 0 , dataset_size , batch_size ): from_ids = hdf5_file [ 'from_id' ][ i : i + batch_size ] to_ids = hdf5_file [ 'to_id' ][ i : i + batch_size ] travel_times = hdf5_file [ 'travel_time' ][ i : i + batch_size ] for from_id , to_id , travel_time in zip ( from_ids , to_ids , travel_times ): self . travel_times_dict [( from_id , to_id )] = travel_time def get_closest_id_tree ( self , lat , lon ): dist , closest_idx = self . tree . query ([[ lon , lat ]], k = 1 ) # Ensure k=1 for clarity # Since closest_idx is a 1D array with a single element, access it directly closest_id = self . ids [ closest_idx ][ 0 ] # Access the first element since closest_idx is 1D return closest_id def query_travel_time ( self , o , d ): # Get closest id origin_closest_id = self . get_closest_id_tree ( o . y , o . x ) # Get closest id destination_closest_id = self . get_closest_id_tree ( d . y , d . x ) # Query the travel time for a given origin and destination ID pair. travel_time = self . travel_times_dict . get (( origin_closest_id , destination_closest_id ), None ) return travel_time def compute_route ( self , source_coord , target_coord ): linestring , travel_time = None , None # Default values in case of early return # Correctly check if any of the coordinates is None if source_coord is None or target_coord is None : #logger.info(\"One of the coordinates is None. Returning None for linestring and travel time.\") return linestring , travel_time # Check if source and target coordinates are the same if source_coord == target_coord : dummy_target = Point ( target_coord . x + 0.0001 , target_coord . y + 0.0001 ) linestring = LineString ([ source_coord , dummy_target ]) travel_time = 0 #logger.info(\"Source and target coordinates are the same. Returning a point for linestring and 0 for travel time.\") return linestring , travel_time # Main route computation block try : # Return a straight line between the source and target coordinates linestring = LineString ([ source_coord , target_coord ]) # Complete the linestring if necessary (this function should handle its own errors or be wrapped in try-except if it can raise exceptions) linestring = complete_linestring ( linestring , source_coord , target_coord ) # Query travel time (this function should also handle its own errors or be wrapped in try-except) travel_time = self . query_travel_time ( source_coord , target_coord ) except Exception as e : logger . error ( f \"Error computing route: { e } \" ) # Optionally, set linestring and travel_time to None or a default value here return linestring , travel_time __init__ ( hdf5_path = hdf5_path , origins_gdf = origins_gdf ) A class to compute and manage a transit matrix, providing travel times between origin-destination pairs. This class preprocesses data from an HDF5 file and uses a KDTree for fast lookup of travel times. It also provides methods to query travel times and compute routes between coordinates. Attributes: Name Type Description hdf5_path str Path to the HDF5 file containing the transit data. travel_times_dict dict Dictionary to store travel times between origin-destination pairs. origins_gdf GeoDataFrame GeoDataFrame containing origin points. points ndarray Array of coordinates extracted from the origins_gdf. tree KDTree KDTree for spatial indexing of origin points. ids ndarray Array of IDs corresponding to the origin points. Functions: Name Description preprocess_data Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. get_closest_id_tree Get the closest origin ID to the given latitude and longitude using the KDTree. query_travel_time Query the travel time between two coordinates. compute_route Compute the route and travel time between source and target coordinates. Source code in tripsender\\routing.py 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 def __init__ ( self , hdf5_path = hdf5_path , origins_gdf = origins_gdf ): \"\"\" A class to compute and manage a transit matrix, providing travel times between origin-destination pairs. This class preprocesses data from an HDF5 file and uses a KDTree for fast lookup of travel times. It also provides methods to query travel times and compute routes between coordinates. Attributes: hdf5_path (str): Path to the HDF5 file containing the transit data. travel_times_dict (dict): Dictionary to store travel times between origin-destination pairs. origins_gdf (GeoDataFrame): GeoDataFrame containing origin points. points (ndarray): Array of coordinates extracted from the origins_gdf. tree (KDTree): KDTree for spatial indexing of origin points. ids (ndarray): Array of IDs corresponding to the origin points. Methods: preprocess_data(): Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. get_closest_id_tree(lat, lon): Get the closest origin ID to the given latitude and longitude using the KDTree. query_travel_time(o, d): Query the travel time between two coordinates. compute_route(source_coord, target_coord): Compute the route and travel time between source and target coordinates. \"\"\" self . hdf5_path = hdf5_path self . travel_times_dict = {} self . origins_gdf = origins_gdf self . points = np . array ( self . origins_gdf [[ 'geometry' ]] . apply ( lambda x : [ x [ 0 ] . x , x [ 0 ] . y ], axis = 1 ) . tolist ()) self . tree = KDTree ( self . points ) self . ids = self . origins_gdf [ 'id' ] . to_numpy () self . preprocess_data () preprocess_data () Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. Source code in tripsender\\routing.py 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 def preprocess_data ( self ): \"\"\"Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups.\"\"\" with h5py . File ( self . hdf5_path , 'r' ) as hdf5_file : # Proceed with the existing logic if datasets are present dataset_size = hdf5_file [ 'from_id' ] . shape [ 0 ] batch_size = 10000 # Adjust based on your system's memory capacity for i in range ( 0 , dataset_size , batch_size ): from_ids = hdf5_file [ 'from_id' ][ i : i + batch_size ] to_ids = hdf5_file [ 'to_id' ][ i : i + batch_size ] travel_times = hdf5_file [ 'travel_time' ][ i : i + batch_size ] for from_id , to_id , travel_time in zip ( from_ids , to_ids , travel_times ): self . travel_times_dict [( from_id , to_id )] = travel_time compute_edge_weights ( coords , edge_length , dem_raster_path , landuse_vector , convex_hull ) Compute edge weights for the graph based on edge length, slope, and proximity to natural features. Parameters: Name Type Description Default coords list List of coordinates for each edge. required edge_length list List of edge lengths. required dem_raster_path str Path to the DEM raster file. required landuse_vector GeoDataFrame Land use vector data. required convex_hull Polygon Convex hull for clipping. required Returns: Name Type Description list Computed edge weights. Source code in tripsender\\routing.py 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def compute_edge_weights ( coords , edge_length , dem_raster_path , landuse_vector , convex_hull ): \"\"\" Compute edge weights for the graph based on edge length, slope, and proximity to natural features. Args: coords (list): List of coordinates for each edge. edge_length (list): List of edge lengths. dem_raster_path (str): Path to the DEM raster file. landuse_vector (GeoDataFrame): Land use vector data. convex_hull (Polygon): Convex hull for clipping. Returns: list: Computed edge weights. \"\"\" # Clip the DEM raster to the area of interest defined by the convex hull clipped_dem , out_transform , out_meta = read_and_clip_raster ( dem_raster_path , convex_hull ) # Process the land use vector data, clipping it to the same area and creating a gradient processed_landuse = process_landuse_data ( landuse_vector , convex_hull , out_meta [ 'crs' ]) normalize_nature_raster = create_gradient ( processed_landuse , clipped_dem . shape [ 1 :], out_transform ) average_nature_values = [] height_difference = [] # Iterate over each street segment to compute the average gradient and slope for line_coords in coords : if len ( line_coords ) > 1 : # Get the raster values at the start and end of the street segment #print(\"Calculating dem absolute difference\") absolute_difference = raster_value_at_line_ends ( clipped_dem [ 0 ], out_transform , line_coords [ 0 ], line_coords [ - 1 ], value_type = 'absolute_difference' ) #print(\"Calculating landuse average\") average_value = raster_value_at_line_ends ( normalize_nature_raster , out_transform , line_coords [ 0 ], line_coords [ - 1 ], value_type = 'average' ) average_nature_values . append ( average_value ) height_difference . append ( absolute_difference ) slope = [ x / y for x , y in zip ( height_difference , edge_length )] norm_edge_length = normalise_list ( edge_length ) norm_distance_nature = normalise_list ( average_nature_values ) norm_slope = normalise_list ( slope ) weights = [ COEF_LENGTH * norm_edge_length [ i ] + COEF_NATURE * norm_distance_nature [ i ] + COEF_SLOPE * norm_slope [ i ] for i in range ( len ( edge_length ))] # Return the edge lengths and computed weight factors for further processing return weights compute_routes_for_all_buildings ( mode = 'walk' , parallel = False ) Compute routes for all buildings in the dataset. Parameters: Name Type Description Default mode str Mode of transportation ('walk', 'bike', 'drive'). Defaults to 'walk'. 'walk' parallel bool Whether to process buildings in parallel. Defaults to False. False Source code in tripsender\\routing.py 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 def compute_routes_for_all_buildings ( mode = 'walk' , parallel = False ): # landuse_vector, convex_hull, \"\"\" Compute routes for all buildings in the dataset. Args: mode (str): Mode of transportation ('walk', 'bike', 'drive'). Defaults to 'walk'. parallel (bool): Whether to process buildings in parallel. Defaults to False. \"\"\" #Fetch the iGraph G_ig = io . fetch_igraph ( mode ) # Build a KDTree for spatial indexing logger . info ( \"Building KDTree for spatial indexing...\" ) v_coordinates = get_vertex_coords ( G_ig ) A = np . array ( v_coordinates ) tree = cKDTree ( A ) # Set names for vertices in the form \"(x,y)\" names = [ f \"( { x } , { y } )\" for x , y in v_coordinates ] G_ig . vs [ \"name\" ] = names # Set weights based on mode if mode in [ 'walk' , 'bike' ]: #e_coordinates = get_edge_coords(G_ig) edge_length = get_edge_lengths ( G_ig ) weights = edge_length #compute_edge_weights(e_coordinates, edge_length, dem_raster_path, landuse_vector, convex_hull) elif mode == 'drive' : edge_travel_time = get_edge_travel_time ( G_ig ) weights = edge_travel_time else : raise ValueError ( f \"Mode must be one of 'walk', 'bike' or 'drive', got { mode } instead.\" ) G_ig . es [ \"weight\" ] = weights # Create a cache to store computed routes route_cache = {} # Parallel processing for each building logger . info ( \"Processing buildings...\" ) batch_size = 10 # Number of buildings to process in each batch building_batches = [ Building . instances [ i : i + batch_size ] for i in range ( 0 , len ( Building . instances ), batch_size )] if parallel : # Capturing the list of lists processed_building_batches = Parallel ( n_jobs =- 1 )( delayed ( process_building_batch )( building_batch , tree , A , G_ig , route_cache , mode = mode ) for building_batch in building_batches ) # Flatten the list of lists processed_buildings = [ building for batch in processed_building_batches for building in batch ] # Replace Building.instances with the updated buildings Building . instances = processed_buildings else : for building_batch in building_batches : process_building_batch ( building_batch , tree , A , G_ig , route_cache , mode = mode ) logger . info ( \"Finished processing computing routes.\" ) create_gradient ( clipped_vector_landuse , out_shape , out_transform , max_distance = 200.0 ) Create a gradient effect of natural features. Parameters: Name Type Description Default clipped_vector_landuse GeoDataFrame Clipped land use vector data. required out_shape tuple Shape of the output raster. required out_transform Affine Transform of the output raster. required max_distance float Maximum distance for gradient scaling. Defaults to 200.0. 200.0 Returns: Name Type Description ndarray Gradient raster. Source code in tripsender\\routing.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def create_gradient ( clipped_vector_landuse , out_shape , out_transform , max_distance = 200.0 ): \"\"\" Create a gradient effect of natural features. Args: clipped_vector_landuse (GeoDataFrame): Clipped land use vector data. out_shape (tuple): Shape of the output raster. out_transform (Affine): Transform of the output raster. max_distance (float): Maximum distance for gradient scaling. Defaults to 200.0. Returns: ndarray: Gradient raster. \"\"\" # Rasterize the vector data, simplifying geometries to improve performance rasterized_vector = rasterize ( [( geom , 1 ) for geom in clipped_vector_landuse . geometry . simplify ( tolerance = 0.1 )], out_shape = out_shape , transform = out_transform , fill = 0 , dtype = np . uint8 ) # Calculate the distance from each '0' pixel (non-natural feature) to the nearest '1' pixel (natural feature) distance_from_nature = distance_transform_edt ( rasterized_vector == 0 ) # Scale distances to meters in-place, assuming the CRS unit is meters pixel_size = out_transform [ 0 ] np . multiply ( distance_from_nature , pixel_size , out = distance_from_nature ) # Clip and scale distances to a 0-1 range in-place, within the specified max_distance np . clip ( distance_from_nature / max_distance , 0 , 1 , out = distance_from_nature ) # Invert the scaled distance in-place to create the gradient effect (decay from natural features) np . subtract ( 1 , distance_from_nature , out = distance_from_nature ) # Ensure that natural feature pixels retain their original value ('1') gradient = np . where ( rasterized_vector == 1 , 1 , distance_from_nature ) return gradient find_closest_source_target ( tree , G_ig , source_coord , targets_coords ) Find the closest source and target nodes in the graph using a KDTree. Parameters: Name Type Description Default tree cKDTree The KDTree for spatial indexing. required G_ig Graph The input graph. required source_coord Point The source coordinate. required targets_coords list The target coordinates. required Returns: Name Type Description tuple Closest source and target nodes. Source code in tripsender\\routing.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def find_closest_source_target ( tree , G_ig , source_coord , targets_coords ): \"\"\" Find the closest source and target nodes in the graph using a KDTree. Args: tree (cKDTree): The KDTree for spatial indexing. G_ig (igraph.Graph): The input graph. source_coord (Point): The source coordinate. targets_coords (list): The target coordinates. Returns: tuple: Closest source and target nodes. \"\"\" # Convert the POINT object to a list of coordinates for the source. source = [ source_coord . x , source_coord . y ] # Query the KDTree to find the index of the closest node to the source. _ , source_index = tree . query ([ source ], k = 1 ) # Convert the list of POINT objects to a list of coordinate lists for the targets. targets = [[ coord . x , coord . y ] for coord in targets_coords ] # Query the KDTree to find the indices of the closest nodes to the targets. _ , target_indices = tree . query ( targets , k = 1 ) # Retrieve the closest source and target nodes from the graph using indices closest_source = G_ig . vs [ source_index [ 0 ]][ \"name\" ] closest_targets = [ G_ig . vs [ index ][ \"name\" ] for index in target_indices ] return closest_source , closest_targets get_edge_coords ( G_ig ) Get the coordinates of edges in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of tuples representing edge coordinates. Source code in tripsender\\routing.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def get_edge_coords ( G_ig ): \"\"\" Get the coordinates of edges in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of tuples representing edge coordinates. \"\"\" edge_coords = [] for edge in G_ig . es : # Get the source and target vertex indices of the edge source_vertex_id = edge . source target_vertex_id = edge . target # Retrieve the coordinates of the source vertex source_x = G_ig . vs [ source_vertex_id ][ 'x' ] source_y = G_ig . vs [ source_vertex_id ][ 'y' ] # Retrieve the coordinates of the target vertex target_x = G_ig . vs [ target_vertex_id ][ 'x' ] target_y = G_ig . vs [ target_vertex_id ][ 'y' ] # Append the coordinates as a tuple of tuples edge_coords . append ((( source_x , source_y ), ( target_x , target_y ))) return edge_coords get_edge_lengths ( G_ig ) Compute the lengths of geometries for each edge in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of edge lengths. Source code in tripsender\\routing.py 55 56 57 58 59 60 61 62 63 64 65 66 67 def get_edge_lengths ( G_ig ): \"\"\" Compute the lengths of geometries for each edge in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of edge lengths. \"\"\" logger . info ( \"Computing lengths of geometries...\" ) edge_lengths = [ edge [ 'length' ] for edge in G_ig . es ] return edge_lengths get_edge_travel_time ( G_ig ) Compute the travel times for each edge in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of travel times. Source code in tripsender\\routing.py 69 70 71 72 73 74 75 76 77 78 79 80 81 def get_edge_travel_time ( G_ig ): \"\"\" Compute the travel times for each edge in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of travel times. \"\"\" logger . info ( \"Computing lengths of geometries...\" ) travel_time = [ edge [ 'travel_time' ] for edge in G_ig . es ] return travel_time get_vertex_coords ( G_ig ) Get the coordinates of vertices in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of tuples representing vertex coordinates. Source code in tripsender\\routing.py 83 84 85 86 87 88 89 90 91 92 93 94 def get_vertex_coords ( G_ig ): \"\"\" Get the coordinates of vertices in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of tuples representing vertex coordinates. \"\"\" v_coords = [( vertex [ 'x' ], vertex [ 'y' ]) for vertex in G_ig . vs ] return v_coords normalise_list ( input_list ) Normalize a list of values to a 0-1 range. Parameters: Name Type Description Default input_list list List of values. required Returns: Name Type Description list Normalized list of values. Source code in tripsender\\routing.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 def normalise_list ( input_list ): \"\"\" Normalize a list of values to a 0-1 range. Args: input_list (list): List of values. Returns: list: Normalized list of values. \"\"\" list_min = min ( input_list ) list_max = max ( input_list ) return [( x - list_min ) / ( list_max - list_min ) for x in input_list ] path_to_linestring ( path_indices , G_ig , s , t ) Convert a path in the graph to a LineString. Parameters: Name Type Description Default path_indices list List of vertex indices representing the path. required G_ig Graph The input graph. required s str Source node identifier. required t str Target node identifier. required Returns: Type Description LineString or Point: The LineString representing the path or a Point if the path is a single point. Source code in tripsender\\routing.py 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 def path_to_linestring ( path_indices , G_ig , s , t ): \"\"\" Convert a path in the graph to a LineString. Args: path_indices (list): List of vertex indices representing the path. G_ig (igraph.Graph): The input graph. s (str): Source node identifier. t (str): Target node identifier. Returns: LineString or Point: The LineString representing the path or a Point if the path is a single point. \"\"\" # End the script if the path is empty or has only one point. if not path_indices : raise ValueError ( \"path_to_linestring: The routing has returned an empty path or a single point, which is not sufficient for creating a LineString\" ) # Extract the coordinates of the path vertices = G_ig . vs [ path_indices ] x = vertices [ \"x\" ] y = vertices [ \"y\" ] if len ( x ) < 2 : # Check if source and destination are the same if s == t : return Point ( x [ 0 ], y [ 0 ]) else : raise ValueError ( f \"path_to_linestring: The routing has returned a path with only one point. { s , t } \" ) # Create the LineString for the path line = LineString ( zip ( x , y )) return line plot_gradient ( gradient , transform , title = 'Gradient Effect of Natural Features' , cmap = 'viridis' , figsize = ( 10 , 5 )) Plot the gradient effect of natural features. Parameters: Name Type Description Default gradient ndarray Gradient raster. required transform Affine Transform of the raster. required title str Title of the plot. Defaults to 'Gradient Effect of Natural Features'. 'Gradient Effect of Natural Features' cmap str Colormap for the plot. Defaults to 'viridis'. 'viridis' figsize tuple Figure size. Defaults to (10, 5). (10, 5) Source code in tripsender\\routing.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 def plot_gradient ( gradient , transform , title = 'Gradient Effect of Natural Features' , cmap = 'viridis' , figsize = ( 10 , 5 )): \"\"\" Plot the gradient effect of natural features. Args: gradient (ndarray): Gradient raster. transform (Affine): Transform of the raster. title (str): Title of the plot. Defaults to 'Gradient Effect of Natural Features'. cmap (str): Colormap for the plot. Defaults to 'viridis'. figsize (tuple): Figure size. Defaults to (10, 5). \"\"\" # Calculate the extent of the raster based on the transform # This defines the min and max of the x and y axes height , width = gradient . shape extent = ( transform [ 2 ], transform [ 2 ] + transform [ 0 ] * width , transform [ 5 ] + transform [ 4 ] * height , transform [ 5 ] ) # Create the figure and axis objects fig , ax = plt . subplots ( figsize = figsize ) # Create the image display of the gradient array using the specified colormap # and include the extent to map to geographic coordinates im = ax . imshow ( gradient , cmap = cmap , extent = extent ) # Add a colorbar to the plot, with a label indicating it shows normalized gradient values plt . colorbar ( im , ax = ax , label = 'Normalized Gradient' ) # Set the title of the plot to the specified title ax . set_title ( title ) # Display the plot plt . show () process_building ( building , tree , A , G_ig , route_cache , mode ) Process a single building to compute routes to preferred locations. Parameters: Name Type Description Default building Building The building to process. required tree cKDTree KDTree for spatial indexing. required A ndarray Array of vertex coordinates. required G_ig Graph The input graph. required route_cache dict Cache to store computed routes. required mode str Mode of transportation ('walk', 'car', 'bike'). required Returns: Name Type Description Building The updated building with computed routes. Source code in tripsender\\routing.py 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def process_building ( building , tree , A , G_ig , route_cache , mode ): \"\"\" Process a single building to compute routes to preferred locations. Args: building (Building): The building to process. tree (cKDTree): KDTree for spatial indexing. A (ndarray): Array of vertex coordinates. G_ig (igraph.Graph): The input graph. route_cache (dict): Cache to store computed routes. mode (str): Mode of transportation ('walk', 'car', 'bike'). Returns: Building: The updated building with computed routes. \"\"\" source_coord = building . coord preferred_locations = building . preferred_locations for category , locations in preferred_locations . __dict__ . items (): if locations and isinstance ( locations , ( list , tuple )): targets_coords = [ loc . location_coordinates for loc in locations ] # List of coordinate pairs # Call find_closest_source_target with correct formats closest_source , closest_targets = find_closest_source_target ( tree , G_ig , source_coord , targets_coords ) for idx , location in enumerate ( locations ): s = closest_source t = closest_targets [ idx ] # Use tuples directly as keys route_key = ( s , t ) if route_key in route_cache : linestring = route_cache [ route_key ] else : path_indices = G_ig . get_shortest_path ( s , t , weights = \"weight\" , mode = \"out\" , output = \"vpath\" ) linestring = path_to_linestring ( path_indices , G_ig , s , t ) route_cache [ route_key ] = linestring if mode == 'walk' : route = Route ( mode , linestring , 4 ) location . route_walk = route elif mode == 'car' : route = Route ( mode , linestring , 45 ) location . route_car = route elif mode == 'bike' : route = Route ( mode , linestring , 10 ) location . route_bike = route # Buildings are updated on the fly without parallel # However, in the case of a batch, we need to return the updated building # so they can be processed in multiple processes and then replace the Building.instances return building process_building_batch ( building_batch , tree , A , G_ig , route_cache , mode ) Process a batch of buildings to compute routes in parallel. Parameters: Name Type Description Default building_batch list List of buildings to process. required tree cKDTree KDTree for spatial indexing. required A ndarray Array of vertex coordinates. required G_ig Graph The input graph. required route_cache dict Cache to store computed routes. required mode str Mode of transportation ('walk', 'car', 'bike'). required Returns: Name Type Description list List of updated buildings with computed routes. Source code in tripsender\\routing.py 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 def process_building_batch ( building_batch , tree , A , G_ig , route_cache , mode ): \"\"\" Process a batch of buildings to compute routes in parallel. Args: building_batch (list): List of buildings to process. tree (cKDTree): KDTree for spatial indexing. A (ndarray): Array of vertex coordinates. G_ig (igraph.Graph): The input graph. route_cache (dict): Cache to store computed routes. mode (str): Mode of transportation ('walk', 'car', 'bike'). Returns: list: List of updated buildings with computed routes. \"\"\" logger . info ( \"Processing building batch...\" ) for building in building_batch : process_building ( building , tree , A , G_ig , route_cache , mode ) # For parallel processing, return the updated building batch return building_batch process_landuse_data ( landuse_vector , convex_hull , dem_raster_crs = 'EPSG:3006' ) Process land use data by clipping and dissolving geometries. Parameters: Name Type Description Default landuse_vector GeoDataFrame The land use vector data. required convex_hull Polygon The convex hull for clipping. required dem_raster_crs str The CRS of the DEM raster. Defaults to 'EPSG:3006'. 'EPSG:3006' Returns: Name Type Description GeoDataFrame Processed and clipped land use vector data. Source code in tripsender\\routing.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 def process_landuse_data ( landuse_vector , convex_hull , dem_raster_crs = 'EPSG:3006' ): \"\"\" Process land use data by clipping and dissolving geometries. Args: landuse_vector (GeoDataFrame): The land use vector data. convex_hull (Polygon): The convex hull for clipping. dem_raster_crs (str): The CRS of the DEM raster. Defaults to 'EPSG:3006'. Returns: GeoDataFrame: Processed and clipped land use vector data. \"\"\" # Filter to include only specified land use types, assuming this is less computationally expensive than clipping landuse_vector = landuse_vector [ landuse_vector [ 'detaljtyp' ] . isin ([ 'SKOGBARR' , '\u00d6PMARK' , 'VATTEN' , 'SKOGL\u00d6V' , 'ODL\u00c5KER' ])] # Reproject the GeoDataFrame if its CRS differs from the DEM raster's CRS if landuse_vector . crs != dem_raster_crs : landuse_vector = landuse_vector . to_crs ( dem_raster_crs ) # Clip the vector data using the bounding box of the convex hull bounding_box = box ( * convex_hull . bounds ) clipped_vector_landuse = gpd . clip ( landuse_vector , bounding_box ) # Dissolve the clipped geometries by land use type to merge geometries with the same 'detaljtyp' clipped_vector_landuse = clipped_vector_landuse . dissolve ( by = 'detaljtyp' ) return clipped_vector_landuse raster_value_at_line_ends ( raster , transform , start_coord , end_coord , value_type = 'average' ) Retrieve raster values at the ends of a line segment. Parameters: Name Type Description Default raster ndarray The raster data. required transform Affine Affine transform of the raster. required start_coord tuple Start coordinate. required end_coord tuple End coordinate. required value_type str Type of value to return ('average' or 'absolute_difference'). 'average' Returns: Name Type Description float The calculated value. Source code in tripsender\\routing.py 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def raster_value_at_line_ends ( raster , transform , start_coord , end_coord , value_type = 'average' ): \"\"\" Retrieve raster values at the ends of a line segment. Args: raster (ndarray): The raster data. transform (Affine): Affine transform of the raster. start_coord (tuple): Start coordinate. end_coord (tuple): End coordinate. value_type (str): Type of value to return ('average' or 'absolute_difference'). Returns: float: The calculated value. \"\"\" if value_type not in ( 'average' , 'absolute_difference' ): raise ValueError ( \"value_type must be 'average' or 'absolute_difference'.\" ) # Convert real-world coordinates to row and column indices row_start , col_start = rowcol ( transform , * start_coord ) row_end , col_end = rowcol ( transform , * end_coord ) # Retrieve raster values at start and end points, safely handling out-of-bounds indices start_value = raster [ row_start , col_start ] if 0 <= row_start < raster . shape [ 0 ] and 0 <= col_start < raster . shape [ 1 ] else np . nan end_value = raster [ row_end , col_end ] if 0 <= row_end < raster . shape [ 0 ] and 0 <= col_end < raster . shape [ 1 ] else np . nan # Calculate the desired value if value_type == 'average' : # Only average non-nan values values = [ v for v in [ start_value , end_value ] if not np . isnan ( v )] val = np . mean ( values ) if values else np . nan # Returns nan if both are nan or empty elif value_type == 'absolute_difference' : val = abs ( start_value - end_value ) if not np . isnan ( start_value ) and not np . isnan ( end_value ) else np . nan return val read_and_clip_raster ( dem_raster_path , convex_hull ) Read and clip a DEM raster using a convex hull. Parameters: Name Type Description Default dem_raster_path str Path to the DEM raster file. required convex_hull Polygon The convex hull for clipping. required Returns: Name Type Description tuple Clipped raster image, transform, and metadata. Source code in tripsender\\routing.py 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def read_and_clip_raster ( dem_raster_path , convex_hull ): \"\"\" Read and clip a DEM raster using a convex hull. Args: dem_raster_path (str): Path to the DEM raster file. convex_hull (Polygon): The convex hull for clipping. Returns: tuple: Clipped raster image, transform, and metadata. \"\"\" with rasterio . open ( dem_raster_path ) as dem_raster : # Step 1 bbox = box ( * convex_hull . bounds ) # Step 2 window = rasterio . windows . from_bounds ( * bbox . bounds , dem_raster . transform ) # Step 3 out_img = dem_raster . read ( window = window , masked = True ) # Step 4 out_transform = dem_raster . window_transform ( window ) # Step 5 out_meta = dem_raster . meta . copy () # Step 6 out_meta . update ({ \"driver\" : \"GTiff\" , \"height\" : out_img . shape [ 1 ], \"width\" : out_img . shape [ 2 ], \"transform\" : out_transform }) return out_img , out_transform , out_meta rowcol ( transform , x , y ) Convert real-world coordinates to pixel coordinates. Parameters: Name Type Description Default transform Affine Affine transform. required x float X-coordinate. required y float Y-coordinate. required Returns: Name Type Description tuple Row and column indices. Source code in tripsender\\routing.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 def rowcol ( transform , x , y ): \"\"\" Convert real-world coordinates to pixel coordinates. Args: transform (Affine): Affine transform. x (float): X-coordinate. y (float): Y-coordinate. Returns: tuple: Row and column indices. \"\"\" # Convert real-world coordinates to pixel coordinates using the affine transform col , row = ~ transform * ( x , y ) # Use the inverse transform to map (x, y) to (row, col) return int ( row ), int ( col )","title":"routing"},{"location":"routing/#tripsender.routing.NetworkRoutingComputer","text":"A class to compute network routes based on a specified mode of transportation. This class provides methods to find the closest source and target nodes, compute routes, and manage the graph structure for routing. Attributes: Name Type Description mode str The mode of transportation ('walk', 'bike', 'drive'). G_ig Graph The graph representing the transportation network. v_coordinates list List of vertex coordinates in the graph. A ndarray Array of vertex coordinates. tree cKDTree KDTree for spatial indexing of vertex coordinates. names list List of vertex names. weights list List of edge weights in the graph. route_cache dict Cache to store computed routes. speed_factor int Factor to adjust travel speed based on the mode of transportation. Methods: Name Description get_closest_source_target Find the closest source and target nodes in the graph for the given coordinates. path_to_linestring Convert a path in the graph to a LineString. compute_route Compute the route and travel time between source and target coordinates. Source code in tripsender\\routing.py 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 class NetworkRoutingComputer : \"\"\" A class to compute network routes based on a specified mode of transportation. This class provides methods to find the closest source and target nodes, compute routes, and manage the graph structure for routing. Attributes: mode (str): The mode of transportation ('walk', 'bike', 'drive'). G_ig (igraph.Graph): The graph representing the transportation network. v_coordinates (list): List of vertex coordinates in the graph. A (ndarray): Array of vertex coordinates. tree (cKDTree): KDTree for spatial indexing of vertex coordinates. names (list): List of vertex names. weights (list): List of edge weights in the graph. route_cache (dict): Cache to store computed routes. speed_factor (int): Factor to adjust travel speed based on the mode of transportation. Methods: get_closest_source_target(source_coord, target_coord): Find the closest source and target nodes in the graph for the given coordinates. path_to_linestring(path_indices, G_ig, s, t): Convert a path in the graph to a LineString. compute_route(source_coord, target_coord, mode='walk'): Compute the route and travel time between source and target coordinates. \"\"\" def __init__ ( self , mode , speed_factor = 4 ): self . mode = mode self . G_ig = io . fetch_igraph ( mode ) self . v_coordinates = get_vertex_coords ( self . G_ig ) self . A = np . array ( self . v_coordinates ) self . tree = cKDTree ( self . A ) self . names = [ f \"( { x } , { y } )\" for x , y in self . v_coordinates ] self . G_ig . vs [ \"name\" ] = self . names if mode in [ 'active' , 'walk' , 'bike' ]: self . edge_length = get_edge_lengths ( self . G_ig ) self . weights = self . edge_length elif mode == 'drive' : self . edge_travel_time = get_edge_travel_time ( self . G_ig ) self . weights = self . edge_travel_time else : raise ValueError ( f \"Mode must be one of 'walk', 'bike' or 'drive', got { mode } instead.\" ) self . G_ig . es [ \"weight\" ] = self . weights self . route_cache = {} self . speed_factor = speed_factor def get_closest_source_target ( self , source_coord , target_coord ): # Convert the POINT object to a list of coordinates for the source. source = [ source_coord . x , source_coord . y ] # Query the KDTree to find the index of the closest node to the source. _ , source_index = self . tree . query ([ source ], k = 1 ) target = [ target_coord . x , target_coord . y ] # Query the KDTree to find the indices of the closest nodes to the targets. _ , target_index = self . tree . query ([ target ], k = 1 ) # Retrieve the closest source and target nodes from the graph using indices closest_source = self . G_ig . vs [ source_index [ 0 ]][ \"name\" ] closest_target = self . G_ig . vs [ target_index [ 0 ]][ \"name\" ] return closest_source , closest_target def path_to_linestring ( self , path_indices , G_ig , s , t ): # End the script if the path is empty or has only one point. if not path_indices : raise ValueError ( \"path_to_linestring: The routing has returned an empty path or a single point, which is not sufficient for creating a LineString\" ) # Extract the coordinates of the path vertices = G_ig . vs [ path_indices ] x = vertices [ \"x\" ] y = vertices [ \"y\" ] if len ( x ) < 2 : # Check if source and destination are the same if s == t : return Point ( x [ 0 ], y [ 0 ]) else : raise ValueError ( f \"path_to_linestring: The routing has returned a path with only one point. { s , t } \" ) # Create the LineString for the path line = LineString ( zip ( x , y )) return line def compute_route ( self , source_coord , target_coord , mode = 'walk' ): linestring , travel_time = None , None # Default values in case of early return # Check if any of the coordinates is None if source_coord is None or target_coord is None : #logger.info(f\"One of the coordinates is None. Returning None for linestring and travel time. Got {source_coord} and {target_coord} instead.\") return linestring , travel_time # Check if source and target coordinates are the same if source_coord == target_coord : # Create a linestring with 10m length and 0 travel time dummy_target = Point ( target_coord . x + 0.0001 , target_coord . y + 0.0001 ) linestring = LineString ([ source_coord , dummy_target ]) travel_time = 0 #logger.info(f\"Source and target coordinates are the same. Returning a point for linestring and 0 for travel time. Got {source_coord} and {target_coord} instead.\") return linestring , travel_time # Check if source and target are of type Point if not isinstance ( source_coord , Point ) or not isinstance ( target_coord , Point ): #logger.info(f\"Source and target coordinates must be of type Point. Returning None for linestring and travel time. Got {source_coord} and {target_coord} instead.\") return linestring , travel_time # Main route computation block try : closest_source , closest_target = self . get_closest_source_target ( source_coord , target_coord ) path_indices = self . G_ig . get_shortest_path ( closest_source , closest_target , weights = \"weight\" , mode = \"out\" , output = \"vpath\" ) linestring = self . path_to_linestring ( path_indices , self . G_ig , closest_source , closest_target ) linestring = complete_linestring ( linestring , source_coord , target_coord ) distance = linestring . length travel_time = (( distance / 1000 ) / ( self . speed_factor )) * 60 #travel_time = speed_factor * distance / 1000 except Exception as e : logger . error ( f \"Error computing route: { e } between { source_coord } and { target_coord } \" ) # Optionally, set linestring and travel_time to None or a default value here return linestring , travel_time","title":"NetworkRoutingComputer"},{"location":"routing/#tripsender.routing.TransitMatrixComputer","text":"Source code in tripsender\\routing.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 class TransitMatrixComputer : def __init__ ( self , hdf5_path = hdf5_path , origins_gdf = origins_gdf ): \"\"\" A class to compute and manage a transit matrix, providing travel times between origin-destination pairs. This class preprocesses data from an HDF5 file and uses a KDTree for fast lookup of travel times. It also provides methods to query travel times and compute routes between coordinates. Attributes: hdf5_path (str): Path to the HDF5 file containing the transit data. travel_times_dict (dict): Dictionary to store travel times between origin-destination pairs. origins_gdf (GeoDataFrame): GeoDataFrame containing origin points. points (ndarray): Array of coordinates extracted from the origins_gdf. tree (KDTree): KDTree for spatial indexing of origin points. ids (ndarray): Array of IDs corresponding to the origin points. Methods: preprocess_data(): Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. get_closest_id_tree(lat, lon): Get the closest origin ID to the given latitude and longitude using the KDTree. query_travel_time(o, d): Query the travel time between two coordinates. compute_route(source_coord, target_coord): Compute the route and travel time between source and target coordinates. \"\"\" self . hdf5_path = hdf5_path self . travel_times_dict = {} self . origins_gdf = origins_gdf self . points = np . array ( self . origins_gdf [[ 'geometry' ]] . apply ( lambda x : [ x [ 0 ] . x , x [ 0 ] . y ], axis = 1 ) . tolist ()) self . tree = KDTree ( self . points ) self . ids = self . origins_gdf [ 'id' ] . to_numpy () self . preprocess_data () def preprocess_data ( self ): \"\"\"Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups.\"\"\" with h5py . File ( self . hdf5_path , 'r' ) as hdf5_file : # Proceed with the existing logic if datasets are present dataset_size = hdf5_file [ 'from_id' ] . shape [ 0 ] batch_size = 10000 # Adjust based on your system's memory capacity for i in range ( 0 , dataset_size , batch_size ): from_ids = hdf5_file [ 'from_id' ][ i : i + batch_size ] to_ids = hdf5_file [ 'to_id' ][ i : i + batch_size ] travel_times = hdf5_file [ 'travel_time' ][ i : i + batch_size ] for from_id , to_id , travel_time in zip ( from_ids , to_ids , travel_times ): self . travel_times_dict [( from_id , to_id )] = travel_time def get_closest_id_tree ( self , lat , lon ): dist , closest_idx = self . tree . query ([[ lon , lat ]], k = 1 ) # Ensure k=1 for clarity # Since closest_idx is a 1D array with a single element, access it directly closest_id = self . ids [ closest_idx ][ 0 ] # Access the first element since closest_idx is 1D return closest_id def query_travel_time ( self , o , d ): # Get closest id origin_closest_id = self . get_closest_id_tree ( o . y , o . x ) # Get closest id destination_closest_id = self . get_closest_id_tree ( d . y , d . x ) # Query the travel time for a given origin and destination ID pair. travel_time = self . travel_times_dict . get (( origin_closest_id , destination_closest_id ), None ) return travel_time def compute_route ( self , source_coord , target_coord ): linestring , travel_time = None , None # Default values in case of early return # Correctly check if any of the coordinates is None if source_coord is None or target_coord is None : #logger.info(\"One of the coordinates is None. Returning None for linestring and travel time.\") return linestring , travel_time # Check if source and target coordinates are the same if source_coord == target_coord : dummy_target = Point ( target_coord . x + 0.0001 , target_coord . y + 0.0001 ) linestring = LineString ([ source_coord , dummy_target ]) travel_time = 0 #logger.info(\"Source and target coordinates are the same. Returning a point for linestring and 0 for travel time.\") return linestring , travel_time # Main route computation block try : # Return a straight line between the source and target coordinates linestring = LineString ([ source_coord , target_coord ]) # Complete the linestring if necessary (this function should handle its own errors or be wrapped in try-except if it can raise exceptions) linestring = complete_linestring ( linestring , source_coord , target_coord ) # Query travel time (this function should also handle its own errors or be wrapped in try-except) travel_time = self . query_travel_time ( source_coord , target_coord ) except Exception as e : logger . error ( f \"Error computing route: { e } \" ) # Optionally, set linestring and travel_time to None or a default value here return linestring , travel_time","title":"TransitMatrixComputer"},{"location":"routing/#tripsender.routing.TransitMatrixComputer.__init__","text":"A class to compute and manage a transit matrix, providing travel times between origin-destination pairs. This class preprocesses data from an HDF5 file and uses a KDTree for fast lookup of travel times. It also provides methods to query travel times and compute routes between coordinates. Attributes: Name Type Description hdf5_path str Path to the HDF5 file containing the transit data. travel_times_dict dict Dictionary to store travel times between origin-destination pairs. origins_gdf GeoDataFrame GeoDataFrame containing origin points. points ndarray Array of coordinates extracted from the origins_gdf. tree KDTree KDTree for spatial indexing of origin points. ids ndarray Array of IDs corresponding to the origin points. Functions: Name Description preprocess_data Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. get_closest_id_tree Get the closest origin ID to the given latitude and longitude using the KDTree. query_travel_time Query the travel time between two coordinates. compute_route Compute the route and travel time between source and target coordinates. Source code in tripsender\\routing.py 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 def __init__ ( self , hdf5_path = hdf5_path , origins_gdf = origins_gdf ): \"\"\" A class to compute and manage a transit matrix, providing travel times between origin-destination pairs. This class preprocesses data from an HDF5 file and uses a KDTree for fast lookup of travel times. It also provides methods to query travel times and compute routes between coordinates. Attributes: hdf5_path (str): Path to the HDF5 file containing the transit data. travel_times_dict (dict): Dictionary to store travel times between origin-destination pairs. origins_gdf (GeoDataFrame): GeoDataFrame containing origin points. points (ndarray): Array of coordinates extracted from the origins_gdf. tree (KDTree): KDTree for spatial indexing of origin points. ids (ndarray): Array of IDs corresponding to the origin points. Methods: preprocess_data(): Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. get_closest_id_tree(lat, lon): Get the closest origin ID to the given latitude and longitude using the KDTree. query_travel_time(o, d): Query the travel time between two coordinates. compute_route(source_coord, target_coord): Compute the route and travel time between source and target coordinates. \"\"\" self . hdf5_path = hdf5_path self . travel_times_dict = {} self . origins_gdf = origins_gdf self . points = np . array ( self . origins_gdf [[ 'geometry' ]] . apply ( lambda x : [ x [ 0 ] . x , x [ 0 ] . y ], axis = 1 ) . tolist ()) self . tree = KDTree ( self . points ) self . ids = self . origins_gdf [ 'id' ] . to_numpy () self . preprocess_data ()","title":"__init__"},{"location":"routing/#tripsender.routing.TransitMatrixComputer.preprocess_data","text":"Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups. Source code in tripsender\\routing.py 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 def preprocess_data ( self ): \"\"\"Preprocess the data from the HDF5 file and store it in a dictionary for fast lookups.\"\"\" with h5py . File ( self . hdf5_path , 'r' ) as hdf5_file : # Proceed with the existing logic if datasets are present dataset_size = hdf5_file [ 'from_id' ] . shape [ 0 ] batch_size = 10000 # Adjust based on your system's memory capacity for i in range ( 0 , dataset_size , batch_size ): from_ids = hdf5_file [ 'from_id' ][ i : i + batch_size ] to_ids = hdf5_file [ 'to_id' ][ i : i + batch_size ] travel_times = hdf5_file [ 'travel_time' ][ i : i + batch_size ] for from_id , to_id , travel_time in zip ( from_ids , to_ids , travel_times ): self . travel_times_dict [( from_id , to_id )] = travel_time","title":"preprocess_data"},{"location":"routing/#tripsender.routing.compute_edge_weights","text":"Compute edge weights for the graph based on edge length, slope, and proximity to natural features. Parameters: Name Type Description Default coords list List of coordinates for each edge. required edge_length list List of edge lengths. required dem_raster_path str Path to the DEM raster file. required landuse_vector GeoDataFrame Land use vector data. required convex_hull Polygon Convex hull for clipping. required Returns: Name Type Description list Computed edge weights. Source code in tripsender\\routing.py 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def compute_edge_weights ( coords , edge_length , dem_raster_path , landuse_vector , convex_hull ): \"\"\" Compute edge weights for the graph based on edge length, slope, and proximity to natural features. Args: coords (list): List of coordinates for each edge. edge_length (list): List of edge lengths. dem_raster_path (str): Path to the DEM raster file. landuse_vector (GeoDataFrame): Land use vector data. convex_hull (Polygon): Convex hull for clipping. Returns: list: Computed edge weights. \"\"\" # Clip the DEM raster to the area of interest defined by the convex hull clipped_dem , out_transform , out_meta = read_and_clip_raster ( dem_raster_path , convex_hull ) # Process the land use vector data, clipping it to the same area and creating a gradient processed_landuse = process_landuse_data ( landuse_vector , convex_hull , out_meta [ 'crs' ]) normalize_nature_raster = create_gradient ( processed_landuse , clipped_dem . shape [ 1 :], out_transform ) average_nature_values = [] height_difference = [] # Iterate over each street segment to compute the average gradient and slope for line_coords in coords : if len ( line_coords ) > 1 : # Get the raster values at the start and end of the street segment #print(\"Calculating dem absolute difference\") absolute_difference = raster_value_at_line_ends ( clipped_dem [ 0 ], out_transform , line_coords [ 0 ], line_coords [ - 1 ], value_type = 'absolute_difference' ) #print(\"Calculating landuse average\") average_value = raster_value_at_line_ends ( normalize_nature_raster , out_transform , line_coords [ 0 ], line_coords [ - 1 ], value_type = 'average' ) average_nature_values . append ( average_value ) height_difference . append ( absolute_difference ) slope = [ x / y for x , y in zip ( height_difference , edge_length )] norm_edge_length = normalise_list ( edge_length ) norm_distance_nature = normalise_list ( average_nature_values ) norm_slope = normalise_list ( slope ) weights = [ COEF_LENGTH * norm_edge_length [ i ] + COEF_NATURE * norm_distance_nature [ i ] + COEF_SLOPE * norm_slope [ i ] for i in range ( len ( edge_length ))] # Return the edge lengths and computed weight factors for further processing return weights","title":"compute_edge_weights"},{"location":"routing/#tripsender.routing.compute_routes_for_all_buildings","text":"Compute routes for all buildings in the dataset. Parameters: Name Type Description Default mode str Mode of transportation ('walk', 'bike', 'drive'). Defaults to 'walk'. 'walk' parallel bool Whether to process buildings in parallel. Defaults to False. False Source code in tripsender\\routing.py 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 def compute_routes_for_all_buildings ( mode = 'walk' , parallel = False ): # landuse_vector, convex_hull, \"\"\" Compute routes for all buildings in the dataset. Args: mode (str): Mode of transportation ('walk', 'bike', 'drive'). Defaults to 'walk'. parallel (bool): Whether to process buildings in parallel. Defaults to False. \"\"\" #Fetch the iGraph G_ig = io . fetch_igraph ( mode ) # Build a KDTree for spatial indexing logger . info ( \"Building KDTree for spatial indexing...\" ) v_coordinates = get_vertex_coords ( G_ig ) A = np . array ( v_coordinates ) tree = cKDTree ( A ) # Set names for vertices in the form \"(x,y)\" names = [ f \"( { x } , { y } )\" for x , y in v_coordinates ] G_ig . vs [ \"name\" ] = names # Set weights based on mode if mode in [ 'walk' , 'bike' ]: #e_coordinates = get_edge_coords(G_ig) edge_length = get_edge_lengths ( G_ig ) weights = edge_length #compute_edge_weights(e_coordinates, edge_length, dem_raster_path, landuse_vector, convex_hull) elif mode == 'drive' : edge_travel_time = get_edge_travel_time ( G_ig ) weights = edge_travel_time else : raise ValueError ( f \"Mode must be one of 'walk', 'bike' or 'drive', got { mode } instead.\" ) G_ig . es [ \"weight\" ] = weights # Create a cache to store computed routes route_cache = {} # Parallel processing for each building logger . info ( \"Processing buildings...\" ) batch_size = 10 # Number of buildings to process in each batch building_batches = [ Building . instances [ i : i + batch_size ] for i in range ( 0 , len ( Building . instances ), batch_size )] if parallel : # Capturing the list of lists processed_building_batches = Parallel ( n_jobs =- 1 )( delayed ( process_building_batch )( building_batch , tree , A , G_ig , route_cache , mode = mode ) for building_batch in building_batches ) # Flatten the list of lists processed_buildings = [ building for batch in processed_building_batches for building in batch ] # Replace Building.instances with the updated buildings Building . instances = processed_buildings else : for building_batch in building_batches : process_building_batch ( building_batch , tree , A , G_ig , route_cache , mode = mode ) logger . info ( \"Finished processing computing routes.\" )","title":"compute_routes_for_all_buildings"},{"location":"routing/#tripsender.routing.create_gradient","text":"Create a gradient effect of natural features. Parameters: Name Type Description Default clipped_vector_landuse GeoDataFrame Clipped land use vector data. required out_shape tuple Shape of the output raster. required out_transform Affine Transform of the output raster. required max_distance float Maximum distance for gradient scaling. Defaults to 200.0. 200.0 Returns: Name Type Description ndarray Gradient raster. Source code in tripsender\\routing.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def create_gradient ( clipped_vector_landuse , out_shape , out_transform , max_distance = 200.0 ): \"\"\" Create a gradient effect of natural features. Args: clipped_vector_landuse (GeoDataFrame): Clipped land use vector data. out_shape (tuple): Shape of the output raster. out_transform (Affine): Transform of the output raster. max_distance (float): Maximum distance for gradient scaling. Defaults to 200.0. Returns: ndarray: Gradient raster. \"\"\" # Rasterize the vector data, simplifying geometries to improve performance rasterized_vector = rasterize ( [( geom , 1 ) for geom in clipped_vector_landuse . geometry . simplify ( tolerance = 0.1 )], out_shape = out_shape , transform = out_transform , fill = 0 , dtype = np . uint8 ) # Calculate the distance from each '0' pixel (non-natural feature) to the nearest '1' pixel (natural feature) distance_from_nature = distance_transform_edt ( rasterized_vector == 0 ) # Scale distances to meters in-place, assuming the CRS unit is meters pixel_size = out_transform [ 0 ] np . multiply ( distance_from_nature , pixel_size , out = distance_from_nature ) # Clip and scale distances to a 0-1 range in-place, within the specified max_distance np . clip ( distance_from_nature / max_distance , 0 , 1 , out = distance_from_nature ) # Invert the scaled distance in-place to create the gradient effect (decay from natural features) np . subtract ( 1 , distance_from_nature , out = distance_from_nature ) # Ensure that natural feature pixels retain their original value ('1') gradient = np . where ( rasterized_vector == 1 , 1 , distance_from_nature ) return gradient","title":"create_gradient"},{"location":"routing/#tripsender.routing.find_closest_source_target","text":"Find the closest source and target nodes in the graph using a KDTree. Parameters: Name Type Description Default tree cKDTree The KDTree for spatial indexing. required G_ig Graph The input graph. required source_coord Point The source coordinate. required targets_coords list The target coordinates. required Returns: Name Type Description tuple Closest source and target nodes. Source code in tripsender\\routing.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def find_closest_source_target ( tree , G_ig , source_coord , targets_coords ): \"\"\" Find the closest source and target nodes in the graph using a KDTree. Args: tree (cKDTree): The KDTree for spatial indexing. G_ig (igraph.Graph): The input graph. source_coord (Point): The source coordinate. targets_coords (list): The target coordinates. Returns: tuple: Closest source and target nodes. \"\"\" # Convert the POINT object to a list of coordinates for the source. source = [ source_coord . x , source_coord . y ] # Query the KDTree to find the index of the closest node to the source. _ , source_index = tree . query ([ source ], k = 1 ) # Convert the list of POINT objects to a list of coordinate lists for the targets. targets = [[ coord . x , coord . y ] for coord in targets_coords ] # Query the KDTree to find the indices of the closest nodes to the targets. _ , target_indices = tree . query ( targets , k = 1 ) # Retrieve the closest source and target nodes from the graph using indices closest_source = G_ig . vs [ source_index [ 0 ]][ \"name\" ] closest_targets = [ G_ig . vs [ index ][ \"name\" ] for index in target_indices ] return closest_source , closest_targets","title":"find_closest_source_target"},{"location":"routing/#tripsender.routing.get_edge_coords","text":"Get the coordinates of edges in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of tuples representing edge coordinates. Source code in tripsender\\routing.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def get_edge_coords ( G_ig ): \"\"\" Get the coordinates of edges in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of tuples representing edge coordinates. \"\"\" edge_coords = [] for edge in G_ig . es : # Get the source and target vertex indices of the edge source_vertex_id = edge . source target_vertex_id = edge . target # Retrieve the coordinates of the source vertex source_x = G_ig . vs [ source_vertex_id ][ 'x' ] source_y = G_ig . vs [ source_vertex_id ][ 'y' ] # Retrieve the coordinates of the target vertex target_x = G_ig . vs [ target_vertex_id ][ 'x' ] target_y = G_ig . vs [ target_vertex_id ][ 'y' ] # Append the coordinates as a tuple of tuples edge_coords . append ((( source_x , source_y ), ( target_x , target_y ))) return edge_coords","title":"get_edge_coords"},{"location":"routing/#tripsender.routing.get_edge_lengths","text":"Compute the lengths of geometries for each edge in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of edge lengths. Source code in tripsender\\routing.py 55 56 57 58 59 60 61 62 63 64 65 66 67 def get_edge_lengths ( G_ig ): \"\"\" Compute the lengths of geometries for each edge in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of edge lengths. \"\"\" logger . info ( \"Computing lengths of geometries...\" ) edge_lengths = [ edge [ 'length' ] for edge in G_ig . es ] return edge_lengths","title":"get_edge_lengths"},{"location":"routing/#tripsender.routing.get_edge_travel_time","text":"Compute the travel times for each edge in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of travel times. Source code in tripsender\\routing.py 69 70 71 72 73 74 75 76 77 78 79 80 81 def get_edge_travel_time ( G_ig ): \"\"\" Compute the travel times for each edge in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of travel times. \"\"\" logger . info ( \"Computing lengths of geometries...\" ) travel_time = [ edge [ 'travel_time' ] for edge in G_ig . es ] return travel_time","title":"get_edge_travel_time"},{"location":"routing/#tripsender.routing.get_vertex_coords","text":"Get the coordinates of vertices in the graph. Parameters: Name Type Description Default G_ig Graph The input graph. required Returns: Name Type Description list A list of tuples representing vertex coordinates. Source code in tripsender\\routing.py 83 84 85 86 87 88 89 90 91 92 93 94 def get_vertex_coords ( G_ig ): \"\"\" Get the coordinates of vertices in the graph. Args: G_ig (igraph.Graph): The input graph. Returns: list: A list of tuples representing vertex coordinates. \"\"\" v_coords = [( vertex [ 'x' ], vertex [ 'y' ]) for vertex in G_ig . vs ] return v_coords","title":"get_vertex_coords"},{"location":"routing/#tripsender.routing.normalise_list","text":"Normalize a list of values to a 0-1 range. Parameters: Name Type Description Default input_list list List of values. required Returns: Name Type Description list Normalized list of values. Source code in tripsender\\routing.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 def normalise_list ( input_list ): \"\"\" Normalize a list of values to a 0-1 range. Args: input_list (list): List of values. Returns: list: Normalized list of values. \"\"\" list_min = min ( input_list ) list_max = max ( input_list ) return [( x - list_min ) / ( list_max - list_min ) for x in input_list ]","title":"normalise_list"},{"location":"routing/#tripsender.routing.path_to_linestring","text":"Convert a path in the graph to a LineString. Parameters: Name Type Description Default path_indices list List of vertex indices representing the path. required G_ig Graph The input graph. required s str Source node identifier. required t str Target node identifier. required Returns: Type Description LineString or Point: The LineString representing the path or a Point if the path is a single point. Source code in tripsender\\routing.py 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 def path_to_linestring ( path_indices , G_ig , s , t ): \"\"\" Convert a path in the graph to a LineString. Args: path_indices (list): List of vertex indices representing the path. G_ig (igraph.Graph): The input graph. s (str): Source node identifier. t (str): Target node identifier. Returns: LineString or Point: The LineString representing the path or a Point if the path is a single point. \"\"\" # End the script if the path is empty or has only one point. if not path_indices : raise ValueError ( \"path_to_linestring: The routing has returned an empty path or a single point, which is not sufficient for creating a LineString\" ) # Extract the coordinates of the path vertices = G_ig . vs [ path_indices ] x = vertices [ \"x\" ] y = vertices [ \"y\" ] if len ( x ) < 2 : # Check if source and destination are the same if s == t : return Point ( x [ 0 ], y [ 0 ]) else : raise ValueError ( f \"path_to_linestring: The routing has returned a path with only one point. { s , t } \" ) # Create the LineString for the path line = LineString ( zip ( x , y )) return line","title":"path_to_linestring"},{"location":"routing/#tripsender.routing.plot_gradient","text":"Plot the gradient effect of natural features. Parameters: Name Type Description Default gradient ndarray Gradient raster. required transform Affine Transform of the raster. required title str Title of the plot. Defaults to 'Gradient Effect of Natural Features'. 'Gradient Effect of Natural Features' cmap str Colormap for the plot. Defaults to 'viridis'. 'viridis' figsize tuple Figure size. Defaults to (10, 5). (10, 5) Source code in tripsender\\routing.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 def plot_gradient ( gradient , transform , title = 'Gradient Effect of Natural Features' , cmap = 'viridis' , figsize = ( 10 , 5 )): \"\"\" Plot the gradient effect of natural features. Args: gradient (ndarray): Gradient raster. transform (Affine): Transform of the raster. title (str): Title of the plot. Defaults to 'Gradient Effect of Natural Features'. cmap (str): Colormap for the plot. Defaults to 'viridis'. figsize (tuple): Figure size. Defaults to (10, 5). \"\"\" # Calculate the extent of the raster based on the transform # This defines the min and max of the x and y axes height , width = gradient . shape extent = ( transform [ 2 ], transform [ 2 ] + transform [ 0 ] * width , transform [ 5 ] + transform [ 4 ] * height , transform [ 5 ] ) # Create the figure and axis objects fig , ax = plt . subplots ( figsize = figsize ) # Create the image display of the gradient array using the specified colormap # and include the extent to map to geographic coordinates im = ax . imshow ( gradient , cmap = cmap , extent = extent ) # Add a colorbar to the plot, with a label indicating it shows normalized gradient values plt . colorbar ( im , ax = ax , label = 'Normalized Gradient' ) # Set the title of the plot to the specified title ax . set_title ( title ) # Display the plot plt . show ()","title":"plot_gradient"},{"location":"routing/#tripsender.routing.process_building","text":"Process a single building to compute routes to preferred locations. Parameters: Name Type Description Default building Building The building to process. required tree cKDTree KDTree for spatial indexing. required A ndarray Array of vertex coordinates. required G_ig Graph The input graph. required route_cache dict Cache to store computed routes. required mode str Mode of transportation ('walk', 'car', 'bike'). required Returns: Name Type Description Building The updated building with computed routes. Source code in tripsender\\routing.py 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def process_building ( building , tree , A , G_ig , route_cache , mode ): \"\"\" Process a single building to compute routes to preferred locations. Args: building (Building): The building to process. tree (cKDTree): KDTree for spatial indexing. A (ndarray): Array of vertex coordinates. G_ig (igraph.Graph): The input graph. route_cache (dict): Cache to store computed routes. mode (str): Mode of transportation ('walk', 'car', 'bike'). Returns: Building: The updated building with computed routes. \"\"\" source_coord = building . coord preferred_locations = building . preferred_locations for category , locations in preferred_locations . __dict__ . items (): if locations and isinstance ( locations , ( list , tuple )): targets_coords = [ loc . location_coordinates for loc in locations ] # List of coordinate pairs # Call find_closest_source_target with correct formats closest_source , closest_targets = find_closest_source_target ( tree , G_ig , source_coord , targets_coords ) for idx , location in enumerate ( locations ): s = closest_source t = closest_targets [ idx ] # Use tuples directly as keys route_key = ( s , t ) if route_key in route_cache : linestring = route_cache [ route_key ] else : path_indices = G_ig . get_shortest_path ( s , t , weights = \"weight\" , mode = \"out\" , output = \"vpath\" ) linestring = path_to_linestring ( path_indices , G_ig , s , t ) route_cache [ route_key ] = linestring if mode == 'walk' : route = Route ( mode , linestring , 4 ) location . route_walk = route elif mode == 'car' : route = Route ( mode , linestring , 45 ) location . route_car = route elif mode == 'bike' : route = Route ( mode , linestring , 10 ) location . route_bike = route # Buildings are updated on the fly without parallel # However, in the case of a batch, we need to return the updated building # so they can be processed in multiple processes and then replace the Building.instances return building","title":"process_building"},{"location":"routing/#tripsender.routing.process_building_batch","text":"Process a batch of buildings to compute routes in parallel. Parameters: Name Type Description Default building_batch list List of buildings to process. required tree cKDTree KDTree for spatial indexing. required A ndarray Array of vertex coordinates. required G_ig Graph The input graph. required route_cache dict Cache to store computed routes. required mode str Mode of transportation ('walk', 'car', 'bike'). required Returns: Name Type Description list List of updated buildings with computed routes. Source code in tripsender\\routing.py 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 def process_building_batch ( building_batch , tree , A , G_ig , route_cache , mode ): \"\"\" Process a batch of buildings to compute routes in parallel. Args: building_batch (list): List of buildings to process. tree (cKDTree): KDTree for spatial indexing. A (ndarray): Array of vertex coordinates. G_ig (igraph.Graph): The input graph. route_cache (dict): Cache to store computed routes. mode (str): Mode of transportation ('walk', 'car', 'bike'). Returns: list: List of updated buildings with computed routes. \"\"\" logger . info ( \"Processing building batch...\" ) for building in building_batch : process_building ( building , tree , A , G_ig , route_cache , mode ) # For parallel processing, return the updated building batch return building_batch","title":"process_building_batch"},{"location":"routing/#tripsender.routing.process_landuse_data","text":"Process land use data by clipping and dissolving geometries. Parameters: Name Type Description Default landuse_vector GeoDataFrame The land use vector data. required convex_hull Polygon The convex hull for clipping. required dem_raster_crs str The CRS of the DEM raster. Defaults to 'EPSG:3006'. 'EPSG:3006' Returns: Name Type Description GeoDataFrame Processed and clipped land use vector data. Source code in tripsender\\routing.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 def process_landuse_data ( landuse_vector , convex_hull , dem_raster_crs = 'EPSG:3006' ): \"\"\" Process land use data by clipping and dissolving geometries. Args: landuse_vector (GeoDataFrame): The land use vector data. convex_hull (Polygon): The convex hull for clipping. dem_raster_crs (str): The CRS of the DEM raster. Defaults to 'EPSG:3006'. Returns: GeoDataFrame: Processed and clipped land use vector data. \"\"\" # Filter to include only specified land use types, assuming this is less computationally expensive than clipping landuse_vector = landuse_vector [ landuse_vector [ 'detaljtyp' ] . isin ([ 'SKOGBARR' , '\u00d6PMARK' , 'VATTEN' , 'SKOGL\u00d6V' , 'ODL\u00c5KER' ])] # Reproject the GeoDataFrame if its CRS differs from the DEM raster's CRS if landuse_vector . crs != dem_raster_crs : landuse_vector = landuse_vector . to_crs ( dem_raster_crs ) # Clip the vector data using the bounding box of the convex hull bounding_box = box ( * convex_hull . bounds ) clipped_vector_landuse = gpd . clip ( landuse_vector , bounding_box ) # Dissolve the clipped geometries by land use type to merge geometries with the same 'detaljtyp' clipped_vector_landuse = clipped_vector_landuse . dissolve ( by = 'detaljtyp' ) return clipped_vector_landuse","title":"process_landuse_data"},{"location":"routing/#tripsender.routing.raster_value_at_line_ends","text":"Retrieve raster values at the ends of a line segment. Parameters: Name Type Description Default raster ndarray The raster data. required transform Affine Affine transform of the raster. required start_coord tuple Start coordinate. required end_coord tuple End coordinate. required value_type str Type of value to return ('average' or 'absolute_difference'). 'average' Returns: Name Type Description float The calculated value. Source code in tripsender\\routing.py 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def raster_value_at_line_ends ( raster , transform , start_coord , end_coord , value_type = 'average' ): \"\"\" Retrieve raster values at the ends of a line segment. Args: raster (ndarray): The raster data. transform (Affine): Affine transform of the raster. start_coord (tuple): Start coordinate. end_coord (tuple): End coordinate. value_type (str): Type of value to return ('average' or 'absolute_difference'). Returns: float: The calculated value. \"\"\" if value_type not in ( 'average' , 'absolute_difference' ): raise ValueError ( \"value_type must be 'average' or 'absolute_difference'.\" ) # Convert real-world coordinates to row and column indices row_start , col_start = rowcol ( transform , * start_coord ) row_end , col_end = rowcol ( transform , * end_coord ) # Retrieve raster values at start and end points, safely handling out-of-bounds indices start_value = raster [ row_start , col_start ] if 0 <= row_start < raster . shape [ 0 ] and 0 <= col_start < raster . shape [ 1 ] else np . nan end_value = raster [ row_end , col_end ] if 0 <= row_end < raster . shape [ 0 ] and 0 <= col_end < raster . shape [ 1 ] else np . nan # Calculate the desired value if value_type == 'average' : # Only average non-nan values values = [ v for v in [ start_value , end_value ] if not np . isnan ( v )] val = np . mean ( values ) if values else np . nan # Returns nan if both are nan or empty elif value_type == 'absolute_difference' : val = abs ( start_value - end_value ) if not np . isnan ( start_value ) and not np . isnan ( end_value ) else np . nan return val","title":"raster_value_at_line_ends"},{"location":"routing/#tripsender.routing.read_and_clip_raster","text":"Read and clip a DEM raster using a convex hull. Parameters: Name Type Description Default dem_raster_path str Path to the DEM raster file. required convex_hull Polygon The convex hull for clipping. required Returns: Name Type Description tuple Clipped raster image, transform, and metadata. Source code in tripsender\\routing.py 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def read_and_clip_raster ( dem_raster_path , convex_hull ): \"\"\" Read and clip a DEM raster using a convex hull. Args: dem_raster_path (str): Path to the DEM raster file. convex_hull (Polygon): The convex hull for clipping. Returns: tuple: Clipped raster image, transform, and metadata. \"\"\" with rasterio . open ( dem_raster_path ) as dem_raster : # Step 1 bbox = box ( * convex_hull . bounds ) # Step 2 window = rasterio . windows . from_bounds ( * bbox . bounds , dem_raster . transform ) # Step 3 out_img = dem_raster . read ( window = window , masked = True ) # Step 4 out_transform = dem_raster . window_transform ( window ) # Step 5 out_meta = dem_raster . meta . copy () # Step 6 out_meta . update ({ \"driver\" : \"GTiff\" , \"height\" : out_img . shape [ 1 ], \"width\" : out_img . shape [ 2 ], \"transform\" : out_transform }) return out_img , out_transform , out_meta","title":"read_and_clip_raster"},{"location":"routing/#tripsender.routing.rowcol","text":"Convert real-world coordinates to pixel coordinates. Parameters: Name Type Description Default transform Affine Affine transform. required x float X-coordinate. required y float Y-coordinate. required Returns: Name Type Description tuple Row and column indices. Source code in tripsender\\routing.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 def rowcol ( transform , x , y ): \"\"\" Convert real-world coordinates to pixel coordinates. Args: transform (Affine): Affine transform. x (float): X-coordinate. y (float): Y-coordinate. Returns: tuple: Row and column indices. \"\"\" # Convert real-world coordinates to pixel coordinates using the affine transform col , row = ~ transform * ( x , y ) # Use the inverse transform to map (x, y) to (row, col) return int ( row ), int ( col )","title":"rowcol"},{"location":"sampler/","text":"DurationSampler Bases: Sampler A class to sample durations based on a specified purpose, extending the Sampler class. Methods: Name Description sample_duration Sample a duration for a given purpose, optionally constrained by minimum and maximum duration. Source code in tripsender\\sampler.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 class DurationSampler ( Sampler ): \"\"\" A class to sample durations based on a specified purpose, extending the Sampler class. Methods: sample_duration(purpose, min_duration=None, max_duration=None): Sample a duration for a given purpose, optionally constrained by minimum and maximum duration. \"\"\" def sample_duration ( self , purpose , min_duration = None , max_duration = None ): # Make purpose case insensitive purpose = purpose . lower () # Make labels in json_data case insensitive self . json_data = { k . lower (): v for k , v in self . json_data . items ()} if purpose not in self . json_data : print ( f \"No data found for purpose: { purpose } \" ) return None data = self . json_data [ purpose ] sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_minutes = sample * 60 # Ensure the sample is within the desired range while ( min_duration is not None and sample_minutes < min_duration ) or ( max_duration is not None and sample_minutes > max_duration ): sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_minutes = sample * 60 # Round to nearest minute sample_minutes = round ( sample_minutes ) return sample_minutes Sampler A class to sample from various statistical distributions. Attributes: Name Type Description json_data dict The input JSON data containing distribution parameters. gmm_cache dict Cache for Gaussian Mixture Model (GMM) objects. Methods: Name Description _get_gmm Retrieve or create a Gaussian Mixture Model (GMM) with the specified number of components and parameters. sample_from_distribution Sample from the specified statistical distribution using the provided parameters. Source code in tripsender\\sampler.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class Sampler : \"\"\" A class to sample from various statistical distributions. Attributes: json_data (dict): The input JSON data containing distribution parameters. gmm_cache (dict): Cache for Gaussian Mixture Model (GMM) objects. Methods: _get_gmm(num_components, parameters): Retrieve or create a Gaussian Mixture Model (GMM) with the specified number of components and parameters. sample_from_distribution(distribution_type, parameters): Sample from the specified statistical distribution using the provided parameters. \"\"\" def __init__ ( self , json_data ): self . json_data = json_data self . gmm_cache = {} # Cache for GMM objects def _get_gmm ( self , num_components , parameters ): # Check cache for an existing GMM with the desired number of components cache_key = f \"gmm_ { num_components } \" if cache_key not in self . gmm_cache : # If not in cache, create a new GMM gmm = GaussianMixture ( n_components = num_components , covariance_type = 'full' ) # Set means gmm . means_ = np . array ( parameters [ 1 ]) . reshape ( num_components , - 1 ) # Set covariances and ensure they are correctly shaped for 'full' covariance type covariances = np . array ( parameters [ 2 ]) if len ( covariances . shape ) == 2 : covariances = covariances . reshape ( num_components , covariances . shape [ 2 ], covariances . shape [ 2 ]) gmm . covariances_ = covariances # Set weights and normalize them weights = np . array ( parameters [ 0 ]) . flatten () normalized_weights = weights / weights . sum () gmm . weights_ = normalized_weights # Store the newly created GMM in the cache self . gmm_cache [ cache_key ] = gmm # Return the GMM (either from cache or the newly created one) return self . gmm_cache [ cache_key ] def sample_from_distribution ( self , distribution_type , parameters ): if distribution_type == 'gamma' : return gamma . rvs ( * parameters ) elif distribution_type == 'invgauss' : return invgauss . rvs ( * parameters ) elif distribution_type == 'lognorm' : return lognorm . rvs ( * parameters ) elif distribution_type == 'genextreme' : return genextreme . rvs ( * parameters ) elif distribution_type == 'weibull_max' : return weibull_max . rvs ( * parameters ) elif distribution_type in [ 'bimodal' , 'trimodal' ]: num_components = 2 if distribution_type == 'bimodal' else 3 gmm = self . _get_gmm ( num_components , parameters ) return float ( gmm . sample ()[ 0 ][ 0 ][ 0 ]) else : raise ValueError ( f \"Unsupported distribution type: { distribution_type } \" ) StartTimeSampler Bases: Sampler A class to sample start times based on a specified purpose, extending the Sampler class. Methods: Name Description sample_start_time Sample a start time for a given purpose, optionally constrained by minimum and maximum time. Source code in tripsender\\sampler.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class StartTimeSampler ( Sampler ): \"\"\" A class to sample start times based on a specified purpose, extending the Sampler class. Methods: sample_start_time(purpose, min_time=None, max_time=None): Sample a start time for a given purpose, optionally constrained by minimum and maximum time. \"\"\" def sample_start_time ( self , purpose , min_time = None , max_time = None ): if purpose not in self . json_data : print ( f \"No data found for purpose: { purpose } \" ) return None data = self . json_data [ purpose ] sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_time = abs ( sample ) % 24 # Wrap around to fit within 24 hours and ensure non-negative # Ensure the sample is within the desired range while ( min_time is not None and sample_time < min_time ) or ( max_time is not None and sample_time > max_time ): sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_time = abs ( sample ) % 24 # Return in 'HHMM' format return f \" { int ( sample_time ) : 02d }{ int (( sample_time * 60 ) % 60 ) : 02d } \"","title":"sampler"},{"location":"sampler/#tripsender.sampler.DurationSampler","text":"Bases: Sampler A class to sample durations based on a specified purpose, extending the Sampler class. Methods: Name Description sample_duration Sample a duration for a given purpose, optionally constrained by minimum and maximum duration. Source code in tripsender\\sampler.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 class DurationSampler ( Sampler ): \"\"\" A class to sample durations based on a specified purpose, extending the Sampler class. Methods: sample_duration(purpose, min_duration=None, max_duration=None): Sample a duration for a given purpose, optionally constrained by minimum and maximum duration. \"\"\" def sample_duration ( self , purpose , min_duration = None , max_duration = None ): # Make purpose case insensitive purpose = purpose . lower () # Make labels in json_data case insensitive self . json_data = { k . lower (): v for k , v in self . json_data . items ()} if purpose not in self . json_data : print ( f \"No data found for purpose: { purpose } \" ) return None data = self . json_data [ purpose ] sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_minutes = sample * 60 # Ensure the sample is within the desired range while ( min_duration is not None and sample_minutes < min_duration ) or ( max_duration is not None and sample_minutes > max_duration ): sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_minutes = sample * 60 # Round to nearest minute sample_minutes = round ( sample_minutes ) return sample_minutes","title":"DurationSampler"},{"location":"sampler/#tripsender.sampler.Sampler","text":"A class to sample from various statistical distributions. Attributes: Name Type Description json_data dict The input JSON data containing distribution parameters. gmm_cache dict Cache for Gaussian Mixture Model (GMM) objects. Methods: Name Description _get_gmm Retrieve or create a Gaussian Mixture Model (GMM) with the specified number of components and parameters. sample_from_distribution Sample from the specified statistical distribution using the provided parameters. Source code in tripsender\\sampler.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class Sampler : \"\"\" A class to sample from various statistical distributions. Attributes: json_data (dict): The input JSON data containing distribution parameters. gmm_cache (dict): Cache for Gaussian Mixture Model (GMM) objects. Methods: _get_gmm(num_components, parameters): Retrieve or create a Gaussian Mixture Model (GMM) with the specified number of components and parameters. sample_from_distribution(distribution_type, parameters): Sample from the specified statistical distribution using the provided parameters. \"\"\" def __init__ ( self , json_data ): self . json_data = json_data self . gmm_cache = {} # Cache for GMM objects def _get_gmm ( self , num_components , parameters ): # Check cache for an existing GMM with the desired number of components cache_key = f \"gmm_ { num_components } \" if cache_key not in self . gmm_cache : # If not in cache, create a new GMM gmm = GaussianMixture ( n_components = num_components , covariance_type = 'full' ) # Set means gmm . means_ = np . array ( parameters [ 1 ]) . reshape ( num_components , - 1 ) # Set covariances and ensure they are correctly shaped for 'full' covariance type covariances = np . array ( parameters [ 2 ]) if len ( covariances . shape ) == 2 : covariances = covariances . reshape ( num_components , covariances . shape [ 2 ], covariances . shape [ 2 ]) gmm . covariances_ = covariances # Set weights and normalize them weights = np . array ( parameters [ 0 ]) . flatten () normalized_weights = weights / weights . sum () gmm . weights_ = normalized_weights # Store the newly created GMM in the cache self . gmm_cache [ cache_key ] = gmm # Return the GMM (either from cache or the newly created one) return self . gmm_cache [ cache_key ] def sample_from_distribution ( self , distribution_type , parameters ): if distribution_type == 'gamma' : return gamma . rvs ( * parameters ) elif distribution_type == 'invgauss' : return invgauss . rvs ( * parameters ) elif distribution_type == 'lognorm' : return lognorm . rvs ( * parameters ) elif distribution_type == 'genextreme' : return genextreme . rvs ( * parameters ) elif distribution_type == 'weibull_max' : return weibull_max . rvs ( * parameters ) elif distribution_type in [ 'bimodal' , 'trimodal' ]: num_components = 2 if distribution_type == 'bimodal' else 3 gmm = self . _get_gmm ( num_components , parameters ) return float ( gmm . sample ()[ 0 ][ 0 ][ 0 ]) else : raise ValueError ( f \"Unsupported distribution type: { distribution_type } \" )","title":"Sampler"},{"location":"sampler/#tripsender.sampler.StartTimeSampler","text":"Bases: Sampler A class to sample start times based on a specified purpose, extending the Sampler class. Methods: Name Description sample_start_time Sample a start time for a given purpose, optionally constrained by minimum and maximum time. Source code in tripsender\\sampler.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class StartTimeSampler ( Sampler ): \"\"\" A class to sample start times based on a specified purpose, extending the Sampler class. Methods: sample_start_time(purpose, min_time=None, max_time=None): Sample a start time for a given purpose, optionally constrained by minimum and maximum time. \"\"\" def sample_start_time ( self , purpose , min_time = None , max_time = None ): if purpose not in self . json_data : print ( f \"No data found for purpose: { purpose } \" ) return None data = self . json_data [ purpose ] sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_time = abs ( sample ) % 24 # Wrap around to fit within 24 hours and ensure non-negative # Ensure the sample is within the desired range while ( min_time is not None and sample_time < min_time ) or ( max_time is not None and sample_time > max_time ): sample = self . sample_from_distribution ( data [ 'distribution' ], data [ 'parameters' ]) sample_time = abs ( sample ) % 24 # Return in 'HHMM' format return f \" { int ( sample_time ) : 02d }{ int (( sample_time * 60 ) % 60 ) : 02d } \"","title":"StartTimeSampler"},{"location":"synthpop/","text":"generate_persons ( population , num_persons = None ) Generate individual person objects based on the given population data. This function generates a number of Person instances based on the demographic distribution provided in the population data. It uses the age, household type, and sex categories to proportionally create individuals that reflect the overall population structure. Parameters: Name Type Description Default population Population An instance of the Population class that contains demographic data. required num_persons int The number of persons to generate. If not specified, the function uses the total population size provided in the population data. None Returns: Type Description None The function performs the following steps: 1. If num_persons is specified, it uses that number; otherwise, it defaults to the total population size. 2. It clears any existing Person instances to start fresh. 3. It calculates the proportional distribution of individuals across different categories of age, household type, and sex based on the provided population data. 4. It iterates through the categories, creating the appropriate number of Person instances for each category, and assigns them to the respective age, household type, and sex. Example usage population_data = Population(year=2023, area=\"Haga\") generate_persons(population_data) Source code in tripsender\\synthpop.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def generate_persons ( population , num_persons = None ): \"\"\" Generate individual person objects based on the given population data. This function generates a number of Person instances based on the demographic distribution provided in the population data. It uses the age, household type, and sex categories to proportionally create individuals that reflect the overall population structure. Args: population (Population): An instance of the Population class that contains demographic data. num_persons (int, optional): The number of persons to generate. If not specified, the function uses the total population size provided in the population data. Returns: None The function performs the following steps: 1. If num_persons is specified, it uses that number; otherwise, it defaults to the total population size. 2. It clears any existing Person instances to start fresh. 3. It calculates the proportional distribution of individuals across different categories of age, household type, and sex based on the provided population data. 4. It iterates through the categories, creating the appropriate number of Person instances for each category, and assigns them to the respective age, household type, and sex. Example usage: >>> population_data = Population(year=2023, area=\"Haga\") >>> generate_persons(population_data) \"\"\" if num_persons : # If num_persons is specified, use that number logger . info ( f \"Number of persons: { num_persons } \" ) #TODO Not implemented pass else : # Otherwise, use the total population num_persons = population . total_population logger . info ( f \"Number of persons: { num_persons } \" ) pop_distribution = population . array_age_household_sex / population . total_population household_labels = population . variable_categories [ 'Hush\u00e5llsst\u00e4llning' ] age_labels = population . variable_categories [ '\u00c5lder' ] sex_labels = population . variable_categories [ 'K\u00f6n' ] # Clear the instances of Person Person . clear_instances () # Generating persons based on the population distribution for i , age in enumerate ( age_labels ): for j , household in enumerate ( household_labels ): for k , sex in enumerate ( sex_labels ): person_range = int ( pop_distribution [ i , j , k ] * num_persons ) for _ in range ( person_range ): Person ( age , sex , household ) synthesise_population ( population , age_split = 45 , min_age_of_parent = 25 ) Synthesise a population by creating households and assigning attributes to individuals and households. This function creates and assigns households, assigns children to households, and sets various attributes such as house type and car ownership for the generated population. The process involves multiple steps to ensure that the synthesized population accurately reflects real-world demographic patterns and household structures. Parameters: Name Type Description Default population Population An instance of the Population class containing demographic data. required age_split int The age threshold used to categorize children into different age groups. Defaults to 45. 45 min_age_of_parent int The minimum age for an individual to be considered a parent. Defaults to 25. 25 Returns: Type Description None The function performs the following steps: 1. Retrieves the total number of households for the specified year and area. 2. Clears any existing Household instances to start fresh. 3. Splits individuals into different lists based on their household type categories (e.g., children, single parents, living alone, married, cohabiting, others). 4. Sorts the lists to prioritize older individuals for certain categories. 5. Creates households for individuals living alone and single parents. 6. Creates households for married and cohabiting couples. 7. Assigns remaining individuals to 'Other' category households. 8. Assigns children to appropriate households based on their age and household type. 9. Assigns house types to households based on the specified year and area. 10. Assigns car ownership to households using a pre-trained classifier model. 11. Assigns primary status (e.g., studying, working, inactive) to individuals using a pre-trained classifier model. Example usage population_data = Population(year=2023, area=\"Haga\") synthesise_population(population_data) Source code in tripsender\\synthpop.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def synthesise_population ( population , age_split = 45 , min_age_of_parent = 25 ): \"\"\" Synthesise a population by creating households and assigning attributes to individuals and households. This function creates and assigns households, assigns children to households, and sets various attributes such as house type and car ownership for the generated population. The process involves multiple steps to ensure that the synthesized population accurately reflects real-world demographic patterns and household structures. Args: population (Population): An instance of the Population class containing demographic data. age_split (int, optional): The age threshold used to categorize children into different age groups. Defaults to 45. min_age_of_parent (int, optional): The minimum age for an individual to be considered a parent. Defaults to 25. Returns: None The function performs the following steps: 1. Retrieves the total number of households for the specified year and area. 2. Clears any existing Household instances to start fresh. 3. Splits individuals into different lists based on their household type categories (e.g., children, single parents, living alone, married, cohabiting, others). 4. Sorts the lists to prioritize older individuals for certain categories. 5. Creates households for individuals living alone and single parents. 6. Creates households for married and cohabiting couples. 7. Assigns remaining individuals to 'Other' category households. 8. Assigns children to appropriate households based on their age and household type. 9. Assigns house types to households based on the specified year and area. 10. Assigns car ownership to households using a pre-trained classifier model. 11. Assigns primary status (e.g., studying, working, inactive) to individuals using a pre-trained classifier model. Example usage: >>> population_data = Population(year=2023, area=\"Haga\") >>> synthesise_population(population_data) \"\"\" # Get total households year = population . year area = population . area total_households = tsutils . fetch_total_households ( year , area ) logger . info ( f \"Total households: { total_households } \" ) # Split individuals into different lists based on their category children , single_parents , living_alone , married_males , married_females , cohabiting_males , cohabiting_females , others = tsutils . split_households_by_householdtype () # # Print counts and totals # logger.info(f\"Children: {len(children)}\") # logger.info(f\"Single Parents: {len(single_parents)}\") # logger.info(f\"Living Alone: {len(living_alone)}\") # logger.info(f\"Married Male: {len(married_males)}\") # logger.info(f\"Married Female: {len(married_females)}\") # logger.info(f\"Cohabiting Male: {len(cohabiting_males)}\") # logger.info(f\"Cohabiting Female: {len(cohabiting_females)}\") # logger.info(f\"Others: {len(others)}\") # logger.info(f\"Total: {len(children)+len(single_parents)+len(living_alone)+len(married_males)+len(married_females)+len(cohabiting_males)+len(cohabiting_females)+len(others)}\") # Sort children by age # Trying reverse to prioritize older parents first children . sort ( key = lambda x : x . age , reverse = True ) # Sort single parents by age single_parents . sort ( key = lambda x : x . age , reverse = True ) Household . clear_instances () households = [] # Step 1 - Create Households # Living alone -> Single logger . info ( f \"Total households after living alone: ie { total_households } - { len ( living_alone ) } = { total_households - len ( living_alone ) } \" ) for person in living_alone : household = Household ( 'Single' ) household . add_member ( person ) households . append ( household ) total_households -= len ( living_alone ) # Single parents -> Single logger . info ( f \"Total households after single parents: ie { total_households } - { len ( single_parents ) } = { total_households - len ( single_parents ) } \" ) for person in single_parents : household = Household ( 'Single' ) household . add_member ( person ) household . has_children = True households . append ( household ) total_households -= len ( single_parents ) # Married Couple / Cohabiting -> Couple len_couple_households , couple_households = tsutils . couples_from_individuals ( married_males + cohabiting_males , married_females + cohabiting_females ) logger . info ( f \"Len of couple households: { len_couple_households } \" ) logger . info ( f \"Actual len of couple households: { len ( couple_households ) } \" ) households . extend ( couple_households ) logger . info ( f \"Total households after couples: ie { total_households } - { len_couple_households } = { total_households - len_couple_households } \" ) total_households -= len_couple_households # Other -> Other # Currently being undercounted random . shuffle ( others ) for person in others : person = others . pop () household = Household ( 'Other' ) household . add_member ( person ) households . append ( household ) total_households -= 1 logger . info ( f \"Total households after others: ie { total_households } - { len ( others ) } = { total_households - len ( others ) } \" ) other_households = [ household for household in households if household . category == 'Other' ] logger . info ( f \"Total other households: { len ( other_households ) } \" ) while others and other_households : person = others . pop () household = random . choice ( other_households ) household . add_member ( person ) # Step 2 - Assigning Children tsutils . assign_children_to_households ( year , area , children , age_split ) Household . sync_children_in_households () # Step 3 - Assigning a housetype to the households tsutils . assign_house_type_to_households ( year , area ) # Step 4 - Assigning car ownership to households car_classifier = joblib . load ( 'models/NHTS_CAR_OWNERSHIP_CLASSIFIER.joblib' ) tsutils . assign_cars_to_households ( year , area , car_classifier ) # Step 5 - Assigning primary status to persons primary_status_classifier = joblib . load ( 'models/NHTS_PRIMARY_STATUS_CLASSIFIER.joblib' ) tsutils . assign_primary_status_to_members ( year , area , primary_status_classifier )","title":"synthpop"},{"location":"synthpop/#tripsender.synthpop.generate_persons","text":"Generate individual person objects based on the given population data. This function generates a number of Person instances based on the demographic distribution provided in the population data. It uses the age, household type, and sex categories to proportionally create individuals that reflect the overall population structure. Parameters: Name Type Description Default population Population An instance of the Population class that contains demographic data. required num_persons int The number of persons to generate. If not specified, the function uses the total population size provided in the population data. None Returns: Type Description None The function performs the following steps: 1. If num_persons is specified, it uses that number; otherwise, it defaults to the total population size. 2. It clears any existing Person instances to start fresh. 3. It calculates the proportional distribution of individuals across different categories of age, household type, and sex based on the provided population data. 4. It iterates through the categories, creating the appropriate number of Person instances for each category, and assigns them to the respective age, household type, and sex. Example usage population_data = Population(year=2023, area=\"Haga\") generate_persons(population_data) Source code in tripsender\\synthpop.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def generate_persons ( population , num_persons = None ): \"\"\" Generate individual person objects based on the given population data. This function generates a number of Person instances based on the demographic distribution provided in the population data. It uses the age, household type, and sex categories to proportionally create individuals that reflect the overall population structure. Args: population (Population): An instance of the Population class that contains demographic data. num_persons (int, optional): The number of persons to generate. If not specified, the function uses the total population size provided in the population data. Returns: None The function performs the following steps: 1. If num_persons is specified, it uses that number; otherwise, it defaults to the total population size. 2. It clears any existing Person instances to start fresh. 3. It calculates the proportional distribution of individuals across different categories of age, household type, and sex based on the provided population data. 4. It iterates through the categories, creating the appropriate number of Person instances for each category, and assigns them to the respective age, household type, and sex. Example usage: >>> population_data = Population(year=2023, area=\"Haga\") >>> generate_persons(population_data) \"\"\" if num_persons : # If num_persons is specified, use that number logger . info ( f \"Number of persons: { num_persons } \" ) #TODO Not implemented pass else : # Otherwise, use the total population num_persons = population . total_population logger . info ( f \"Number of persons: { num_persons } \" ) pop_distribution = population . array_age_household_sex / population . total_population household_labels = population . variable_categories [ 'Hush\u00e5llsst\u00e4llning' ] age_labels = population . variable_categories [ '\u00c5lder' ] sex_labels = population . variable_categories [ 'K\u00f6n' ] # Clear the instances of Person Person . clear_instances () # Generating persons based on the population distribution for i , age in enumerate ( age_labels ): for j , household in enumerate ( household_labels ): for k , sex in enumerate ( sex_labels ): person_range = int ( pop_distribution [ i , j , k ] * num_persons ) for _ in range ( person_range ): Person ( age , sex , household )","title":"generate_persons"},{"location":"synthpop/#tripsender.synthpop.synthesise_population","text":"Synthesise a population by creating households and assigning attributes to individuals and households. This function creates and assigns households, assigns children to households, and sets various attributes such as house type and car ownership for the generated population. The process involves multiple steps to ensure that the synthesized population accurately reflects real-world demographic patterns and household structures. Parameters: Name Type Description Default population Population An instance of the Population class containing demographic data. required age_split int The age threshold used to categorize children into different age groups. Defaults to 45. 45 min_age_of_parent int The minimum age for an individual to be considered a parent. Defaults to 25. 25 Returns: Type Description None The function performs the following steps: 1. Retrieves the total number of households for the specified year and area. 2. Clears any existing Household instances to start fresh. 3. Splits individuals into different lists based on their household type categories (e.g., children, single parents, living alone, married, cohabiting, others). 4. Sorts the lists to prioritize older individuals for certain categories. 5. Creates households for individuals living alone and single parents. 6. Creates households for married and cohabiting couples. 7. Assigns remaining individuals to 'Other' category households. 8. Assigns children to appropriate households based on their age and household type. 9. Assigns house types to households based on the specified year and area. 10. Assigns car ownership to households using a pre-trained classifier model. 11. Assigns primary status (e.g., studying, working, inactive) to individuals using a pre-trained classifier model. Example usage population_data = Population(year=2023, area=\"Haga\") synthesise_population(population_data) Source code in tripsender\\synthpop.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def synthesise_population ( population , age_split = 45 , min_age_of_parent = 25 ): \"\"\" Synthesise a population by creating households and assigning attributes to individuals and households. This function creates and assigns households, assigns children to households, and sets various attributes such as house type and car ownership for the generated population. The process involves multiple steps to ensure that the synthesized population accurately reflects real-world demographic patterns and household structures. Args: population (Population): An instance of the Population class containing demographic data. age_split (int, optional): The age threshold used to categorize children into different age groups. Defaults to 45. min_age_of_parent (int, optional): The minimum age for an individual to be considered a parent. Defaults to 25. Returns: None The function performs the following steps: 1. Retrieves the total number of households for the specified year and area. 2. Clears any existing Household instances to start fresh. 3. Splits individuals into different lists based on their household type categories (e.g., children, single parents, living alone, married, cohabiting, others). 4. Sorts the lists to prioritize older individuals for certain categories. 5. Creates households for individuals living alone and single parents. 6. Creates households for married and cohabiting couples. 7. Assigns remaining individuals to 'Other' category households. 8. Assigns children to appropriate households based on their age and household type. 9. Assigns house types to households based on the specified year and area. 10. Assigns car ownership to households using a pre-trained classifier model. 11. Assigns primary status (e.g., studying, working, inactive) to individuals using a pre-trained classifier model. Example usage: >>> population_data = Population(year=2023, area=\"Haga\") >>> synthesise_population(population_data) \"\"\" # Get total households year = population . year area = population . area total_households = tsutils . fetch_total_households ( year , area ) logger . info ( f \"Total households: { total_households } \" ) # Split individuals into different lists based on their category children , single_parents , living_alone , married_males , married_females , cohabiting_males , cohabiting_females , others = tsutils . split_households_by_householdtype () # # Print counts and totals # logger.info(f\"Children: {len(children)}\") # logger.info(f\"Single Parents: {len(single_parents)}\") # logger.info(f\"Living Alone: {len(living_alone)}\") # logger.info(f\"Married Male: {len(married_males)}\") # logger.info(f\"Married Female: {len(married_females)}\") # logger.info(f\"Cohabiting Male: {len(cohabiting_males)}\") # logger.info(f\"Cohabiting Female: {len(cohabiting_females)}\") # logger.info(f\"Others: {len(others)}\") # logger.info(f\"Total: {len(children)+len(single_parents)+len(living_alone)+len(married_males)+len(married_females)+len(cohabiting_males)+len(cohabiting_females)+len(others)}\") # Sort children by age # Trying reverse to prioritize older parents first children . sort ( key = lambda x : x . age , reverse = True ) # Sort single parents by age single_parents . sort ( key = lambda x : x . age , reverse = True ) Household . clear_instances () households = [] # Step 1 - Create Households # Living alone -> Single logger . info ( f \"Total households after living alone: ie { total_households } - { len ( living_alone ) } = { total_households - len ( living_alone ) } \" ) for person in living_alone : household = Household ( 'Single' ) household . add_member ( person ) households . append ( household ) total_households -= len ( living_alone ) # Single parents -> Single logger . info ( f \"Total households after single parents: ie { total_households } - { len ( single_parents ) } = { total_households - len ( single_parents ) } \" ) for person in single_parents : household = Household ( 'Single' ) household . add_member ( person ) household . has_children = True households . append ( household ) total_households -= len ( single_parents ) # Married Couple / Cohabiting -> Couple len_couple_households , couple_households = tsutils . couples_from_individuals ( married_males + cohabiting_males , married_females + cohabiting_females ) logger . info ( f \"Len of couple households: { len_couple_households } \" ) logger . info ( f \"Actual len of couple households: { len ( couple_households ) } \" ) households . extend ( couple_households ) logger . info ( f \"Total households after couples: ie { total_households } - { len_couple_households } = { total_households - len_couple_households } \" ) total_households -= len_couple_households # Other -> Other # Currently being undercounted random . shuffle ( others ) for person in others : person = others . pop () household = Household ( 'Other' ) household . add_member ( person ) households . append ( household ) total_households -= 1 logger . info ( f \"Total households after others: ie { total_households } - { len ( others ) } = { total_households - len ( others ) } \" ) other_households = [ household for household in households if household . category == 'Other' ] logger . info ( f \"Total other households: { len ( other_households ) } \" ) while others and other_households : person = others . pop () household = random . choice ( other_households ) household . add_member ( person ) # Step 2 - Assigning Children tsutils . assign_children_to_households ( year , area , children , age_split ) Household . sync_children_in_households () # Step 3 - Assigning a housetype to the households tsutils . assign_house_type_to_households ( year , area ) # Step 4 - Assigning car ownership to households car_classifier = joblib . load ( 'models/NHTS_CAR_OWNERSHIP_CLASSIFIER.joblib' ) tsutils . assign_cars_to_households ( year , area , car_classifier ) # Step 5 - Assigning primary status to persons primary_status_classifier = joblib . load ( 'models/NHTS_PRIMARY_STATUS_CLASSIFIER.joblib' ) tsutils . assign_primary_status_to_members ( year , area , primary_status_classifier )","title":"synthesise_population"},{"location":"utils/","text":"assign_cars_to_households ( year , area , classifier ) Assign car ownership to households based on a classifier model. This function assigns car ownership to households in the specified year and area using a pre-trained classifier model. It predicts the probability of car ownership for each household and assigns cars based on the top predictions. Parameters: Name Type Description Default year int The year for which to assign car ownership. required area str The geographical area for which to assign car ownership. required classifier object The pre-trained classifier model for predicting car ownership. required Returns: Type Description None The function performs the following steps: 1. Fetches car ownership data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of car ownership for each household. 4. Assigns car ownership based on the top predictions. 5. Caps the number of cars per household to a specified maximum. 6. Logs the total number of cars after capping. Source code in tripsender\\utils.py 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 def assign_cars_to_households ( year , area , classifier ): \"\"\" Assign car ownership to households based on a classifier model. This function assigns car ownership to households in the specified year and area using a pre-trained classifier model. It predicts the probability of car ownership for each household and assigns cars based on the top predictions. Args: year (int): The year for which to assign car ownership. area (str): The geographical area for which to assign car ownership. classifier (object): The pre-trained classifier model for predicting car ownership. Returns: None The function performs the following steps: 1. Fetches car ownership data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of car ownership for each household. 4. Assigns car ownership based on the top predictions. 5. Caps the number of cars per household to a specified maximum. 6. Logs the total number of cars after capping. \"\"\" # Provide the estimated total cars and call the function to scale and optionally plot the results car_data = fetch_car_data ( year , area ) estimated_total_cars = int ( car_data [ \"data\" ][ 0 ][ \"values\" ][ 0 ]) logger . info ( f \"Total estimated cars in neighborhood: { estimated_total_cars } \" ) aligned_columns = [ 'child_count' , 'adult_count' , 'x0_Kvinnor' , 'x0_M\u00e4n' , 'x0_Other' , 'x1_16-24' , 'x1_25-34' , 'x1_35-44' , 'x1_45-54' , 'x1_55-64' , 'x1_65-74' , 'x1_75+' , 'x2_Apartment' , 'x2_Other' , 'x2_Villa' , 'x3_Couple' , 'x3_Other' , 'x3_Single' , 'x2_Not Available' ] df , adults = preprocess_household_data ( aligned_columns = aligned_columns , drop = [ 'car_count' , 'primary_status' ], onehotencode = True ) # Predict probabilities using the classifier probs = classifier . predict_proba ( df )[:, 1 ] # Assign car_count based on the top estimated_total_cars predictions top_indices = ( - probs ) . argsort ()[: estimated_total_cars ] df [ 'car_count' ] = 0 df . loc [ top_indices , 'car_count' ] = 1 # Assign cars to individuals and calculate household cars for i , person in enumerate ( adults ): person . has_car = df [ 'car_count' ][ i ] for household in Household . instances : household . cars = sum ( person . has_car for person in household . members ) # Cap the number of cars per household to a maximum of 3 cap_cars_per_household ( Household . instances ) total_cars_after_capping = sum ( household . cars for household in Household . instances ) logger . info ( f \"Total cars in neighborhood after capping to 4: { total_cars_after_capping } \" ) assign_children_to_households ( year , area , children , age_split , min_age_of_parent = 25 ) Assign children to households based on age and probability data. This function assigns children to households for the specified year and area using probability data and age-based categorization. It splits households into different categories based on the age of the head and assigns children accordingly. Parameters: Name Type Description Default year int The year for which to assign children. required area str The geographical area for which to assign children. required children list The list of children to be assigned. required age_split int The age threshold to categorize households. required min_age_of_parent int The minimum age for a parent. Defaults to 25. 25 Returns: Type Description None The function performs the following steps: 1. Determines if a household has children based on probability data. 2. Splits households into different categories based on the age of the head. 3. Assigns the number of children to each household based on the probability matrix. 4. Randomly adjusts the number of children in households to match the total number of children. 5. Matches children to households based on the number of children needed. 6. Updates the has_child attribute for each person in the household. 7. Logs the assignment process and results. Source code in tripsender\\utils.py 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 def assign_children_to_households ( year , area , children , age_split , min_age_of_parent = 25 ): \"\"\" Assign children to households based on age and probability data. This function assigns children to households for the specified year and area using probability data and age-based categorization. It splits households into different categories based on the age of the head and assigns children accordingly. Args: year (int): The year for which to assign children. area (str): The geographical area for which to assign children. children (list): The list of children to be assigned. age_split (int): The age threshold to categorize households. min_age_of_parent (int, optional): The minimum age for a parent. Defaults to 25. Returns: None The function performs the following steps: 1. Determines if a household has children based on probability data. 2. Splits households into different categories based on the age of the head. 3. Assigns the number of children to each household based on the probability matrix. 4. Randomly adjusts the number of children in households to match the total number of children. 5. Matches children to households based on the number of children needed. 6. Updates the has_child attribute for each person in the household. 7. Logs the assignment process and results. \"\"\" # Step 1 - Determine if a household has children households = Household . instances households . sort ( key = lambda household : random . choice ([ member . age for member in household . members if not member . is_child ])) # Get probability of having children p_children = get_probability_of_children ( year , area ) # Given the household type, calculate the probability of having children in household.has_children for household in households : category = household . category # Single parent households are assumed to have children already if category == 'Couple' : household . has_children = np . random . choice ([ True , False ], p = [ p_children [ 'Couple' ][ True ], p_children [ 'Couple' ][ False ]]) elif category == 'Other' : household . has_children = np . random . choice ([ True , False ], p = [ p_children [ 'Other' ][ True ], p_children [ 'Other' ][ False ]]) # Step 2 - Determine the age at which a person had their first child 25 years ago # Filter households that have children and are either Couple or Other households_with_children = [ household for household in households if household . has_children and household . category in [ 'Single' , 'Couple' , 'Other' ]] # Split households based on the age of the head # These will get older children above 45 households_with_children_above_age_split = [ household for household in households_with_children if household . members [ 0 ] . age > age_split ] # These will get younger children below 45 households_with_children_below_age_split = [ household for household in households_with_children if household . members [ 0 ] . age <= age_split ] # Get the probability matrix for the number of children in each household category p_matrix_0_24 , p_matrix_25 = impute_municipal_children_count ( year , area ) # Step 3 - Assign number of children to households with children for household in households_with_children_below_age_split : # Get household category category = household . category # Get the probability matrix for the household category if category == 'Single' : p_matrix = p_matrix_0_24 [ 'Single' ] elif category == 'Couple' : p_matrix = p_matrix_0_24 [ 'Couple' ] elif category == 'Other' : p_matrix = p_matrix_0_24 [ 'Other' ] # Sample from p_matrix household . children = np . random . choice ([ 1 , 2 , 3 ], p = [ p_matrix [ 1 ], p_matrix [ 2 ], p_matrix [ 3 ]]) # Repeat for households with children and age of head above 50 for household in households_with_children_above_age_split : # Get household category category = household . category # Get the probability matrix for the household category if category == 'Single' : p_matrix = p_matrix_25 [ 'Single' ] if category == 'Couple' : p_matrix = p_matrix_25 [ 'Couple' ] elif category == 'Other' : p_matrix = p_matrix_25 [ 'Other' ] # Sample from p_matrix household . children = np . random . choice ([ 1 , 2 , 3 ], p = [ p_matrix [ 1 ], p_matrix [ 2 ], p_matrix [ 3 ]]) # log number of children in households_with_children total_children_in_households = sum ( household . children for household in households_with_children ) # Randomly increase household.children to households with children < 3 until len(children) == total_children_in_households while len ( children ) > total_children_in_households : # Optionally shuffle the households to randomize which ones get extra children random . shuffle ( households_with_children ) increased = False # Flag to check if any household's child count was increased in this iteration for household in households_with_children : if household . children < 3 : household . children += 1 total_children_in_households += 1 increased = True if total_children_in_households == len ( children ): break # If no household's child count was increased in this iteration, break out of the loop to prevent infinite looping if not increased : break logger . info ( f \"Total number of children to be assigned: { total_children_in_households } \" ) logger . info ( f \"Total number of children: { len ( children ) } \" ) match_list_household_children ( households_with_children , children ) # Update has_child attribute for each person in the household based on the number of children in the household for household in households : household . update_has_child () assign_house_type_to_households ( year , area ) Assign house types to households based on probability data (improved method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an improved method that accounts for varying household sizes and assigns house types accordingly. Parameters: Name Type Description Default year int The year for which to assign house types. required area str The geographical area for which to assign house types. required Returns: Type Description None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key, with special handling for larger households. 3. Iterates through each household to assign house types based on the probability data. 4. Logs any cases where valid house type data is not available for certain household sizes. Source code in tripsender\\utils.py 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 def assign_house_type_to_households ( year , area ): \"\"\" Assign house types to households based on probability data (improved method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an improved method that accounts for varying household sizes and assigns house types accordingly. Args: year (int): The year for which to assign house types. area (str): The geographical area for which to assign house types. Returns: None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key, with special handling for larger households. 3. Iterates through each household to assign house types based on the probability data. 4. Logs any cases where valid house type data is not available for certain household sizes. \"\"\" p_housetype = get_probability_of_housetype ( year , area ) # Define a mapping from household size to the corresponding key in p_housetype size_to_key_mapping = { 1 : '1 person' , 2 : '2 personer' , 3 : '3 personer' , 4 : '4 personer' , 5 : '5 personer' , 6 : '6 eller fler personer' } for household in Household . instances : household_size = len ( household . members ) # For households larger than 6, start checking from '6 eller fler personer' if household_size > 6 : current_size = 6 else : current_size = household_size # Flag to indicate if a house type has been assigned assigned = False while current_size >= 1 : key = size_to_key_mapping [ current_size ] # Check if there's valid probability data for the current size probabilities = list ( p_housetype . get ( key , {}) . values ()) if sum ( probabilities ) > 0 : house_type = np . random . choice ( list ( p_housetype [ key ] . keys ()), p = probabilities ) household . house_type = house_type assigned = True break # Exit the loop once a house type is assigned current_size -= 1 # Decrement size to check the next smaller size if not assigned : # If no valid house type was assigned logger . info ( f \"No valid house type data for household size { household_size } or smaller. No house type assigned.\" ) assign_house_type_to_households_old ( year , area ) Assign house types to households based on probability data (old method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an older method that directly maps household sizes to house types. Parameters: Name Type Description Default year int The year for which to assign house types. required area str The geographical area for which to assign house types. required Returns: Type Description None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key. 3. Assigns house types to households based on the probability data. 4. Logs any cases where household size does not match the probability data. Source code in tripsender\\utils.py 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 def assign_house_type_to_households_old ( year , area ): \"\"\" Assign house types to households based on probability data (old method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an older method that directly maps household sizes to house types. Args: year (int): The year for which to assign house types. area (str): The geographical area for which to assign house types. Returns: None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key. 3. Assigns house types to households based on the probability data. 4. Logs any cases where household size does not match the probability data. \"\"\" p_housetype = get_probability_of_housetype ( year , area ) # Define a mapping from household size to the corresponding key in p_housetype size_to_key_mapping = { 1 : '1 person' , 2 : '2 personer' , 3 : '3 personer' , 4 : '4 personer' , 5 : '5 personer' , 6 : '6 eller fler personer' } for household in Household . instances : household_size = len ( household . members ) # Use the mapping to get the corresponding key for the household size key = size_to_key_mapping . get ( household_size , None ) if household_size > 6 : # Explicitly handle the case where size > 6 key = '6 eller fler personer' if key : house_type = np . random . choice ( list ( p_housetype [ key ] . keys ()), p = list ( p_housetype [ key ] . values ())) household . house_type = house_type else : logger . info ( f \"assign_house_type_to_households: Household size { household_size } not found in p_housetype\" ) assign_primary_status_to_members ( year , area , classifier ) Assign primary status (e.g., work, education, home) to household members. This function assigns primary status to household members for the specified year and area using a pre-trained classifier model. It predicts the probability of different primary statuses for each individual and assigns the status based on the top predictions. Parameters: Name Type Description Default year int The year for which to assign primary status. required area str The geographical area for which to assign primary status. required classifier object The pre-trained classifier model for predicting primary status. required Returns: Type Description None The function performs the following steps: 1. Fetches primary status data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of different primary statuses for each individual. 4. Assigns primary status to individuals based on the top predictions. 5. Logs the distribution of primary status among the household members. Source code in tripsender\\utils.py 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 def assign_primary_status_to_members ( year , area , classifier ): \"\"\" Assign primary status (e.g., work, education, home) to household members. This function assigns primary status to household members for the specified year and area using a pre-trained classifier model. It predicts the probability of different primary statuses for each individual and assigns the status based on the top predictions. Args: year (int): The year for which to assign primary status. area (str): The geographical area for which to assign primary status. classifier (object): The pre-trained classifier model for predicting primary status. Returns: None The function performs the following steps: 1. Fetches primary status data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of different primary statuses for each individual. 4. Assigns primary status to individuals based on the top predictions. 5. Logs the distribution of primary status among the household members. \"\"\" primary_dict = fetch_primary_status ( year , area ) # {'WORK': '6140', 'STUDY': '505', 'INACTIVE': '285'} working_count = int ( primary_dict [ 'WORK' ]) study_count = int ( primary_dict [ 'STUDY' ]) home_count = int ( primary_dict [ 'INACTIVE' ]) aligned_columns = [ 'child_count' , 'adult_count' , 'car_count' , 'x0_Kvinnor' , 'x0_M\u00e4n' , 'x0_Other' , 'x1_16-24' , 'x1_25-34' , 'x1_35-44' , 'x1_45-54' , 'x1_55-64' , 'x1_65-74' , 'x1_75+' , 'x2_Apartment' , 'x2_Other' , 'x2_Villa' , 'x3_Couple' , 'x3_Other' , 'x3_Single' , 'x2_Not Available' ] df , adults = preprocess_household_data ( aligned_columns = aligned_columns , drop = [ 'primary_status' ], onehotencode = True ) # Assume 'classifier' and 'df' are already defined and ready probs = classifier . predict_proba ( df ) # Initialize all to 'NA' (or another default status) df [ 'primary_status' ] = 'NA' # Sort indices based on probabilities for 'WORK' work_indices = np . argsort ( - probs [:, 0 ])[: working_count ] df . loc [ work_indices , 'primary_status' ] = 'WORK' # Exclude already assigned 'WORK' from 'STUDY' remaining_for_study = df [ df [ 'primary_status' ] == 'NA' ] study_indices = np . argsort ( - probs [ remaining_for_study . index , 1 ])[: study_count ] df . loc [ study_indices , 'primary_status' ] = 'EDUCATION' # Assign 'HOME' to the remaining, if needed remaining_for_home = df [ df [ 'primary_status' ] == 'NA' ] if len ( remaining_for_home ) > home_count : home_indices = np . argsort ( - probs [ remaining_for_home . index , 2 ])[: home_count ] df . loc [ home_indices , 'primary_status' ] = 'HOME' else : df . loc [ remaining_for_home . index , 'primary_status' ] = 'HOME' # Update the primary status of adults based on the DataFrame for i , adult in enumerate ( adults ): adult . primary_status = df . loc [ i , 'primary_status' ] workers , students , neither = [], [], [] for person in Person . instances : if person . primary_status == \"WORK\" : workers . append ( person ) elif person . primary_status == \"EDUCATION\" : students . append ( person ) elif person . primary_status == \"HOME\" : neither . append ( person ) logger . info ( f \"Number of workers: { len ( workers ) } - { len ( workers ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of students: { len ( students ) } - { len ( students ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of neither: { len ( neither ) } - { len ( neither ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Total number of persons: { len ( Person . instances ) } \" ) assign_primary_status_to_members_backup ( classifier ) Assign primary status (e.g., work, education, home) to household members using a backup method. This function assigns primary status to household members using a pre-trained classifier model. It predicts the primary status for each individual based on household data and assigns the corresponding status to each member. Parameters: Name Type Description Default classifier object The pre-trained classifier model for predicting primary status. required Returns: Type Description None The function performs the following steps: 1. Preprocesses household data for model input. 2. Predicts the primary status for each individual using the classifier. 3. Assigns the predicted primary status to each member. 4. Logs the distribution of primary status among the household members. Source code in tripsender\\utils.py 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 def assign_primary_status_to_members_backup ( classifier ): \"\"\" Assign primary status (e.g., work, education, home) to household members using a backup method. This function assigns primary status to household members using a pre-trained classifier model. It predicts the primary status for each individual based on household data and assigns the corresponding status to each member. Args: classifier (object): The pre-trained classifier model for predicting primary status. Returns: None The function performs the following steps: 1. Preprocesses household data for model input. 2. Predicts the primary status for each individual using the classifier. 3. Assigns the predicted primary status to each member. 4. Logs the distribution of primary status among the household members. \"\"\" aligned_columns = [ 'child_count' , 'adult_count' , 'car_count' , 'x0_Kvinnor' , 'x0_M\u00e4n' , 'x0_Other' , 'x1_16-24' , 'x1_25-34' , 'x1_35-44' , 'x1_45-54' , 'x1_55-64' , 'x1_65-74' , 'x1_75+' , 'x2_Apartment' , 'x2_Other' , 'x2_Villa' , 'x3_Couple' , 'x3_Other' , 'x3_Single' , 'x2_Not Available' ] df , adults = preprocess_household_data ( aligned_columns = aligned_columns , drop = [ 'primary_status' ], onehotencode = True ) # Predict the primary status for each person using the classifier df [ 'primary_status' ] = classifier . predict ( df ) # Add the primary status to each person for i , adult in enumerate ( adults ): numeric_primary_status = df [ 'primary_status' ][ i ] if numeric_primary_status == 1 : adult . primary_status = 'WORK' elif numeric_primary_status == 2 : adult . primary_status = 'EDUCATION' elif numeric_primary_status == 3 : adult . primary_status = 'HOME' else : adult . primary_status = 'NA' workers , students , neither = [], [], [] for person in Person . instances : if person . primary_status == \"WORK\" : workers . append ( person ) elif person . primary_status == \"EDUCATION\" : students . append ( person ) elif person . primary_status == \"HOME\" : neither . append ( person ) logger . info ( f \"Number of workers: { len ( workers ) } - { len ( workers ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of students: { len ( students ) } - { len ( students ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of neither: { len ( neither ) } - { len ( neither ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Total number of persons: { len ( Person . instances ) } \" ) balance_lists ( p1 , p2 ) Balance the lengths of two lists by moving excess individuals to a separate list. This function ensures that the two input lists have the same length by moving excess individuals from the longer list to a separate list of unmatched individuals. Parameters: Name Type Description Default p1 list The first list of individuals. required p2 list The second list of individuals. required Returns: Name Type Description tuple A tuple containing the balanced lists and the list of unmatched individuals. The function performs the following steps: 1. Checks if the lengths of the two lists are equal. 2. If not, calculates the difference in lengths and moves excess individuals to a separate list. 3. Returns the balanced lists and the list of unmatched individuals. Source code in tripsender\\utils.py 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 def balance_lists ( p1 , p2 ): \"\"\" Balance the lengths of two lists by moving excess individuals to a separate list. This function ensures that the two input lists have the same length by moving excess individuals from the longer list to a separate list of unmatched individuals. Args: p1 (list): The first list of individuals. p2 (list): The second list of individuals. Returns: tuple: A tuple containing the balanced lists and the list of unmatched individuals. The function performs the following steps: 1. Checks if the lengths of the two lists are equal. 2. If not, calculates the difference in lengths and moves excess individuals to a separate list. 3. Returns the balanced lists and the list of unmatched individuals. \"\"\" len_p1 , len_p2 = len ( p1 ), len ( p2 ) # Check if the lists are already of equal length if len_p1 == len_p2 : return p1 , p2 , [] # Find the difference in lengths diff = abs ( len_p1 - len_p2 ) # Move individuals to unmatched_individuals until the lengths are equal unmatched_individuals = [] while diff > 0 : if len_p1 > len_p2 : unmatched_individuals . append ( p1 . pop ()) else : unmatched_individuals . append ( p2 . pop ()) diff -= 1 return p1 , p2 , unmatched_individuals calculate_similarity ( query , area ) Calculate the similarity between the query and the area. This function calculates the similarity score between the query string and the area string based on various criteria such as exact match, missing characters, and common characters. Parameters: Name Type Description Default query str The query string. required area str The area string to compare with the query. required Returns: Name Type Description float The similarity score between the query and the area. The function performs the following steps: 1. Checks for an exact match and returns a high similarity score if found. 2. Checks for missing characters and returns a high similarity score if found. 3. Calculates the similarity based on the number of common characters between the query and the area. 4. Returns the similarity score. Source code in tripsender\\utils.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def calculate_similarity ( query , area ): \"\"\" Calculate the similarity between the query and the area. This function calculates the similarity score between the query string and the area string based on various criteria such as exact match, missing characters, and common characters. Args: query (str): The query string. area (str): The area string to compare with the query. Returns: float: The similarity score between the query and the area. The function performs the following steps: 1. Checks for an exact match and returns a high similarity score if found. 2. Checks for missing characters and returns a high similarity score if found. 3. Calculates the similarity based on the number of common characters between the query and the area. 4. Returns the similarity score. \"\"\" query_len = len ( query ) area_len = len ( area ) # Check for exact match if query == area : return 100 # Check for missing characters if query_len + 1 == area_len and area . startswith ( query ): return 90 # Check for misspelled names with 1 missing character if query_len == area_len + 1 and query . startswith ( area ): return 90 # Calculate similarity based on common characters common_chars = set ( query ) . intersection ( area ) similarity = ( len ( common_chars ) / max ( query_len , area_len )) * 100 return similarity cap_cars_per_household ( households , max_cars = 4 ) Cap the number of cars per household to a specified maximum. This function ensures that no household has more than the specified maximum number of cars. If a household has more cars than the specified maximum, the excess cars are removed and the car ownership status of individuals is updated accordingly. Parameters: Name Type Description Default households list The list of Household instances. required max_cars int The maximum number of cars allowed per household. Defaults to 4. 4 Returns: Type Description None The function performs the following steps: 1. Iterates through each household in the list. 2. Checks if the household has more cars than the specified maximum. 3. If so, removes the excess cars and updates the car ownership status of individuals. Source code in tripsender\\utils.py 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 def cap_cars_per_household ( households , max_cars = 4 ): \"\"\" Cap the number of cars per household to a specified maximum. This function ensures that no household has more than the specified maximum number of cars. If a household has more cars than the specified maximum, the excess cars are removed and the car ownership status of individuals is updated accordingly. Args: households (list): The list of Household instances. max_cars (int): The maximum number of cars allowed per household. Defaults to 4. Returns: None The function performs the following steps: 1. Iterates through each household in the list. 2. Checks if the household has more cars than the specified maximum. 3. If so, removes the excess cars and updates the car ownership status of individuals. \"\"\" for household in households : if household . cars > max_cars : excess_cars = household . cars - max_cars household . cars -= excess_cars members_with_cars = [ member for member in household . members if member . has_car ] random . shuffle ( members_with_cars ) for person in members_with_cars [: excess_cars ]: person . has_car = False clear_instances () Clear all instances of Population, Person, House, Household, Building, and ActivitySequence. This function clears all instances of the specified classes to reset the data. It ensures that no residual data remains from previous runs. Returns: Type Description None The function performs the following steps: 1. Clears all instances of the Population class. 2. Clears all instances of the Person class. 3. Clears all instances of the House class. 4. Clears all instances of the Household class. 5. Clears all instances of the Building class. 6. Clears all instances of the ActivitySequence class. Source code in tripsender\\utils.py 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 def clear_instances (): \"\"\" Clear all instances of Population, Person, House, Household, Building, and ActivitySequence. This function clears all instances of the specified classes to reset the data. It ensures that no residual data remains from previous runs. Returns: None The function performs the following steps: 1. Clears all instances of the Population class. 2. Clears all instances of the Person class. 3. Clears all instances of the House class. 4. Clears all instances of the Household class. 5. Clears all instances of the Building class. 6. Clears all instances of the ActivitySequence class. \"\"\" Population . clear_instances () Person . clear_instances () House . clear_instances () Household . clear_instances () Building . clear_instances () ActivitySequence . clear_instances () couples_from_individuals ( p1 , p2 ) Create couples from two lists of individuals and form households. This function matches individuals from two lists (e.g., males and females) to create couples and form households. It balances the lists, matches individuals based on age, and creates Household instances for each couple. Parameters: Name Type Description Default p1 list The first list of individuals (e.g., males). required p2 list The second list of individuals (e.g., females). required Returns: Name Type Description tuple A tuple containing the number of households created and the list of Household instances. The function performs the following steps: 1. Balances the lengths of the two lists. 2. Matches individuals from the two lists based on age and other criteria. 3. Creates Household instances for each matched couple. 4. Returns the number of households created and the list of Household instances. Source code in tripsender\\utils.py 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 def couples_from_individuals ( p1 , p2 ): \"\"\" Create couples from two lists of individuals and form households. This function matches individuals from two lists (e.g., males and females) to create couples and form households. It balances the lists, matches individuals based on age, and creates Household instances for each couple. Args: p1 (list): The first list of individuals (e.g., males). p2 (list): The second list of individuals (e.g., females). Returns: tuple: A tuple containing the number of households created and the list of Household instances. The function performs the following steps: 1. Balances the lengths of the two lists. 2. Matches individuals from the two lists based on age and other criteria. 3. Creates Household instances for each matched couple. 4. Returns the number of households created and the list of Household instances. \"\"\" households = [] #logger.info(f\"There are {len(p1)} males and {len(p2)} females in this group\") # Check the length of the two groups, if they are not equal, move the extra individual into a new group #unmatched_individuals = [] #logger.info(\"Length of partner lists\",len(p1), len(p2)) # P1 and p2 need to be of equal length # if moving extra individual to either p1 or p2 makes them equal, then do that # else move the extra individual to unmatched_individuals until the length of p1 and p2 are equal p1 , p2 , unmatched_individuals = balance_lists ( p1 , p2 ) # Check if unmatched_individuals in empty # if not empty check if it is odd # if odd, create one new person with the same attributes as a random unmatched_individual # and add it to the unmatched_individuals list # Once even, split the list into two and add them to p1 and p2 if unmatched_individuals : if len ( unmatched_individuals ) % 2 == 1 : # pick a random person person = random . choice ( unmatched_individuals ) #get age group of person person_age_group = age_group_from_age ( person . age ) new_person = Person ( person_age_group , person . sex , person . household_type ) # Add the new person to the unmatched_individuals list unmatched_individuals . append ( new_person ) # Split the unmatched_individuals list into two and add them to p1 and p2 p1 . extend ( unmatched_individuals [: len ( unmatched_individuals ) // 2 ]) p2 . extend ( unmatched_individuals [ len ( unmatched_individuals ) // 2 :]) #logger.info(\"Length of partner lists\",len(p1), len(p2)) # sort the two groups by age p1 . sort ( key = lambda x : x . age , reverse = True ) p2 . sort ( key = lambda x : x . age , reverse = True ) # Get the age proxy for group 1 age_proxy_list = [] for person in p1 : # Sample a number from distribution mean = 0 sd = 6 age_proxy = np . random . normal ( 0 , 6 ) + person . age age_proxy_list . append ( age_proxy ) # sort age_proxy_list in descending order and use it to sort p1 p1 = [ x for _ , x in sorted ( zip ( age_proxy_list , p1 ), reverse = True )] # Match individuals in married_individuals_split_1 with individuals in p2 for i , person in enumerate ( p1 ): # assiging household head if person . age > p2 [ i ] . age : person . is_head = True else : p2 [ i ] . is_head = True household = Household ( 'Couple' ) household . add_member ( person ) household . add_member ( p2 [ i ]) # adding household to households households . append ( household ) households_created = len ( p1 ) return households_created , households get_older_child_probability_matrix ( older_children_data ) Calculate the probability matrix for households with older children (aged 25+ years). This function processes the input data to calculate the probability of households having older children. It returns a dictionary with the probability of having older children in different household categories. Parameters: Name Type Description Default older_children_data dict The input data containing information on households with older children. required Returns: Name Type Description dict A dictionary containing the probability matrix for households with older children. The function performs the following steps: 1. Processes the input data to extract household categories and the count of older children. 2. Calculates the total number of households with older children. 3. Calculates the probability of having older children in each household category. 4. Returns the resulting probability matrix. Source code in tripsender\\utils.py 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_older_child_probability_matrix ( older_children_data ): \"\"\" Calculate the probability matrix for households with older children (aged 25+ years). This function processes the input data to calculate the probability of households having older children. It returns a dictionary with the probability of having older children in different household categories. Args: older_children_data (dict): The input data containing information on households with older children. Returns: dict: A dictionary containing the probability matrix for households with older children. The function performs the following steps: 1. Processes the input data to extract household categories and the count of older children. 2. Calculates the total number of households with older children. 3. Calculates the probability of having older children in each household category. 4. Returns the resulting probability matrix. \"\"\" total_older_kids = 0 keys = [] probabilities = [] for household_type in older_children_data [ 'data' ]: key = household_type [ \"key\" ][ 1 ] if \"25\" in key : if \"Ensamst\u00e5ende\" in key : key = \"Single\" elif \"Sammanboende\" in key : key = \"Couple\" elif \"\u00d6vriga\" in key : key = \"Other\" keys . append ( key ) value = int ( household_type [ \"values\" ][ 0 ]) total_older_kids += value probabilities . append ( value ) probabilities = [ value / total_older_kids for value in probabilities ] # create a dict of keys and probabilities return dict ( zip ( keys , probabilities )) get_probability_of_children ( year , area ) Calculate the probability of having children in different household types. This function fetches data on households with children for the specified year and area, processes the data to calculate the probability of having children in different household types, and returns the calculated probabilities. Parameters: Name Type Description Default year int The year for which the data is to be fetched. required area str The geographical area for which the data is to be fetched. required Returns: Name Type Description dict A dictionary containing the probability of having children in each household type. The function performs the following steps: 1. Fetches data on households with children for the specified year and area. 2. Processes the data to calculate the total number of households in each household type. 3. Calculates the probability of having children in each household type based on the fetched data. 4. Returns the calculated probabilities. Source code in tripsender\\utils.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 def get_probability_of_children ( year , area ): \"\"\" Calculate the probability of having children in different household types. This function fetches data on households with children for the specified year and area, processes the data to calculate the probability of having children in different household types, and returns the calculated probabilities. Args: year (int): The year for which the data is to be fetched. area (str): The geographical area for which the data is to be fetched. Returns: dict: A dictionary containing the probability of having children in each household type. The function performs the following steps: 1. Fetches data on households with children for the specified year and area. 2. Processes the data to calculate the total number of households in each household type. 3. Calculates the probability of having children in each household type based on the fetched data. 4. Returns the calculated probabilities. \"\"\" data = fetch_older_children_data ( year , area ) p_children_age = {} for item in data [ \"data\" ]: key = ( item [ \"key\" ][ 1 ] . split ( \" \" )[ 0 ]) nested_key = item [ \"key\" ][ 1 ] . replace ( key , \"\" ) value = item [ \"values\" ][ 0 ] if 'utan barn' in nested_key : nested_key = 'No Kids' elif '0-24' in nested_key : nested_key = 'Kids Under 25' elif '25' in nested_key : nested_key = 'Kids Over 25' if key not in p_children_age : p_children_age [ key ] = {} p_children_age [ key ][ nested_key ] = int ( value ) # Total households in each key total_households = {} for key in p_children_age : total_households [ key ] = sum ( p_children_age [ key ] . values ()) # Replace Ensamst\u00e5ende with Single, Sammanboende with Couple and \u00d6vrigt with Other total_households [ 'Single' ] = total_households . pop ( 'Ensamst\u00e5ende' ) total_households [ 'Couple' ] = total_households . pop ( 'Sammanboende' ) total_households [ 'Other' ] = total_households . pop ( '\u00d6vriga' ) # Create a new dictionary called hasChild with two keys True and False and the values are the number of households hasChild = {} for key in p_children_age : hasChild [ key ] = {} hasChild [ key ][ True ] = p_children_age [ key ][ 'Kids Under 25' ] + p_children_age [ key ][ 'Kids Over 25' ] hasChild [ key ][ False ] = p_children_age [ key ][ 'No Kids' ] # Replace Ensamst\u00e5ende with Single, Sammanboende with Couple and \u00d6vrigt with Other hasChild [ 'Single' ] = hasChild . pop ( 'Ensamst\u00e5ende' ) hasChild [ 'Couple' ] = hasChild . pop ( 'Sammanboende' ) hasChild [ 'Other' ] = hasChild . pop ( '\u00d6vriga' ) # Calculate the probability of having children in each household type p_children = {} for key in hasChild : p_children [ key ] = {} p_children [ key ][ True ] = hasChild [ key ][ True ] / total_households [ key ] p_children [ key ][ False ] = hasChild [ key ][ False ] / total_households [ key ] return p_children get_probability_of_housetype ( year , area ) Calculate the probability of different household types in a given area. This function fetches data on household types for the specified year and area, processes the data to calculate the probability of each household type, and returns the calculated probabilities. Parameters: Name Type Description Default year int The year for which the data is to be fetched. required area str The geographical area for which the data is to be fetched. required Returns: Name Type Description dict A dictionary containing the probability of each household type in the area. The function performs the following steps: 1. Fetches data on household types for the specified year and area. 2. Processes the data to map household types to simplified categories. 3. Calculates the total number of households in each category. 4. Calculates the percentage of each household type based on the fetched data. 5. Returns the calculated probabilities. Source code in tripsender\\utils.py 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_probability_of_housetype ( year , area ): \"\"\" Calculate the probability of different household types in a given area. This function fetches data on household types for the specified year and area, processes the data to calculate the probability of each household type, and returns the calculated probabilities. Args: year (int): The year for which the data is to be fetched. area (str): The geographical area for which the data is to be fetched. Returns: dict: A dictionary containing the probability of each household type in the area. The function performs the following steps: 1. Fetches data on household types for the specified year and area. 2. Processes the data to map household types to simplified categories. 3. Calculates the total number of households in each category. 4. Calculates the percentage of each household type based on the fetched data. 5. Returns the calculated probabilities. \"\"\" # Fetch the data data = fetch_housetype_data ( year , area ) # Create a dictionary with the probability of each household type p_housetype = {} for item in data [ \"data\" ]: key = ( item [ \"key\" ][ 1 ]) nested_key = ( item [ \"key\" ][ 2 ]) value = item [ \"values\" ][ 0 ] if \"Sm\u00e5hus\" in nested_key : nested_key = \"Villa\" elif \"Flerbostadshus\" in nested_key : nested_key = \"Apartment\" elif \"Specialbostad, \u00f6vriga hus\" in nested_key : nested_key = \"Other\" else : nested_key = \"Not Available\" if key not in p_housetype : p_housetype [ key ] = {} p_housetype [ key ][ nested_key ] = int ( value ) # Total households in each key total_households = {} for key in p_housetype : total_households [ key ] = sum ( p_housetype [ key ] . values ()) # Calculate the percentage of each household type p_housetype_percentage = {} for key in p_housetype : p_housetype_percentage [ key ] = {} for nested_key in p_housetype [ key ]: # Take care of divbyzero error if total_households [ key ] == 0 : p_housetype_percentage [ key ][ nested_key ] = 0 else : p_housetype_percentage [ key ][ nested_key ] = p_housetype [ key ][ nested_key ] / total_households [ key ] return p_housetype_percentage get_younger_child_probability_matrix ( data ) Calculate the probability matrix for the number of younger children in households. This function processes the input data to calculate the probability of having a certain number of younger children in different household categories. It returns the resulting probability matrix. Parameters: Name Type Description Default data dict The input data containing household information. required Returns: Name Type Description dict A dictionary containing the probability matrix for the number of younger children in households. The function performs the following steps: 1. Renames household types in the input data to simplified categories. 2. Merges data for similar household types. 3. Creates a nested dictionary with the count of younger children for each household category. 4. Calculates the probability of having a certain number of younger children in each household category. 5. Returns the resulting probability matrix. Source code in tripsender\\utils.py 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 def get_younger_child_probability_matrix ( data ): \"\"\" Calculate the probability matrix for the number of younger children in households. This function processes the input data to calculate the probability of having a certain number of younger children in different household categories. It returns the resulting probability matrix. Args: data (dict): The input data containing household information. Returns: dict: A dictionary containing the probability matrix for the number of younger children in households. The function performs the following steps: 1. Renames household types in the input data to simplified categories. 2. Merges data for similar household types. 3. Creates a nested dictionary with the count of younger children for each household category. 4. Calculates the probability of having a certain number of younger children in each household category. 5. Returns the resulting probability matrix. \"\"\" # Step 1: Rename household types # Create a dictionary to map the original household types to their replacements household_types = { 'Ensamst\u00e5ende' : 'Single' , 'Sammanboende' : 'Couple' , '\u00d6vriga hush\u00e5ll' : 'Couple' , 'Uppgift saknas' : 'Other' } # Iterate through each entry in the data for entry in data [ 'data' ]: household_type = entry [ 'key' ][ 1 ] # Get the household type from the entry # Replace the household type with its corresponding replacement if it exists in the dictionary entry [ 'key' ][ 1 ] = household_types . get ( household_type , household_type ) # Step 2: Merge couple households # Initialize an empty dictionary to store the merged data merged_data = {} # Iterate through each entry in the data for entry in data [ 'data' ]: key = tuple ( entry [ 'key' ][ 1 : - 1 ]) # Extract the key by excluding the area and year value = int ( entry [ 'values' ][ 0 ]) # Convert the value to an integer merged_data [ key ] = merged_data . get ( key , 0 ) + value # Add the value to the existing value for the corresponding key, or initialize it to 0 if the key doesn't exist # Step 2.1 Nest data # Initialize an empty dictionary to store the nested data probability_matrix = {} # Iterate through each (category, children) pair and its corresponding value in the merged data for ( category , children ), value in merged_data . items (): # Create a nested dictionary if the category doesn't exist in the probability matrix probability_matrix . setdefault ( category , {})[ children ] = value # Add the value to the corresponding children key in the category dictionary # Step 3: Find totals per children number # Iterate through each household type in the probability matrix for household_type in probability_matrix : # Calculate the total value by summing the values for all children numbers in the household type dictionary total = sum ( probability_matrix [ household_type ] . values ()) # Replace the values in the household type dictionary with their respective probabilities probability_matrix [ household_type ] = { children : value / total if total != 0 else 0 for children , value in probability_matrix [ household_type ] . items () # Divide each value by the total, accounting for the possibility of zero division } # Return the resulting probability matrix return probability_matrix impute_municipal_children_count ( year , area ) Impute the count of children in households within a municipality based on provided data. This function fetches municipal children data for the specified year and area, processes the data to impute the count of children in different household categories, and returns the imputed data as dictionaries for households with children aged 0-24 years and 25 years or older. Parameters: Name Type Description Default year int The year for which the data is to be fetched. required area str The geographical area for which the data is to be fetched. required Returns: Name Type Description tuple Two dictionaries containing imputed children counts for households with children aged 0-24 years and 25 years or older. The function performs the following steps: 1. Fetches municipal children data for the specified year and area. 2. Processes the data to create a nested dictionary with children counts for different household categories. 3. Transforms the data to calculate the probability of having a certain number of children in each household category. 4. Separates the data into two dictionaries based on the age of children (0-24 years and 25 years or older). 5. Returns the two dictionaries with imputed children counts. Source code in tripsender\\utils.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def impute_municipal_children_count ( year , area ): \"\"\" Impute the count of children in households within a municipality based on provided data. This function fetches municipal children data for the specified year and area, processes the data to impute the count of children in different household categories, and returns the imputed data as dictionaries for households with children aged 0-24 years and 25 years or older. Args: year (int): The year for which the data is to be fetched. area (str): The geographical area for which the data is to be fetched. Returns: tuple: Two dictionaries containing imputed children counts for households with children aged 0-24 years and 25 years or older. The function performs the following steps: 1. Fetches municipal children data for the specified year and area. 2. Processes the data to create a nested dictionary with children counts for different household categories. 3. Transforms the data to calculate the probability of having a certain number of children in each household category. 4. Separates the data into two dictionaries based on the age of children (0-24 years and 25 years or older). 5. Returns the two dictionaries with imputed children counts. \"\"\" data = fetch_municipal_children_data ( year ) # Extract the relevant data from the JSON nested_dict = {} total_households = [] for hh in data [ \"data\" ]: key = hh [ \"key\" ][ 1 ] nested_key = hh [ \"key\" ][ 2 ] value = int ( hh [ \"values\" ][ 0 ]) #total_households.append(value) if key not in nested_dict : nested_dict [ key ] = {} nested_dict [ key ][ nested_key ] = value if 'SAKNAS' in nested_dict : del nested_dict [ 'SAKNAS' ] # Calculate the total number of households in the municipality for key in nested_dict : total_households . append ( sum ( nested_dict [ key ] . values ())) # Get probability of number of children in each household category #for i,key in enumerate(nested_dict): # for nested_key in nested_dict[key]: # nested_dict[key][nested_key] = nested_dict[key][nested_key]/total_households[i] # Creating a dictionary for name changes name_change = { 'ESUB' : 'Ensamst\u00e5ende utan barn' , 'ESMB24' : 'Ensamst\u00e5ende med barn 0-24 \u00e5r' , 'ESMB25' : 'Ensamst\u00e5ende med barn 25 \u00e5r eller \u00e4ldre' , 'SMUB' : 'Sammanboende utan barn' , 'SBMB24' : 'Sammanboende med barn 0-24 \u00e5r' , 'SBMB25' : 'Sammanboende med barn 25 \u00e5r eller \u00e4ldre' , 'OVRIUB' : '\u00d6vriga hush\u00e5ll utan barn' , '\u00d6MB24' : '\u00d6vriga hush\u00e5ll med barn 0-24 \u00e5r' , '\u00d6MB25' : '\u00d6vriga hush\u00e5ll med barn 25 \u00e5r eller \u00e4ldre' } # If a key is found in the name_change dictionary, replace the key with the value municipal_children = {} for old_key , value in nested_dict . items (): new_key = name_change . get ( old_key , old_key ) municipal_children [ new_key ] = value # Remove keys with utan barn municipal_children = { k : v for k , v in municipal_children . items () if 'utan barn' not in k } # Replace UB with 0, M1B with 1, M2B with 2, M3+B with 3 for key , value in municipal_children . items (): key_list = list ( value . keys ()) # Check if any ['UB','M1B', 'M2B','M3+B','SAKNAS'] in key_list if any ( x in key_list for x in [ 'UB' , 'M1B' , 'M2B' , 'M3+B' , 'SAKNAS' ]): municipal_children [ key ][ 0 ] = municipal_children [ key ] . pop ( 'UB' ) municipal_children [ key ][ 1 ] = municipal_children [ key ] . pop ( 'M1B' ) municipal_children [ key ][ 2 ] = municipal_children [ key ] . pop ( 'M2B' ) municipal_children [ key ][ 3 ] = municipal_children [ key ] . pop ( 'M3+B' ) municipal_children [ key ][ 'other' ] = municipal_children [ key ] . pop ( 'SAKNAS' ) # Create two dicts from municipal_children dict, one for 0-24 years and one for 25+ years municipal_children_0_24 = { k : v for k , v in municipal_children . items () if '0-24' in k } municipal_children_25 = { k : v for k , v in municipal_children . items () if '25' in k } # split key and replace with first word municipal_children_0_24 = { k . split ()[ 0 ]: v for k , v in municipal_children_0_24 . items ()} municipal_children_25 = { k . split ()[ 0 ]: v for k , v in municipal_children_25 . items ()} # Replace ensamst\u00e5ende with single, sammanboende with couple and \u00f6vriga hush\u00e5ll with other municipal_children_0_24 = { k . replace ( 'Ensamst\u00e5ende' , 'Single' ) . replace ( 'Sammanboende' , 'Couple' ) . replace ( '\u00d6vriga' , 'Other' ): v for k , v in municipal_children_0_24 . items ()} municipal_children_25 = { k . replace ( 'Ensamst\u00e5ende' , 'Single' ) . replace ( 'Sammanboende' , 'Couple' ) . replace ( '\u00d6vriga' , 'Other' ): v for k , v in municipal_children_25 . items ()} # Calculate total households 0-24 and 25+ total_households_0_24 = [] total_households_25 = [] for key in municipal_children_0_24 : total_households_0_24 . append ( sum ( municipal_children_0_24 [ key ] . values ())) for key in municipal_children_25 : total_households_25 . append ( sum ( municipal_children_25 [ key ] . values ())) # Calculate the probability of number of children in each household category municipal_children_0_24 for i , key in enumerate ( municipal_children_0_24 ): for hh in municipal_children_0_24 [ key ]: municipal_children_0_24 [ key ][ hh ] = municipal_children_0_24 [ key ][ hh ] / total_households_0_24 [ i ] for i , key in enumerate ( municipal_children_25 ): for hh in municipal_children_25 [ key ]: municipal_children_25 [ key ][ hh ] = municipal_children_25 [ key ][ hh ] / total_households_25 [ i ] return municipal_children_0_24 , municipal_children_25 match_child_to_parent ( parent , list_of_children , min_age_of_parent = 20 , initial_tolerance = 5 , max_tolerance = 20 , tolerance_increment = 2 ) Match a child to a parent based on age and add the child to the parent's household. This function matches a child to a parent from the list of children based on the age difference between the parent and the child. It uses a tolerance range to find a suitable match and adds the matched child to the parent's household. Parameters: Name Type Description Default parent Person The parent individual. required list_of_children list The list of child individuals to match. required min_age_of_parent int The minimum age for a parent. Defaults to 20. 20 initial_tolerance int The initial tolerance range for matching. Defaults to 5. 5 max_tolerance int The maximum tolerance range for matching. Defaults to 20. 20 tolerance_increment int The increment in tolerance range for each iteration. Defaults to 2. 2 Returns: Type Description None The function performs the following steps: 1. Calculates the proxy age of the child based on the parent's age and minimum age of parent. 2. Iterates through the list of children to find a match within the initial tolerance range. 3. If no match is found, increases the tolerance range and retries until the maximum tolerance is reached. 4. Adds the matched child to the parent's household and removes the child from the list of children. 5. Logs the matching process and results. Source code in tripsender\\utils.py 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 def match_child_to_parent ( parent , list_of_children , min_age_of_parent = 20 , initial_tolerance = 5 , max_tolerance = 20 , tolerance_increment = 2 ): \"\"\" Match a child to a parent based on age and add the child to the parent's household. This function matches a child to a parent from the list of children based on the age difference between the parent and the child. It uses a tolerance range to find a suitable match and adds the matched child to the parent's household. Args: parent (Person): The parent individual. list_of_children (list): The list of child individuals to match. min_age_of_parent (int, optional): The minimum age for a parent. Defaults to 20. initial_tolerance (int, optional): The initial tolerance range for matching. Defaults to 5. max_tolerance (int, optional): The maximum tolerance range for matching. Defaults to 20. tolerance_increment (int, optional): The increment in tolerance range for each iteration. Defaults to 2. Returns: None The function performs the following steps: 1. Calculates the proxy age of the child based on the parent's age and minimum age of parent. 2. Iterates through the list of children to find a match within the initial tolerance range. 3. If no match is found, increases the tolerance range and retries until the maximum tolerance is reached. 4. Adds the matched child to the parent's household and removes the child from the list of children. 5. Logs the matching process and results. \"\"\" # Age difference heuristic based on the parent's age proxy_age_of_child = parent . age - min_age_of_parent #logger.info(f\"match_child_to_parent: Parent Age: {parent.age}. Calculated Proxy Age of Child: {proxy_age_of_child}.\") tolerance = initial_tolerance children_to_remove = [] while tolerance <= max_tolerance and not children_to_remove : #logger.info(f\"match_child_to_parent: Checking with tolerance: {tolerance} years\") # Get potential matches based on current tolerance potential_matches = [ child for child in list_of_children if abs ( child . age - proxy_age_of_child ) < tolerance ] # If there are potential matches, sort them by age (older children first) potential_matches . sort ( key = lambda x : x . age , reverse = True ) if potential_matches : # Pick the oldest child from potential matches chosen_child = potential_matches [ 0 ] #logger.info(f\"match_child_to_parent: Matched child {chosen_child.age} to parent {parent.age} with tolerance {tolerance} years.\") parent . household . add_child ( chosen_child ) logger . info ( f \"Matched child (age: { chosen_child . age } ) to household with parent (age: { parent . age } )\" ) children_to_remove . append ( chosen_child ) else : tolerance += tolerance_increment #logger.info(f\"match_child_to_parent: No suitable children found for parent {parent.age} of {parent.household_type} with current tolerance. Increasing tolerance.\") # Remove matched children from the list for child in children_to_remove : list_of_children . remove ( child ) if not children_to_remove : logger . info ( f \"match_child_to_parent: No suitable children found for parent { parent . age } of { parent . household_type } even with max tolerance of { max_tolerance } years.\" ) match_list_household_children ( list_household , list_children ) Match children to households based on the number of children needed. This function matches children to households based on the number of children each household needs. It expands the household list based on the number of children required and pairs each child with a household. Parameters: Name Type Description Default list_household list The list of households. required list_children list The list of children to be matched. required Returns: Type Description None The function performs the following steps: 1. Expands the household list based on the number of children needed in each household. 2. Sorts the household list based on the age of a randomly chosen parent. 3. Sorts the children list by age. 4. Pairs each child with a household and adds the child to the household. 5. Logs the matching process and results. Source code in tripsender\\utils.py 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 def match_list_household_children ( list_household , list_children ): \"\"\" Match children to households based on the number of children needed. This function matches children to households based on the number of children each household needs. It expands the household list based on the number of children required and pairs each child with a household. Args: list_household (list): The list of households. list_children (list): The list of children to be matched. Returns: None The function performs the following steps: 1. Expands the household list based on the number of children needed in each household. 2. Sorts the household list based on the age of a randomly chosen parent. 3. Sorts the children list by age. 4. Pairs each child with a household and adds the child to the household. 5. Logs the matching process and results. \"\"\" new_list_household = [] # Expand household list based on the number of children in each household for household in list_household : stack_number = household . children temp_household_stack = [ household for _ in range ( stack_number )] new_list_household . extend ( temp_household_stack ) # Sort the household list based on the age of a randomly chosen parent (from oldest to youngest) #new_list_household.sort(key=lambda household: random.choice([member.age for member in household.members if not member.is_child])) # Sort the children list by age (oldest first) list_children . sort ( key = lambda child : child . age , reverse = True ) # Pair each child with a household for child in list_children : household = new_list_household . pop () parents = [ member for member in household . members if not member . is_child ] parent = random . choice ( parents ) #logger.info(f\"Matched child (age: {child.age}) to household with parent (age: {parent.age})\") household . add_child ( child ) parse_num_children ( data ) Parse the number of children from a string. This function extracts the number of children from the given data string using regular expressions. Parameters: Name Type Description Default data str The input string containing the number of children. required Returns: Name Type Description int The number of children extracted from the input string. Returns 0 if no number is found. Example parse_num_children(\"3 children\") 3 Source code in tripsender\\utils.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 def parse_num_children ( data ): \"\"\" Parse the number of children from a string. This function extracts the number of children from the given data string using regular expressions. Args: data (str): The input string containing the number of children. Returns: int: The number of children extracted from the input string. Returns 0 if no number is found. Example: >>> parse_num_children(\"3 children\") 3 \"\"\" return int ( re . search ( r '\\d+' , data ) . group ()) if re . search ( r '\\d+' , data ) else 0 preprocess_household_data ( aligned_columns = [], drop = [], onehotencode = False ) Preprocess household data for model input. This function preprocesses household data by ensuring all required columns are present, dropping specified columns, and optionally one-hot encoding categorical variables. Parameters: Name Type Description Default aligned_columns list List of columns to ensure are present in the DataFrame. [] drop list List of columns to drop from the DataFrame. [] onehotencode bool Whether to one-hot encode categorical variables. Defaults to False. False Returns: Name Type Description tuple A tuple containing the preprocessed DataFrame and the list of adult individuals. The function performs the following steps: 1. Fetches household data and adult individuals. 2. Ensures all specified columns are present in the DataFrame. 3. Drops specified columns from the DataFrame. 4. Optionally one-hot encodes categorical variables. 5. Returns the preprocessed DataFrame and the list of adult individuals. Source code in tripsender\\utils.py 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 def preprocess_household_data ( aligned_columns = [], drop = [], onehotencode = False ): \"\"\" Preprocess household data for model input. This function preprocesses household data by ensuring all required columns are present, dropping specified columns, and optionally one-hot encoding categorical variables. Args: aligned_columns (list): List of columns to ensure are present in the DataFrame. drop (list): List of columns to drop from the DataFrame. onehotencode (bool): Whether to one-hot encode categorical variables. Defaults to False. Returns: tuple: A tuple containing the preprocessed DataFrame and the list of adult individuals. The function performs the following steps: 1. Fetches household data and adult individuals. 2. Ensures all specified columns are present in the DataFrame. 3. Drops specified columns from the DataFrame. 4. Optionally one-hot encodes categorical variables. 5. Returns the preprocessed DataFrame and the list of adult individuals. \"\"\" df , adults = Household . return_nhts ( drop = drop , onehotencode = onehotencode ) # Ensure all columns in aligned_columns are present in the DataFrame for column in aligned_columns : if column not in df . columns : df [ column ] = 0 df = df [ aligned_columns ] return df , adults sample_children_category ( probability_matrix , household_type ) Sample a children category based on the probability matrix for the given household type. This function uses the provided probability matrix to randomly sample a children category for the specified household type. Parameters: Name Type Description Default probability_matrix dict The probability matrix for children categories. required household_type str The household type for which to sample a children category. required Returns: Name Type Description int The sampled children category. Returns None if the household type is not found in the probability matrix. The function performs the following steps: 1. Checks if the household type exists in the probability matrix. 2. Extracts children categories and their corresponding probabilities from the probability matrix. 3. Randomly samples a children category based on the extracted probabilities. 4. Returns the sampled children category. Source code in tripsender\\utils.py 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 def sample_children_category ( probability_matrix , household_type ): \"\"\" Sample a children category based on the probability matrix for the given household type. This function uses the provided probability matrix to randomly sample a children category for the specified household type. Args: probability_matrix (dict): The probability matrix for children categories. household_type (str): The household type for which to sample a children category. Returns: int: The sampled children category. Returns None if the household type is not found in the probability matrix. The function performs the following steps: 1. Checks if the household type exists in the probability matrix. 2. Extracts children categories and their corresponding probabilities from the probability matrix. 3. Randomly samples a children category based on the extracted probabilities. 4. Returns the sampled children category. \"\"\" if household_type in probability_matrix : children_categories = list ( probability_matrix [ household_type ] . keys ()) probabilities = list ( probability_matrix [ household_type ] . values ()) # Sample a children category based on the probabilities sampled_category = random . choices ( children_categories , probabilities )[ 0 ] return ( sampled_category ) else : return ( None ) sample_household_for_older_child ( probability_matrix ) Sample a household type based on the probability matrix for older children. This function uses the provided probability matrix to randomly sample a household type that is likely to have older children. Parameters: Name Type Description Default probability_matrix dict The probability matrix for households with older children. required Returns: Name Type Description str The sampled household type. The function performs the following steps: 1. Extracts household categories and their corresponding probabilities from the probability matrix. 2. Randomly samples a household type based on the extracted probabilities. 3. Returns the sampled household type. Source code in tripsender\\utils.py 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def sample_household_for_older_child ( probability_matrix ): \"\"\" Sample a household type based on the probability matrix for older children. This function uses the provided probability matrix to randomly sample a household type that is likely to have older children. Args: probability_matrix (dict): The probability matrix for households with older children. Returns: str: The sampled household type. The function performs the following steps: 1. Extracts household categories and their corresponding probabilities from the probability matrix. 2. Randomly samples a household type based on the extracted probabilities. 3. Returns the sampled household type. \"\"\" # Sample a household type based on the probabilities household_categories = list ( probability_matrix . keys ()) probabilities = list ( probability_matrix . values ()) sampled_household_type = random . choices ( household_categories , probabilities )[ 0 ] return ( sampled_household_type ) search_primary_area ( query , df = pd . read_csv ( PATH_PRIMARY_AREA )) Search for the best matching primary area from the DataFrame based on the query. This function takes a query string and searches for the best matching primary area from the given DataFrame. It calculates the similarity between the query and each primary area in the DataFrame, and returns the best match. Parameters: Name Type Description Default query str The query string to search for. required df DataFrame The DataFrame containing primary areas. Defaults to reading from PATH_PRIMARY_AREA. read_csv ( PATH_PRIMARY_AREA ) Returns: Name Type Description str The best matching primary area. The function performs the following steps: 1. Converts the query to lowercase for case-insensitive comparison. 2. Iterates through each primary area in the DataFrame, converting it to lowercase. 3. Calculates the similarity between the query and the current primary area. 4. Updates the best match if the current primary area has a higher similarity score. 5. Returns the best matching primary area. Source code in tripsender\\utils.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def search_primary_area ( query , df = pd . read_csv ( PATH_PRIMARY_AREA )): \"\"\" Search for the best matching primary area from the DataFrame based on the query. This function takes a query string and searches for the best matching primary area from the given DataFrame. It calculates the similarity between the query and each primary area in the DataFrame, and returns the best match. Args: query (str): The query string to search for. df (pd.DataFrame): The DataFrame containing primary areas. Defaults to reading from PATH_PRIMARY_AREA. Returns: str: The best matching primary area. The function performs the following steps: 1. Converts the query to lowercase for case-insensitive comparison. 2. Iterates through each primary area in the DataFrame, converting it to lowercase. 3. Calculates the similarity between the query and the current primary area. 4. Updates the best match if the current primary area has a higher similarity score. 5. Returns the best matching primary area. \"\"\" query = query . lower () # Convert query to lowercase best_match = None best_similarity = 0 for area in df [ 'primary_area' ]: area_lower = area . lower () # Convert area to lowercase similarity = calculate_similarity ( query , area_lower ) # Calculate similarity # Update the best match if the current area has higher similarity if similarity > best_similarity : best_similarity = similarity best_match = area return best_match split_households_by_householdtype () Split individuals into different lists based on their household type. This function splits individuals into different lists based on their household type, such as children, single parents, living alone, married, cohabiting, and others. Returns: Name Type Description tuple A tuple containing lists of individuals for each household type. The function performs the following steps: 1. Iterates through each individual and categorizes them based on their household type. 2. Adds the individuals to the corresponding list for their household type. 3. Logs the number of individuals in each household type. 4. Returns the lists of individuals for each household type. Source code in tripsender\\utils.py 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 def split_households_by_householdtype (): \"\"\" Split individuals into different lists based on their household type. This function splits individuals into different lists based on their household type, such as children, single parents, living alone, married, cohabiting, and others. Returns: tuple: A tuple containing lists of individuals for each household type. The function performs the following steps: 1. Iterates through each individual and categorizes them based on their household type. 2. Adds the individuals to the corresponding list for their household type. 3. Logs the number of individuals in each household type. 4. Returns the lists of individuals for each household type. \"\"\" # Create a list of households children = [] single_parents = [] living_alone = [] married_males = [] married_females = [] cohabiting_males = [] cohabiting_females = [] others = [] # Separate individuals into different lists based on their category for person in Person . instances : if person . household_type == CHILD : # Child person . is_child = True children . append ( person ) elif person . household_type == SINGLE_PARENT : # Single parent #person.hasChild = True single_parents . append ( person ) elif person . household_type == LIVING_ALONE : # Living alone living_alone . append ( person ) elif person . household_type == MARRIED : # Married if person . sex == MALE : married_males . append ( person ) else : married_females . append ( person ) elif person . household_type == COHABITING : # Cohabiting if person . sex == MALE : cohabiting_males . append ( person ) else : cohabiting_females . append ( person ) else : others . append ( person ) # Not living alone/ other # Print the number of individuals in each category logger . info ( f \"Number of children: { len ( children ) } \" ) logger . info ( f \"Number of single parents: { len ( single_parents ) } \" ) logger . info ( f \"Number of individuals living alone: { len ( living_alone ) } \" ) logger . info ( f \"Number of married males: { len ( married_males ) } \" ) logger . info ( f \"Number of married females: { len ( married_females ) } \" ) logger . info ( f \"Number of cohabiting males: { len ( cohabiting_males ) } \" ) logger . info ( f \"Number of cohabiting females: { len ( cohabiting_females ) } \" ) logger . info ( f \"Number of others: { len ( others ) } \" ) return children , single_parents , living_alone , married_males , married_females , cohabiting_males , cohabiting_females , others","title":"utils"},{"location":"utils/#tripsender.utils.assign_cars_to_households","text":"Assign car ownership to households based on a classifier model. This function assigns car ownership to households in the specified year and area using a pre-trained classifier model. It predicts the probability of car ownership for each household and assigns cars based on the top predictions. Parameters: Name Type Description Default year int The year for which to assign car ownership. required area str The geographical area for which to assign car ownership. required classifier object The pre-trained classifier model for predicting car ownership. required Returns: Type Description None The function performs the following steps: 1. Fetches car ownership data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of car ownership for each household. 4. Assigns car ownership based on the top predictions. 5. Caps the number of cars per household to a specified maximum. 6. Logs the total number of cars after capping. Source code in tripsender\\utils.py 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 def assign_cars_to_households ( year , area , classifier ): \"\"\" Assign car ownership to households based on a classifier model. This function assigns car ownership to households in the specified year and area using a pre-trained classifier model. It predicts the probability of car ownership for each household and assigns cars based on the top predictions. Args: year (int): The year for which to assign car ownership. area (str): The geographical area for which to assign car ownership. classifier (object): The pre-trained classifier model for predicting car ownership. Returns: None The function performs the following steps: 1. Fetches car ownership data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of car ownership for each household. 4. Assigns car ownership based on the top predictions. 5. Caps the number of cars per household to a specified maximum. 6. Logs the total number of cars after capping. \"\"\" # Provide the estimated total cars and call the function to scale and optionally plot the results car_data = fetch_car_data ( year , area ) estimated_total_cars = int ( car_data [ \"data\" ][ 0 ][ \"values\" ][ 0 ]) logger . info ( f \"Total estimated cars in neighborhood: { estimated_total_cars } \" ) aligned_columns = [ 'child_count' , 'adult_count' , 'x0_Kvinnor' , 'x0_M\u00e4n' , 'x0_Other' , 'x1_16-24' , 'x1_25-34' , 'x1_35-44' , 'x1_45-54' , 'x1_55-64' , 'x1_65-74' , 'x1_75+' , 'x2_Apartment' , 'x2_Other' , 'x2_Villa' , 'x3_Couple' , 'x3_Other' , 'x3_Single' , 'x2_Not Available' ] df , adults = preprocess_household_data ( aligned_columns = aligned_columns , drop = [ 'car_count' , 'primary_status' ], onehotencode = True ) # Predict probabilities using the classifier probs = classifier . predict_proba ( df )[:, 1 ] # Assign car_count based on the top estimated_total_cars predictions top_indices = ( - probs ) . argsort ()[: estimated_total_cars ] df [ 'car_count' ] = 0 df . loc [ top_indices , 'car_count' ] = 1 # Assign cars to individuals and calculate household cars for i , person in enumerate ( adults ): person . has_car = df [ 'car_count' ][ i ] for household in Household . instances : household . cars = sum ( person . has_car for person in household . members ) # Cap the number of cars per household to a maximum of 3 cap_cars_per_household ( Household . instances ) total_cars_after_capping = sum ( household . cars for household in Household . instances ) logger . info ( f \"Total cars in neighborhood after capping to 4: { total_cars_after_capping } \" )","title":"assign_cars_to_households"},{"location":"utils/#tripsender.utils.assign_children_to_households","text":"Assign children to households based on age and probability data. This function assigns children to households for the specified year and area using probability data and age-based categorization. It splits households into different categories based on the age of the head and assigns children accordingly. Parameters: Name Type Description Default year int The year for which to assign children. required area str The geographical area for which to assign children. required children list The list of children to be assigned. required age_split int The age threshold to categorize households. required min_age_of_parent int The minimum age for a parent. Defaults to 25. 25 Returns: Type Description None The function performs the following steps: 1. Determines if a household has children based on probability data. 2. Splits households into different categories based on the age of the head. 3. Assigns the number of children to each household based on the probability matrix. 4. Randomly adjusts the number of children in households to match the total number of children. 5. Matches children to households based on the number of children needed. 6. Updates the has_child attribute for each person in the household. 7. Logs the assignment process and results. Source code in tripsender\\utils.py 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 def assign_children_to_households ( year , area , children , age_split , min_age_of_parent = 25 ): \"\"\" Assign children to households based on age and probability data. This function assigns children to households for the specified year and area using probability data and age-based categorization. It splits households into different categories based on the age of the head and assigns children accordingly. Args: year (int): The year for which to assign children. area (str): The geographical area for which to assign children. children (list): The list of children to be assigned. age_split (int): The age threshold to categorize households. min_age_of_parent (int, optional): The minimum age for a parent. Defaults to 25. Returns: None The function performs the following steps: 1. Determines if a household has children based on probability data. 2. Splits households into different categories based on the age of the head. 3. Assigns the number of children to each household based on the probability matrix. 4. Randomly adjusts the number of children in households to match the total number of children. 5. Matches children to households based on the number of children needed. 6. Updates the has_child attribute for each person in the household. 7. Logs the assignment process and results. \"\"\" # Step 1 - Determine if a household has children households = Household . instances households . sort ( key = lambda household : random . choice ([ member . age for member in household . members if not member . is_child ])) # Get probability of having children p_children = get_probability_of_children ( year , area ) # Given the household type, calculate the probability of having children in household.has_children for household in households : category = household . category # Single parent households are assumed to have children already if category == 'Couple' : household . has_children = np . random . choice ([ True , False ], p = [ p_children [ 'Couple' ][ True ], p_children [ 'Couple' ][ False ]]) elif category == 'Other' : household . has_children = np . random . choice ([ True , False ], p = [ p_children [ 'Other' ][ True ], p_children [ 'Other' ][ False ]]) # Step 2 - Determine the age at which a person had their first child 25 years ago # Filter households that have children and are either Couple or Other households_with_children = [ household for household in households if household . has_children and household . category in [ 'Single' , 'Couple' , 'Other' ]] # Split households based on the age of the head # These will get older children above 45 households_with_children_above_age_split = [ household for household in households_with_children if household . members [ 0 ] . age > age_split ] # These will get younger children below 45 households_with_children_below_age_split = [ household for household in households_with_children if household . members [ 0 ] . age <= age_split ] # Get the probability matrix for the number of children in each household category p_matrix_0_24 , p_matrix_25 = impute_municipal_children_count ( year , area ) # Step 3 - Assign number of children to households with children for household in households_with_children_below_age_split : # Get household category category = household . category # Get the probability matrix for the household category if category == 'Single' : p_matrix = p_matrix_0_24 [ 'Single' ] elif category == 'Couple' : p_matrix = p_matrix_0_24 [ 'Couple' ] elif category == 'Other' : p_matrix = p_matrix_0_24 [ 'Other' ] # Sample from p_matrix household . children = np . random . choice ([ 1 , 2 , 3 ], p = [ p_matrix [ 1 ], p_matrix [ 2 ], p_matrix [ 3 ]]) # Repeat for households with children and age of head above 50 for household in households_with_children_above_age_split : # Get household category category = household . category # Get the probability matrix for the household category if category == 'Single' : p_matrix = p_matrix_25 [ 'Single' ] if category == 'Couple' : p_matrix = p_matrix_25 [ 'Couple' ] elif category == 'Other' : p_matrix = p_matrix_25 [ 'Other' ] # Sample from p_matrix household . children = np . random . choice ([ 1 , 2 , 3 ], p = [ p_matrix [ 1 ], p_matrix [ 2 ], p_matrix [ 3 ]]) # log number of children in households_with_children total_children_in_households = sum ( household . children for household in households_with_children ) # Randomly increase household.children to households with children < 3 until len(children) == total_children_in_households while len ( children ) > total_children_in_households : # Optionally shuffle the households to randomize which ones get extra children random . shuffle ( households_with_children ) increased = False # Flag to check if any household's child count was increased in this iteration for household in households_with_children : if household . children < 3 : household . children += 1 total_children_in_households += 1 increased = True if total_children_in_households == len ( children ): break # If no household's child count was increased in this iteration, break out of the loop to prevent infinite looping if not increased : break logger . info ( f \"Total number of children to be assigned: { total_children_in_households } \" ) logger . info ( f \"Total number of children: { len ( children ) } \" ) match_list_household_children ( households_with_children , children ) # Update has_child attribute for each person in the household based on the number of children in the household for household in households : household . update_has_child ()","title":"assign_children_to_households"},{"location":"utils/#tripsender.utils.assign_house_type_to_households","text":"Assign house types to households based on probability data (improved method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an improved method that accounts for varying household sizes and assigns house types accordingly. Parameters: Name Type Description Default year int The year for which to assign house types. required area str The geographical area for which to assign house types. required Returns: Type Description None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key, with special handling for larger households. 3. Iterates through each household to assign house types based on the probability data. 4. Logs any cases where valid house type data is not available for certain household sizes. Source code in tripsender\\utils.py 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 def assign_house_type_to_households ( year , area ): \"\"\" Assign house types to households based on probability data (improved method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an improved method that accounts for varying household sizes and assigns house types accordingly. Args: year (int): The year for which to assign house types. area (str): The geographical area for which to assign house types. Returns: None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key, with special handling for larger households. 3. Iterates through each household to assign house types based on the probability data. 4. Logs any cases where valid house type data is not available for certain household sizes. \"\"\" p_housetype = get_probability_of_housetype ( year , area ) # Define a mapping from household size to the corresponding key in p_housetype size_to_key_mapping = { 1 : '1 person' , 2 : '2 personer' , 3 : '3 personer' , 4 : '4 personer' , 5 : '5 personer' , 6 : '6 eller fler personer' } for household in Household . instances : household_size = len ( household . members ) # For households larger than 6, start checking from '6 eller fler personer' if household_size > 6 : current_size = 6 else : current_size = household_size # Flag to indicate if a house type has been assigned assigned = False while current_size >= 1 : key = size_to_key_mapping [ current_size ] # Check if there's valid probability data for the current size probabilities = list ( p_housetype . get ( key , {}) . values ()) if sum ( probabilities ) > 0 : house_type = np . random . choice ( list ( p_housetype [ key ] . keys ()), p = probabilities ) household . house_type = house_type assigned = True break # Exit the loop once a house type is assigned current_size -= 1 # Decrement size to check the next smaller size if not assigned : # If no valid house type was assigned logger . info ( f \"No valid house type data for household size { household_size } or smaller. No house type assigned.\" )","title":"assign_house_type_to_households"},{"location":"utils/#tripsender.utils.assign_house_type_to_households_old","text":"Assign house types to households based on probability data (old method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an older method that directly maps household sizes to house types. Parameters: Name Type Description Default year int The year for which to assign house types. required area str The geographical area for which to assign house types. required Returns: Type Description None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key. 3. Assigns house types to households based on the probability data. 4. Logs any cases where household size does not match the probability data. Source code in tripsender\\utils.py 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 def assign_house_type_to_households_old ( year , area ): \"\"\" Assign house types to households based on probability data (old method). This function assigns house types to households in the specified year and area using probability data fetched from external sources. It uses an older method that directly maps household sizes to house types. Args: year (int): The year for which to assign house types. area (str): The geographical area for which to assign house types. Returns: None The function performs the following steps: 1. Fetches probability data for house types based on the specified year and area. 2. Maps household sizes to the corresponding house type key. 3. Assigns house types to households based on the probability data. 4. Logs any cases where household size does not match the probability data. \"\"\" p_housetype = get_probability_of_housetype ( year , area ) # Define a mapping from household size to the corresponding key in p_housetype size_to_key_mapping = { 1 : '1 person' , 2 : '2 personer' , 3 : '3 personer' , 4 : '4 personer' , 5 : '5 personer' , 6 : '6 eller fler personer' } for household in Household . instances : household_size = len ( household . members ) # Use the mapping to get the corresponding key for the household size key = size_to_key_mapping . get ( household_size , None ) if household_size > 6 : # Explicitly handle the case where size > 6 key = '6 eller fler personer' if key : house_type = np . random . choice ( list ( p_housetype [ key ] . keys ()), p = list ( p_housetype [ key ] . values ())) household . house_type = house_type else : logger . info ( f \"assign_house_type_to_households: Household size { household_size } not found in p_housetype\" )","title":"assign_house_type_to_households_old"},{"location":"utils/#tripsender.utils.assign_primary_status_to_members","text":"Assign primary status (e.g., work, education, home) to household members. This function assigns primary status to household members for the specified year and area using a pre-trained classifier model. It predicts the probability of different primary statuses for each individual and assigns the status based on the top predictions. Parameters: Name Type Description Default year int The year for which to assign primary status. required area str The geographical area for which to assign primary status. required classifier object The pre-trained classifier model for predicting primary status. required Returns: Type Description None The function performs the following steps: 1. Fetches primary status data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of different primary statuses for each individual. 4. Assigns primary status to individuals based on the top predictions. 5. Logs the distribution of primary status among the household members. Source code in tripsender\\utils.py 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 def assign_primary_status_to_members ( year , area , classifier ): \"\"\" Assign primary status (e.g., work, education, home) to household members. This function assigns primary status to household members for the specified year and area using a pre-trained classifier model. It predicts the probability of different primary statuses for each individual and assigns the status based on the top predictions. Args: year (int): The year for which to assign primary status. area (str): The geographical area for which to assign primary status. classifier (object): The pre-trained classifier model for predicting primary status. Returns: None The function performs the following steps: 1. Fetches primary status data for the specified year and area. 2. Preprocesses household data for model input. 3. Predicts the probability of different primary statuses for each individual. 4. Assigns primary status to individuals based on the top predictions. 5. Logs the distribution of primary status among the household members. \"\"\" primary_dict = fetch_primary_status ( year , area ) # {'WORK': '6140', 'STUDY': '505', 'INACTIVE': '285'} working_count = int ( primary_dict [ 'WORK' ]) study_count = int ( primary_dict [ 'STUDY' ]) home_count = int ( primary_dict [ 'INACTIVE' ]) aligned_columns = [ 'child_count' , 'adult_count' , 'car_count' , 'x0_Kvinnor' , 'x0_M\u00e4n' , 'x0_Other' , 'x1_16-24' , 'x1_25-34' , 'x1_35-44' , 'x1_45-54' , 'x1_55-64' , 'x1_65-74' , 'x1_75+' , 'x2_Apartment' , 'x2_Other' , 'x2_Villa' , 'x3_Couple' , 'x3_Other' , 'x3_Single' , 'x2_Not Available' ] df , adults = preprocess_household_data ( aligned_columns = aligned_columns , drop = [ 'primary_status' ], onehotencode = True ) # Assume 'classifier' and 'df' are already defined and ready probs = classifier . predict_proba ( df ) # Initialize all to 'NA' (or another default status) df [ 'primary_status' ] = 'NA' # Sort indices based on probabilities for 'WORK' work_indices = np . argsort ( - probs [:, 0 ])[: working_count ] df . loc [ work_indices , 'primary_status' ] = 'WORK' # Exclude already assigned 'WORK' from 'STUDY' remaining_for_study = df [ df [ 'primary_status' ] == 'NA' ] study_indices = np . argsort ( - probs [ remaining_for_study . index , 1 ])[: study_count ] df . loc [ study_indices , 'primary_status' ] = 'EDUCATION' # Assign 'HOME' to the remaining, if needed remaining_for_home = df [ df [ 'primary_status' ] == 'NA' ] if len ( remaining_for_home ) > home_count : home_indices = np . argsort ( - probs [ remaining_for_home . index , 2 ])[: home_count ] df . loc [ home_indices , 'primary_status' ] = 'HOME' else : df . loc [ remaining_for_home . index , 'primary_status' ] = 'HOME' # Update the primary status of adults based on the DataFrame for i , adult in enumerate ( adults ): adult . primary_status = df . loc [ i , 'primary_status' ] workers , students , neither = [], [], [] for person in Person . instances : if person . primary_status == \"WORK\" : workers . append ( person ) elif person . primary_status == \"EDUCATION\" : students . append ( person ) elif person . primary_status == \"HOME\" : neither . append ( person ) logger . info ( f \"Number of workers: { len ( workers ) } - { len ( workers ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of students: { len ( students ) } - { len ( students ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of neither: { len ( neither ) } - { len ( neither ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Total number of persons: { len ( Person . instances ) } \" )","title":"assign_primary_status_to_members"},{"location":"utils/#tripsender.utils.assign_primary_status_to_members_backup","text":"Assign primary status (e.g., work, education, home) to household members using a backup method. This function assigns primary status to household members using a pre-trained classifier model. It predicts the primary status for each individual based on household data and assigns the corresponding status to each member. Parameters: Name Type Description Default classifier object The pre-trained classifier model for predicting primary status. required Returns: Type Description None The function performs the following steps: 1. Preprocesses household data for model input. 2. Predicts the primary status for each individual using the classifier. 3. Assigns the predicted primary status to each member. 4. Logs the distribution of primary status among the household members. Source code in tripsender\\utils.py 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 def assign_primary_status_to_members_backup ( classifier ): \"\"\" Assign primary status (e.g., work, education, home) to household members using a backup method. This function assigns primary status to household members using a pre-trained classifier model. It predicts the primary status for each individual based on household data and assigns the corresponding status to each member. Args: classifier (object): The pre-trained classifier model for predicting primary status. Returns: None The function performs the following steps: 1. Preprocesses household data for model input. 2. Predicts the primary status for each individual using the classifier. 3. Assigns the predicted primary status to each member. 4. Logs the distribution of primary status among the household members. \"\"\" aligned_columns = [ 'child_count' , 'adult_count' , 'car_count' , 'x0_Kvinnor' , 'x0_M\u00e4n' , 'x0_Other' , 'x1_16-24' , 'x1_25-34' , 'x1_35-44' , 'x1_45-54' , 'x1_55-64' , 'x1_65-74' , 'x1_75+' , 'x2_Apartment' , 'x2_Other' , 'x2_Villa' , 'x3_Couple' , 'x3_Other' , 'x3_Single' , 'x2_Not Available' ] df , adults = preprocess_household_data ( aligned_columns = aligned_columns , drop = [ 'primary_status' ], onehotencode = True ) # Predict the primary status for each person using the classifier df [ 'primary_status' ] = classifier . predict ( df ) # Add the primary status to each person for i , adult in enumerate ( adults ): numeric_primary_status = df [ 'primary_status' ][ i ] if numeric_primary_status == 1 : adult . primary_status = 'WORK' elif numeric_primary_status == 2 : adult . primary_status = 'EDUCATION' elif numeric_primary_status == 3 : adult . primary_status = 'HOME' else : adult . primary_status = 'NA' workers , students , neither = [], [], [] for person in Person . instances : if person . primary_status == \"WORK\" : workers . append ( person ) elif person . primary_status == \"EDUCATION\" : students . append ( person ) elif person . primary_status == \"HOME\" : neither . append ( person ) logger . info ( f \"Number of workers: { len ( workers ) } - { len ( workers ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of students: { len ( students ) } - { len ( students ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Number of neither: { len ( neither ) } - { len ( neither ) / len ( Person . instances ) * 100 : .2f } %\" ) logger . info ( f \"Total number of persons: { len ( Person . instances ) } \" )","title":"assign_primary_status_to_members_backup"},{"location":"utils/#tripsender.utils.balance_lists","text":"Balance the lengths of two lists by moving excess individuals to a separate list. This function ensures that the two input lists have the same length by moving excess individuals from the longer list to a separate list of unmatched individuals. Parameters: Name Type Description Default p1 list The first list of individuals. required p2 list The second list of individuals. required Returns: Name Type Description tuple A tuple containing the balanced lists and the list of unmatched individuals. The function performs the following steps: 1. Checks if the lengths of the two lists are equal. 2. If not, calculates the difference in lengths and moves excess individuals to a separate list. 3. Returns the balanced lists and the list of unmatched individuals. Source code in tripsender\\utils.py 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 def balance_lists ( p1 , p2 ): \"\"\" Balance the lengths of two lists by moving excess individuals to a separate list. This function ensures that the two input lists have the same length by moving excess individuals from the longer list to a separate list of unmatched individuals. Args: p1 (list): The first list of individuals. p2 (list): The second list of individuals. Returns: tuple: A tuple containing the balanced lists and the list of unmatched individuals. The function performs the following steps: 1. Checks if the lengths of the two lists are equal. 2. If not, calculates the difference in lengths and moves excess individuals to a separate list. 3. Returns the balanced lists and the list of unmatched individuals. \"\"\" len_p1 , len_p2 = len ( p1 ), len ( p2 ) # Check if the lists are already of equal length if len_p1 == len_p2 : return p1 , p2 , [] # Find the difference in lengths diff = abs ( len_p1 - len_p2 ) # Move individuals to unmatched_individuals until the lengths are equal unmatched_individuals = [] while diff > 0 : if len_p1 > len_p2 : unmatched_individuals . append ( p1 . pop ()) else : unmatched_individuals . append ( p2 . pop ()) diff -= 1 return p1 , p2 , unmatched_individuals","title":"balance_lists"},{"location":"utils/#tripsender.utils.calculate_similarity","text":"Calculate the similarity between the query and the area. This function calculates the similarity score between the query string and the area string based on various criteria such as exact match, missing characters, and common characters. Parameters: Name Type Description Default query str The query string. required area str The area string to compare with the query. required Returns: Name Type Description float The similarity score between the query and the area. The function performs the following steps: 1. Checks for an exact match and returns a high similarity score if found. 2. Checks for missing characters and returns a high similarity score if found. 3. Calculates the similarity based on the number of common characters between the query and the area. 4. Returns the similarity score. Source code in tripsender\\utils.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def calculate_similarity ( query , area ): \"\"\" Calculate the similarity between the query and the area. This function calculates the similarity score between the query string and the area string based on various criteria such as exact match, missing characters, and common characters. Args: query (str): The query string. area (str): The area string to compare with the query. Returns: float: The similarity score between the query and the area. The function performs the following steps: 1. Checks for an exact match and returns a high similarity score if found. 2. Checks for missing characters and returns a high similarity score if found. 3. Calculates the similarity based on the number of common characters between the query and the area. 4. Returns the similarity score. \"\"\" query_len = len ( query ) area_len = len ( area ) # Check for exact match if query == area : return 100 # Check for missing characters if query_len + 1 == area_len and area . startswith ( query ): return 90 # Check for misspelled names with 1 missing character if query_len == area_len + 1 and query . startswith ( area ): return 90 # Calculate similarity based on common characters common_chars = set ( query ) . intersection ( area ) similarity = ( len ( common_chars ) / max ( query_len , area_len )) * 100 return similarity","title":"calculate_similarity"},{"location":"utils/#tripsender.utils.cap_cars_per_household","text":"Cap the number of cars per household to a specified maximum. This function ensures that no household has more than the specified maximum number of cars. If a household has more cars than the specified maximum, the excess cars are removed and the car ownership status of individuals is updated accordingly. Parameters: Name Type Description Default households list The list of Household instances. required max_cars int The maximum number of cars allowed per household. Defaults to 4. 4 Returns: Type Description None The function performs the following steps: 1. Iterates through each household in the list. 2. Checks if the household has more cars than the specified maximum. 3. If so, removes the excess cars and updates the car ownership status of individuals. Source code in tripsender\\utils.py 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 def cap_cars_per_household ( households , max_cars = 4 ): \"\"\" Cap the number of cars per household to a specified maximum. This function ensures that no household has more than the specified maximum number of cars. If a household has more cars than the specified maximum, the excess cars are removed and the car ownership status of individuals is updated accordingly. Args: households (list): The list of Household instances. max_cars (int): The maximum number of cars allowed per household. Defaults to 4. Returns: None The function performs the following steps: 1. Iterates through each household in the list. 2. Checks if the household has more cars than the specified maximum. 3. If so, removes the excess cars and updates the car ownership status of individuals. \"\"\" for household in households : if household . cars > max_cars : excess_cars = household . cars - max_cars household . cars -= excess_cars members_with_cars = [ member for member in household . members if member . has_car ] random . shuffle ( members_with_cars ) for person in members_with_cars [: excess_cars ]: person . has_car = False","title":"cap_cars_per_household"},{"location":"utils/#tripsender.utils.clear_instances","text":"Clear all instances of Population, Person, House, Household, Building, and ActivitySequence. This function clears all instances of the specified classes to reset the data. It ensures that no residual data remains from previous runs. Returns: Type Description None The function performs the following steps: 1. Clears all instances of the Population class. 2. Clears all instances of the Person class. 3. Clears all instances of the House class. 4. Clears all instances of the Household class. 5. Clears all instances of the Building class. 6. Clears all instances of the ActivitySequence class. Source code in tripsender\\utils.py 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 def clear_instances (): \"\"\" Clear all instances of Population, Person, House, Household, Building, and ActivitySequence. This function clears all instances of the specified classes to reset the data. It ensures that no residual data remains from previous runs. Returns: None The function performs the following steps: 1. Clears all instances of the Population class. 2. Clears all instances of the Person class. 3. Clears all instances of the House class. 4. Clears all instances of the Household class. 5. Clears all instances of the Building class. 6. Clears all instances of the ActivitySequence class. \"\"\" Population . clear_instances () Person . clear_instances () House . clear_instances () Household . clear_instances () Building . clear_instances () ActivitySequence . clear_instances ()","title":"clear_instances"},{"location":"utils/#tripsender.utils.couples_from_individuals","text":"Create couples from two lists of individuals and form households. This function matches individuals from two lists (e.g., males and females) to create couples and form households. It balances the lists, matches individuals based on age, and creates Household instances for each couple. Parameters: Name Type Description Default p1 list The first list of individuals (e.g., males). required p2 list The second list of individuals (e.g., females). required Returns: Name Type Description tuple A tuple containing the number of households created and the list of Household instances. The function performs the following steps: 1. Balances the lengths of the two lists. 2. Matches individuals from the two lists based on age and other criteria. 3. Creates Household instances for each matched couple. 4. Returns the number of households created and the list of Household instances. Source code in tripsender\\utils.py 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 def couples_from_individuals ( p1 , p2 ): \"\"\" Create couples from two lists of individuals and form households. This function matches individuals from two lists (e.g., males and females) to create couples and form households. It balances the lists, matches individuals based on age, and creates Household instances for each couple. Args: p1 (list): The first list of individuals (e.g., males). p2 (list): The second list of individuals (e.g., females). Returns: tuple: A tuple containing the number of households created and the list of Household instances. The function performs the following steps: 1. Balances the lengths of the two lists. 2. Matches individuals from the two lists based on age and other criteria. 3. Creates Household instances for each matched couple. 4. Returns the number of households created and the list of Household instances. \"\"\" households = [] #logger.info(f\"There are {len(p1)} males and {len(p2)} females in this group\") # Check the length of the two groups, if they are not equal, move the extra individual into a new group #unmatched_individuals = [] #logger.info(\"Length of partner lists\",len(p1), len(p2)) # P1 and p2 need to be of equal length # if moving extra individual to either p1 or p2 makes them equal, then do that # else move the extra individual to unmatched_individuals until the length of p1 and p2 are equal p1 , p2 , unmatched_individuals = balance_lists ( p1 , p2 ) # Check if unmatched_individuals in empty # if not empty check if it is odd # if odd, create one new person with the same attributes as a random unmatched_individual # and add it to the unmatched_individuals list # Once even, split the list into two and add them to p1 and p2 if unmatched_individuals : if len ( unmatched_individuals ) % 2 == 1 : # pick a random person person = random . choice ( unmatched_individuals ) #get age group of person person_age_group = age_group_from_age ( person . age ) new_person = Person ( person_age_group , person . sex , person . household_type ) # Add the new person to the unmatched_individuals list unmatched_individuals . append ( new_person ) # Split the unmatched_individuals list into two and add them to p1 and p2 p1 . extend ( unmatched_individuals [: len ( unmatched_individuals ) // 2 ]) p2 . extend ( unmatched_individuals [ len ( unmatched_individuals ) // 2 :]) #logger.info(\"Length of partner lists\",len(p1), len(p2)) # sort the two groups by age p1 . sort ( key = lambda x : x . age , reverse = True ) p2 . sort ( key = lambda x : x . age , reverse = True ) # Get the age proxy for group 1 age_proxy_list = [] for person in p1 : # Sample a number from distribution mean = 0 sd = 6 age_proxy = np . random . normal ( 0 , 6 ) + person . age age_proxy_list . append ( age_proxy ) # sort age_proxy_list in descending order and use it to sort p1 p1 = [ x for _ , x in sorted ( zip ( age_proxy_list , p1 ), reverse = True )] # Match individuals in married_individuals_split_1 with individuals in p2 for i , person in enumerate ( p1 ): # assiging household head if person . age > p2 [ i ] . age : person . is_head = True else : p2 [ i ] . is_head = True household = Household ( 'Couple' ) household . add_member ( person ) household . add_member ( p2 [ i ]) # adding household to households households . append ( household ) households_created = len ( p1 ) return households_created , households","title":"couples_from_individuals"},{"location":"utils/#tripsender.utils.get_older_child_probability_matrix","text":"Calculate the probability matrix for households with older children (aged 25+ years). This function processes the input data to calculate the probability of households having older children. It returns a dictionary with the probability of having older children in different household categories. Parameters: Name Type Description Default older_children_data dict The input data containing information on households with older children. required Returns: Name Type Description dict A dictionary containing the probability matrix for households with older children. The function performs the following steps: 1. Processes the input data to extract household categories and the count of older children. 2. Calculates the total number of households with older children. 3. Calculates the probability of having older children in each household category. 4. Returns the resulting probability matrix. Source code in tripsender\\utils.py 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_older_child_probability_matrix ( older_children_data ): \"\"\" Calculate the probability matrix for households with older children (aged 25+ years). This function processes the input data to calculate the probability of households having older children. It returns a dictionary with the probability of having older children in different household categories. Args: older_children_data (dict): The input data containing information on households with older children. Returns: dict: A dictionary containing the probability matrix for households with older children. The function performs the following steps: 1. Processes the input data to extract household categories and the count of older children. 2. Calculates the total number of households with older children. 3. Calculates the probability of having older children in each household category. 4. Returns the resulting probability matrix. \"\"\" total_older_kids = 0 keys = [] probabilities = [] for household_type in older_children_data [ 'data' ]: key = household_type [ \"key\" ][ 1 ] if \"25\" in key : if \"Ensamst\u00e5ende\" in key : key = \"Single\" elif \"Sammanboende\" in key : key = \"Couple\" elif \"\u00d6vriga\" in key : key = \"Other\" keys . append ( key ) value = int ( household_type [ \"values\" ][ 0 ]) total_older_kids += value probabilities . append ( value ) probabilities = [ value / total_older_kids for value in probabilities ] # create a dict of keys and probabilities return dict ( zip ( keys , probabilities ))","title":"get_older_child_probability_matrix"},{"location":"utils/#tripsender.utils.get_probability_of_children","text":"Calculate the probability of having children in different household types. This function fetches data on households with children for the specified year and area, processes the data to calculate the probability of having children in different household types, and returns the calculated probabilities. Parameters: Name Type Description Default year int The year for which the data is to be fetched. required area str The geographical area for which the data is to be fetched. required Returns: Name Type Description dict A dictionary containing the probability of having children in each household type. The function performs the following steps: 1. Fetches data on households with children for the specified year and area. 2. Processes the data to calculate the total number of households in each household type. 3. Calculates the probability of having children in each household type based on the fetched data. 4. Returns the calculated probabilities. Source code in tripsender\\utils.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 def get_probability_of_children ( year , area ): \"\"\" Calculate the probability of having children in different household types. This function fetches data on households with children for the specified year and area, processes the data to calculate the probability of having children in different household types, and returns the calculated probabilities. Args: year (int): The year for which the data is to be fetched. area (str): The geographical area for which the data is to be fetched. Returns: dict: A dictionary containing the probability of having children in each household type. The function performs the following steps: 1. Fetches data on households with children for the specified year and area. 2. Processes the data to calculate the total number of households in each household type. 3. Calculates the probability of having children in each household type based on the fetched data. 4. Returns the calculated probabilities. \"\"\" data = fetch_older_children_data ( year , area ) p_children_age = {} for item in data [ \"data\" ]: key = ( item [ \"key\" ][ 1 ] . split ( \" \" )[ 0 ]) nested_key = item [ \"key\" ][ 1 ] . replace ( key , \"\" ) value = item [ \"values\" ][ 0 ] if 'utan barn' in nested_key : nested_key = 'No Kids' elif '0-24' in nested_key : nested_key = 'Kids Under 25' elif '25' in nested_key : nested_key = 'Kids Over 25' if key not in p_children_age : p_children_age [ key ] = {} p_children_age [ key ][ nested_key ] = int ( value ) # Total households in each key total_households = {} for key in p_children_age : total_households [ key ] = sum ( p_children_age [ key ] . values ()) # Replace Ensamst\u00e5ende with Single, Sammanboende with Couple and \u00d6vrigt with Other total_households [ 'Single' ] = total_households . pop ( 'Ensamst\u00e5ende' ) total_households [ 'Couple' ] = total_households . pop ( 'Sammanboende' ) total_households [ 'Other' ] = total_households . pop ( '\u00d6vriga' ) # Create a new dictionary called hasChild with two keys True and False and the values are the number of households hasChild = {} for key in p_children_age : hasChild [ key ] = {} hasChild [ key ][ True ] = p_children_age [ key ][ 'Kids Under 25' ] + p_children_age [ key ][ 'Kids Over 25' ] hasChild [ key ][ False ] = p_children_age [ key ][ 'No Kids' ] # Replace Ensamst\u00e5ende with Single, Sammanboende with Couple and \u00d6vrigt with Other hasChild [ 'Single' ] = hasChild . pop ( 'Ensamst\u00e5ende' ) hasChild [ 'Couple' ] = hasChild . pop ( 'Sammanboende' ) hasChild [ 'Other' ] = hasChild . pop ( '\u00d6vriga' ) # Calculate the probability of having children in each household type p_children = {} for key in hasChild : p_children [ key ] = {} p_children [ key ][ True ] = hasChild [ key ][ True ] / total_households [ key ] p_children [ key ][ False ] = hasChild [ key ][ False ] / total_households [ key ] return p_children","title":"get_probability_of_children"},{"location":"utils/#tripsender.utils.get_probability_of_housetype","text":"Calculate the probability of different household types in a given area. This function fetches data on household types for the specified year and area, processes the data to calculate the probability of each household type, and returns the calculated probabilities. Parameters: Name Type Description Default year int The year for which the data is to be fetched. required area str The geographical area for which the data is to be fetched. required Returns: Name Type Description dict A dictionary containing the probability of each household type in the area. The function performs the following steps: 1. Fetches data on household types for the specified year and area. 2. Processes the data to map household types to simplified categories. 3. Calculates the total number of households in each category. 4. Calculates the percentage of each household type based on the fetched data. 5. Returns the calculated probabilities. Source code in tripsender\\utils.py 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_probability_of_housetype ( year , area ): \"\"\" Calculate the probability of different household types in a given area. This function fetches data on household types for the specified year and area, processes the data to calculate the probability of each household type, and returns the calculated probabilities. Args: year (int): The year for which the data is to be fetched. area (str): The geographical area for which the data is to be fetched. Returns: dict: A dictionary containing the probability of each household type in the area. The function performs the following steps: 1. Fetches data on household types for the specified year and area. 2. Processes the data to map household types to simplified categories. 3. Calculates the total number of households in each category. 4. Calculates the percentage of each household type based on the fetched data. 5. Returns the calculated probabilities. \"\"\" # Fetch the data data = fetch_housetype_data ( year , area ) # Create a dictionary with the probability of each household type p_housetype = {} for item in data [ \"data\" ]: key = ( item [ \"key\" ][ 1 ]) nested_key = ( item [ \"key\" ][ 2 ]) value = item [ \"values\" ][ 0 ] if \"Sm\u00e5hus\" in nested_key : nested_key = \"Villa\" elif \"Flerbostadshus\" in nested_key : nested_key = \"Apartment\" elif \"Specialbostad, \u00f6vriga hus\" in nested_key : nested_key = \"Other\" else : nested_key = \"Not Available\" if key not in p_housetype : p_housetype [ key ] = {} p_housetype [ key ][ nested_key ] = int ( value ) # Total households in each key total_households = {} for key in p_housetype : total_households [ key ] = sum ( p_housetype [ key ] . values ()) # Calculate the percentage of each household type p_housetype_percentage = {} for key in p_housetype : p_housetype_percentage [ key ] = {} for nested_key in p_housetype [ key ]: # Take care of divbyzero error if total_households [ key ] == 0 : p_housetype_percentage [ key ][ nested_key ] = 0 else : p_housetype_percentage [ key ][ nested_key ] = p_housetype [ key ][ nested_key ] / total_households [ key ] return p_housetype_percentage","title":"get_probability_of_housetype"},{"location":"utils/#tripsender.utils.get_younger_child_probability_matrix","text":"Calculate the probability matrix for the number of younger children in households. This function processes the input data to calculate the probability of having a certain number of younger children in different household categories. It returns the resulting probability matrix. Parameters: Name Type Description Default data dict The input data containing household information. required Returns: Name Type Description dict A dictionary containing the probability matrix for the number of younger children in households. The function performs the following steps: 1. Renames household types in the input data to simplified categories. 2. Merges data for similar household types. 3. Creates a nested dictionary with the count of younger children for each household category. 4. Calculates the probability of having a certain number of younger children in each household category. 5. Returns the resulting probability matrix. Source code in tripsender\\utils.py 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 def get_younger_child_probability_matrix ( data ): \"\"\" Calculate the probability matrix for the number of younger children in households. This function processes the input data to calculate the probability of having a certain number of younger children in different household categories. It returns the resulting probability matrix. Args: data (dict): The input data containing household information. Returns: dict: A dictionary containing the probability matrix for the number of younger children in households. The function performs the following steps: 1. Renames household types in the input data to simplified categories. 2. Merges data for similar household types. 3. Creates a nested dictionary with the count of younger children for each household category. 4. Calculates the probability of having a certain number of younger children in each household category. 5. Returns the resulting probability matrix. \"\"\" # Step 1: Rename household types # Create a dictionary to map the original household types to their replacements household_types = { 'Ensamst\u00e5ende' : 'Single' , 'Sammanboende' : 'Couple' , '\u00d6vriga hush\u00e5ll' : 'Couple' , 'Uppgift saknas' : 'Other' } # Iterate through each entry in the data for entry in data [ 'data' ]: household_type = entry [ 'key' ][ 1 ] # Get the household type from the entry # Replace the household type with its corresponding replacement if it exists in the dictionary entry [ 'key' ][ 1 ] = household_types . get ( household_type , household_type ) # Step 2: Merge couple households # Initialize an empty dictionary to store the merged data merged_data = {} # Iterate through each entry in the data for entry in data [ 'data' ]: key = tuple ( entry [ 'key' ][ 1 : - 1 ]) # Extract the key by excluding the area and year value = int ( entry [ 'values' ][ 0 ]) # Convert the value to an integer merged_data [ key ] = merged_data . get ( key , 0 ) + value # Add the value to the existing value for the corresponding key, or initialize it to 0 if the key doesn't exist # Step 2.1 Nest data # Initialize an empty dictionary to store the nested data probability_matrix = {} # Iterate through each (category, children) pair and its corresponding value in the merged data for ( category , children ), value in merged_data . items (): # Create a nested dictionary if the category doesn't exist in the probability matrix probability_matrix . setdefault ( category , {})[ children ] = value # Add the value to the corresponding children key in the category dictionary # Step 3: Find totals per children number # Iterate through each household type in the probability matrix for household_type in probability_matrix : # Calculate the total value by summing the values for all children numbers in the household type dictionary total = sum ( probability_matrix [ household_type ] . values ()) # Replace the values in the household type dictionary with their respective probabilities probability_matrix [ household_type ] = { children : value / total if total != 0 else 0 for children , value in probability_matrix [ household_type ] . items () # Divide each value by the total, accounting for the possibility of zero division } # Return the resulting probability matrix return probability_matrix","title":"get_younger_child_probability_matrix"},{"location":"utils/#tripsender.utils.impute_municipal_children_count","text":"Impute the count of children in households within a municipality based on provided data. This function fetches municipal children data for the specified year and area, processes the data to impute the count of children in different household categories, and returns the imputed data as dictionaries for households with children aged 0-24 years and 25 years or older. Parameters: Name Type Description Default year int The year for which the data is to be fetched. required area str The geographical area for which the data is to be fetched. required Returns: Name Type Description tuple Two dictionaries containing imputed children counts for households with children aged 0-24 years and 25 years or older. The function performs the following steps: 1. Fetches municipal children data for the specified year and area. 2. Processes the data to create a nested dictionary with children counts for different household categories. 3. Transforms the data to calculate the probability of having a certain number of children in each household category. 4. Separates the data into two dictionaries based on the age of children (0-24 years and 25 years or older). 5. Returns the two dictionaries with imputed children counts. Source code in tripsender\\utils.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def impute_municipal_children_count ( year , area ): \"\"\" Impute the count of children in households within a municipality based on provided data. This function fetches municipal children data for the specified year and area, processes the data to impute the count of children in different household categories, and returns the imputed data as dictionaries for households with children aged 0-24 years and 25 years or older. Args: year (int): The year for which the data is to be fetched. area (str): The geographical area for which the data is to be fetched. Returns: tuple: Two dictionaries containing imputed children counts for households with children aged 0-24 years and 25 years or older. The function performs the following steps: 1. Fetches municipal children data for the specified year and area. 2. Processes the data to create a nested dictionary with children counts for different household categories. 3. Transforms the data to calculate the probability of having a certain number of children in each household category. 4. Separates the data into two dictionaries based on the age of children (0-24 years and 25 years or older). 5. Returns the two dictionaries with imputed children counts. \"\"\" data = fetch_municipal_children_data ( year ) # Extract the relevant data from the JSON nested_dict = {} total_households = [] for hh in data [ \"data\" ]: key = hh [ \"key\" ][ 1 ] nested_key = hh [ \"key\" ][ 2 ] value = int ( hh [ \"values\" ][ 0 ]) #total_households.append(value) if key not in nested_dict : nested_dict [ key ] = {} nested_dict [ key ][ nested_key ] = value if 'SAKNAS' in nested_dict : del nested_dict [ 'SAKNAS' ] # Calculate the total number of households in the municipality for key in nested_dict : total_households . append ( sum ( nested_dict [ key ] . values ())) # Get probability of number of children in each household category #for i,key in enumerate(nested_dict): # for nested_key in nested_dict[key]: # nested_dict[key][nested_key] = nested_dict[key][nested_key]/total_households[i] # Creating a dictionary for name changes name_change = { 'ESUB' : 'Ensamst\u00e5ende utan barn' , 'ESMB24' : 'Ensamst\u00e5ende med barn 0-24 \u00e5r' , 'ESMB25' : 'Ensamst\u00e5ende med barn 25 \u00e5r eller \u00e4ldre' , 'SMUB' : 'Sammanboende utan barn' , 'SBMB24' : 'Sammanboende med barn 0-24 \u00e5r' , 'SBMB25' : 'Sammanboende med barn 25 \u00e5r eller \u00e4ldre' , 'OVRIUB' : '\u00d6vriga hush\u00e5ll utan barn' , '\u00d6MB24' : '\u00d6vriga hush\u00e5ll med barn 0-24 \u00e5r' , '\u00d6MB25' : '\u00d6vriga hush\u00e5ll med barn 25 \u00e5r eller \u00e4ldre' } # If a key is found in the name_change dictionary, replace the key with the value municipal_children = {} for old_key , value in nested_dict . items (): new_key = name_change . get ( old_key , old_key ) municipal_children [ new_key ] = value # Remove keys with utan barn municipal_children = { k : v for k , v in municipal_children . items () if 'utan barn' not in k } # Replace UB with 0, M1B with 1, M2B with 2, M3+B with 3 for key , value in municipal_children . items (): key_list = list ( value . keys ()) # Check if any ['UB','M1B', 'M2B','M3+B','SAKNAS'] in key_list if any ( x in key_list for x in [ 'UB' , 'M1B' , 'M2B' , 'M3+B' , 'SAKNAS' ]): municipal_children [ key ][ 0 ] = municipal_children [ key ] . pop ( 'UB' ) municipal_children [ key ][ 1 ] = municipal_children [ key ] . pop ( 'M1B' ) municipal_children [ key ][ 2 ] = municipal_children [ key ] . pop ( 'M2B' ) municipal_children [ key ][ 3 ] = municipal_children [ key ] . pop ( 'M3+B' ) municipal_children [ key ][ 'other' ] = municipal_children [ key ] . pop ( 'SAKNAS' ) # Create two dicts from municipal_children dict, one for 0-24 years and one for 25+ years municipal_children_0_24 = { k : v for k , v in municipal_children . items () if '0-24' in k } municipal_children_25 = { k : v for k , v in municipal_children . items () if '25' in k } # split key and replace with first word municipal_children_0_24 = { k . split ()[ 0 ]: v for k , v in municipal_children_0_24 . items ()} municipal_children_25 = { k . split ()[ 0 ]: v for k , v in municipal_children_25 . items ()} # Replace ensamst\u00e5ende with single, sammanboende with couple and \u00f6vriga hush\u00e5ll with other municipal_children_0_24 = { k . replace ( 'Ensamst\u00e5ende' , 'Single' ) . replace ( 'Sammanboende' , 'Couple' ) . replace ( '\u00d6vriga' , 'Other' ): v for k , v in municipal_children_0_24 . items ()} municipal_children_25 = { k . replace ( 'Ensamst\u00e5ende' , 'Single' ) . replace ( 'Sammanboende' , 'Couple' ) . replace ( '\u00d6vriga' , 'Other' ): v for k , v in municipal_children_25 . items ()} # Calculate total households 0-24 and 25+ total_households_0_24 = [] total_households_25 = [] for key in municipal_children_0_24 : total_households_0_24 . append ( sum ( municipal_children_0_24 [ key ] . values ())) for key in municipal_children_25 : total_households_25 . append ( sum ( municipal_children_25 [ key ] . values ())) # Calculate the probability of number of children in each household category municipal_children_0_24 for i , key in enumerate ( municipal_children_0_24 ): for hh in municipal_children_0_24 [ key ]: municipal_children_0_24 [ key ][ hh ] = municipal_children_0_24 [ key ][ hh ] / total_households_0_24 [ i ] for i , key in enumerate ( municipal_children_25 ): for hh in municipal_children_25 [ key ]: municipal_children_25 [ key ][ hh ] = municipal_children_25 [ key ][ hh ] / total_households_25 [ i ] return municipal_children_0_24 , municipal_children_25","title":"impute_municipal_children_count"},{"location":"utils/#tripsender.utils.match_child_to_parent","text":"Match a child to a parent based on age and add the child to the parent's household. This function matches a child to a parent from the list of children based on the age difference between the parent and the child. It uses a tolerance range to find a suitable match and adds the matched child to the parent's household. Parameters: Name Type Description Default parent Person The parent individual. required list_of_children list The list of child individuals to match. required min_age_of_parent int The minimum age for a parent. Defaults to 20. 20 initial_tolerance int The initial tolerance range for matching. Defaults to 5. 5 max_tolerance int The maximum tolerance range for matching. Defaults to 20. 20 tolerance_increment int The increment in tolerance range for each iteration. Defaults to 2. 2 Returns: Type Description None The function performs the following steps: 1. Calculates the proxy age of the child based on the parent's age and minimum age of parent. 2. Iterates through the list of children to find a match within the initial tolerance range. 3. If no match is found, increases the tolerance range and retries until the maximum tolerance is reached. 4. Adds the matched child to the parent's household and removes the child from the list of children. 5. Logs the matching process and results. Source code in tripsender\\utils.py 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 def match_child_to_parent ( parent , list_of_children , min_age_of_parent = 20 , initial_tolerance = 5 , max_tolerance = 20 , tolerance_increment = 2 ): \"\"\" Match a child to a parent based on age and add the child to the parent's household. This function matches a child to a parent from the list of children based on the age difference between the parent and the child. It uses a tolerance range to find a suitable match and adds the matched child to the parent's household. Args: parent (Person): The parent individual. list_of_children (list): The list of child individuals to match. min_age_of_parent (int, optional): The minimum age for a parent. Defaults to 20. initial_tolerance (int, optional): The initial tolerance range for matching. Defaults to 5. max_tolerance (int, optional): The maximum tolerance range for matching. Defaults to 20. tolerance_increment (int, optional): The increment in tolerance range for each iteration. Defaults to 2. Returns: None The function performs the following steps: 1. Calculates the proxy age of the child based on the parent's age and minimum age of parent. 2. Iterates through the list of children to find a match within the initial tolerance range. 3. If no match is found, increases the tolerance range and retries until the maximum tolerance is reached. 4. Adds the matched child to the parent's household and removes the child from the list of children. 5. Logs the matching process and results. \"\"\" # Age difference heuristic based on the parent's age proxy_age_of_child = parent . age - min_age_of_parent #logger.info(f\"match_child_to_parent: Parent Age: {parent.age}. Calculated Proxy Age of Child: {proxy_age_of_child}.\") tolerance = initial_tolerance children_to_remove = [] while tolerance <= max_tolerance and not children_to_remove : #logger.info(f\"match_child_to_parent: Checking with tolerance: {tolerance} years\") # Get potential matches based on current tolerance potential_matches = [ child for child in list_of_children if abs ( child . age - proxy_age_of_child ) < tolerance ] # If there are potential matches, sort them by age (older children first) potential_matches . sort ( key = lambda x : x . age , reverse = True ) if potential_matches : # Pick the oldest child from potential matches chosen_child = potential_matches [ 0 ] #logger.info(f\"match_child_to_parent: Matched child {chosen_child.age} to parent {parent.age} with tolerance {tolerance} years.\") parent . household . add_child ( chosen_child ) logger . info ( f \"Matched child (age: { chosen_child . age } ) to household with parent (age: { parent . age } )\" ) children_to_remove . append ( chosen_child ) else : tolerance += tolerance_increment #logger.info(f\"match_child_to_parent: No suitable children found for parent {parent.age} of {parent.household_type} with current tolerance. Increasing tolerance.\") # Remove matched children from the list for child in children_to_remove : list_of_children . remove ( child ) if not children_to_remove : logger . info ( f \"match_child_to_parent: No suitable children found for parent { parent . age } of { parent . household_type } even with max tolerance of { max_tolerance } years.\" )","title":"match_child_to_parent"},{"location":"utils/#tripsender.utils.match_list_household_children","text":"Match children to households based on the number of children needed. This function matches children to households based on the number of children each household needs. It expands the household list based on the number of children required and pairs each child with a household. Parameters: Name Type Description Default list_household list The list of households. required list_children list The list of children to be matched. required Returns: Type Description None The function performs the following steps: 1. Expands the household list based on the number of children needed in each household. 2. Sorts the household list based on the age of a randomly chosen parent. 3. Sorts the children list by age. 4. Pairs each child with a household and adds the child to the household. 5. Logs the matching process and results. Source code in tripsender\\utils.py 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 def match_list_household_children ( list_household , list_children ): \"\"\" Match children to households based on the number of children needed. This function matches children to households based on the number of children each household needs. It expands the household list based on the number of children required and pairs each child with a household. Args: list_household (list): The list of households. list_children (list): The list of children to be matched. Returns: None The function performs the following steps: 1. Expands the household list based on the number of children needed in each household. 2. Sorts the household list based on the age of a randomly chosen parent. 3. Sorts the children list by age. 4. Pairs each child with a household and adds the child to the household. 5. Logs the matching process and results. \"\"\" new_list_household = [] # Expand household list based on the number of children in each household for household in list_household : stack_number = household . children temp_household_stack = [ household for _ in range ( stack_number )] new_list_household . extend ( temp_household_stack ) # Sort the household list based on the age of a randomly chosen parent (from oldest to youngest) #new_list_household.sort(key=lambda household: random.choice([member.age for member in household.members if not member.is_child])) # Sort the children list by age (oldest first) list_children . sort ( key = lambda child : child . age , reverse = True ) # Pair each child with a household for child in list_children : household = new_list_household . pop () parents = [ member for member in household . members if not member . is_child ] parent = random . choice ( parents ) #logger.info(f\"Matched child (age: {child.age}) to household with parent (age: {parent.age})\") household . add_child ( child )","title":"match_list_household_children"},{"location":"utils/#tripsender.utils.parse_num_children","text":"Parse the number of children from a string. This function extracts the number of children from the given data string using regular expressions. Parameters: Name Type Description Default data str The input string containing the number of children. required Returns: Name Type Description int The number of children extracted from the input string. Returns 0 if no number is found. Example parse_num_children(\"3 children\") 3 Source code in tripsender\\utils.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 def parse_num_children ( data ): \"\"\" Parse the number of children from a string. This function extracts the number of children from the given data string using regular expressions. Args: data (str): The input string containing the number of children. Returns: int: The number of children extracted from the input string. Returns 0 if no number is found. Example: >>> parse_num_children(\"3 children\") 3 \"\"\" return int ( re . search ( r '\\d+' , data ) . group ()) if re . search ( r '\\d+' , data ) else 0","title":"parse_num_children"},{"location":"utils/#tripsender.utils.preprocess_household_data","text":"Preprocess household data for model input. This function preprocesses household data by ensuring all required columns are present, dropping specified columns, and optionally one-hot encoding categorical variables. Parameters: Name Type Description Default aligned_columns list List of columns to ensure are present in the DataFrame. [] drop list List of columns to drop from the DataFrame. [] onehotencode bool Whether to one-hot encode categorical variables. Defaults to False. False Returns: Name Type Description tuple A tuple containing the preprocessed DataFrame and the list of adult individuals. The function performs the following steps: 1. Fetches household data and adult individuals. 2. Ensures all specified columns are present in the DataFrame. 3. Drops specified columns from the DataFrame. 4. Optionally one-hot encodes categorical variables. 5. Returns the preprocessed DataFrame and the list of adult individuals. Source code in tripsender\\utils.py 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 def preprocess_household_data ( aligned_columns = [], drop = [], onehotencode = False ): \"\"\" Preprocess household data for model input. This function preprocesses household data by ensuring all required columns are present, dropping specified columns, and optionally one-hot encoding categorical variables. Args: aligned_columns (list): List of columns to ensure are present in the DataFrame. drop (list): List of columns to drop from the DataFrame. onehotencode (bool): Whether to one-hot encode categorical variables. Defaults to False. Returns: tuple: A tuple containing the preprocessed DataFrame and the list of adult individuals. The function performs the following steps: 1. Fetches household data and adult individuals. 2. Ensures all specified columns are present in the DataFrame. 3. Drops specified columns from the DataFrame. 4. Optionally one-hot encodes categorical variables. 5. Returns the preprocessed DataFrame and the list of adult individuals. \"\"\" df , adults = Household . return_nhts ( drop = drop , onehotencode = onehotencode ) # Ensure all columns in aligned_columns are present in the DataFrame for column in aligned_columns : if column not in df . columns : df [ column ] = 0 df = df [ aligned_columns ] return df , adults","title":"preprocess_household_data"},{"location":"utils/#tripsender.utils.sample_children_category","text":"Sample a children category based on the probability matrix for the given household type. This function uses the provided probability matrix to randomly sample a children category for the specified household type. Parameters: Name Type Description Default probability_matrix dict The probability matrix for children categories. required household_type str The household type for which to sample a children category. required Returns: Name Type Description int The sampled children category. Returns None if the household type is not found in the probability matrix. The function performs the following steps: 1. Checks if the household type exists in the probability matrix. 2. Extracts children categories and their corresponding probabilities from the probability matrix. 3. Randomly samples a children category based on the extracted probabilities. 4. Returns the sampled children category. Source code in tripsender\\utils.py 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 def sample_children_category ( probability_matrix , household_type ): \"\"\" Sample a children category based on the probability matrix for the given household type. This function uses the provided probability matrix to randomly sample a children category for the specified household type. Args: probability_matrix (dict): The probability matrix for children categories. household_type (str): The household type for which to sample a children category. Returns: int: The sampled children category. Returns None if the household type is not found in the probability matrix. The function performs the following steps: 1. Checks if the household type exists in the probability matrix. 2. Extracts children categories and their corresponding probabilities from the probability matrix. 3. Randomly samples a children category based on the extracted probabilities. 4. Returns the sampled children category. \"\"\" if household_type in probability_matrix : children_categories = list ( probability_matrix [ household_type ] . keys ()) probabilities = list ( probability_matrix [ household_type ] . values ()) # Sample a children category based on the probabilities sampled_category = random . choices ( children_categories , probabilities )[ 0 ] return ( sampled_category ) else : return ( None )","title":"sample_children_category"},{"location":"utils/#tripsender.utils.sample_household_for_older_child","text":"Sample a household type based on the probability matrix for older children. This function uses the provided probability matrix to randomly sample a household type that is likely to have older children. Parameters: Name Type Description Default probability_matrix dict The probability matrix for households with older children. required Returns: Name Type Description str The sampled household type. The function performs the following steps: 1. Extracts household categories and their corresponding probabilities from the probability matrix. 2. Randomly samples a household type based on the extracted probabilities. 3. Returns the sampled household type. Source code in tripsender\\utils.py 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def sample_household_for_older_child ( probability_matrix ): \"\"\" Sample a household type based on the probability matrix for older children. This function uses the provided probability matrix to randomly sample a household type that is likely to have older children. Args: probability_matrix (dict): The probability matrix for households with older children. Returns: str: The sampled household type. The function performs the following steps: 1. Extracts household categories and their corresponding probabilities from the probability matrix. 2. Randomly samples a household type based on the extracted probabilities. 3. Returns the sampled household type. \"\"\" # Sample a household type based on the probabilities household_categories = list ( probability_matrix . keys ()) probabilities = list ( probability_matrix . values ()) sampled_household_type = random . choices ( household_categories , probabilities )[ 0 ] return ( sampled_household_type )","title":"sample_household_for_older_child"},{"location":"utils/#tripsender.utils.search_primary_area","text":"Search for the best matching primary area from the DataFrame based on the query. This function takes a query string and searches for the best matching primary area from the given DataFrame. It calculates the similarity between the query and each primary area in the DataFrame, and returns the best match. Parameters: Name Type Description Default query str The query string to search for. required df DataFrame The DataFrame containing primary areas. Defaults to reading from PATH_PRIMARY_AREA. read_csv ( PATH_PRIMARY_AREA ) Returns: Name Type Description str The best matching primary area. The function performs the following steps: 1. Converts the query to lowercase for case-insensitive comparison. 2. Iterates through each primary area in the DataFrame, converting it to lowercase. 3. Calculates the similarity between the query and the current primary area. 4. Updates the best match if the current primary area has a higher similarity score. 5. Returns the best matching primary area. Source code in tripsender\\utils.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def search_primary_area ( query , df = pd . read_csv ( PATH_PRIMARY_AREA )): \"\"\" Search for the best matching primary area from the DataFrame based on the query. This function takes a query string and searches for the best matching primary area from the given DataFrame. It calculates the similarity between the query and each primary area in the DataFrame, and returns the best match. Args: query (str): The query string to search for. df (pd.DataFrame): The DataFrame containing primary areas. Defaults to reading from PATH_PRIMARY_AREA. Returns: str: The best matching primary area. The function performs the following steps: 1. Converts the query to lowercase for case-insensitive comparison. 2. Iterates through each primary area in the DataFrame, converting it to lowercase. 3. Calculates the similarity between the query and the current primary area. 4. Updates the best match if the current primary area has a higher similarity score. 5. Returns the best matching primary area. \"\"\" query = query . lower () # Convert query to lowercase best_match = None best_similarity = 0 for area in df [ 'primary_area' ]: area_lower = area . lower () # Convert area to lowercase similarity = calculate_similarity ( query , area_lower ) # Calculate similarity # Update the best match if the current area has higher similarity if similarity > best_similarity : best_similarity = similarity best_match = area return best_match","title":"search_primary_area"},{"location":"utils/#tripsender.utils.split_households_by_householdtype","text":"Split individuals into different lists based on their household type. This function splits individuals into different lists based on their household type, such as children, single parents, living alone, married, cohabiting, and others. Returns: Name Type Description tuple A tuple containing lists of individuals for each household type. The function performs the following steps: 1. Iterates through each individual and categorizes them based on their household type. 2. Adds the individuals to the corresponding list for their household type. 3. Logs the number of individuals in each household type. 4. Returns the lists of individuals for each household type. Source code in tripsender\\utils.py 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 def split_households_by_householdtype (): \"\"\" Split individuals into different lists based on their household type. This function splits individuals into different lists based on their household type, such as children, single parents, living alone, married, cohabiting, and others. Returns: tuple: A tuple containing lists of individuals for each household type. The function performs the following steps: 1. Iterates through each individual and categorizes them based on their household type. 2. Adds the individuals to the corresponding list for their household type. 3. Logs the number of individuals in each household type. 4. Returns the lists of individuals for each household type. \"\"\" # Create a list of households children = [] single_parents = [] living_alone = [] married_males = [] married_females = [] cohabiting_males = [] cohabiting_females = [] others = [] # Separate individuals into different lists based on their category for person in Person . instances : if person . household_type == CHILD : # Child person . is_child = True children . append ( person ) elif person . household_type == SINGLE_PARENT : # Single parent #person.hasChild = True single_parents . append ( person ) elif person . household_type == LIVING_ALONE : # Living alone living_alone . append ( person ) elif person . household_type == MARRIED : # Married if person . sex == MALE : married_males . append ( person ) else : married_females . append ( person ) elif person . household_type == COHABITING : # Cohabiting if person . sex == MALE : cohabiting_males . append ( person ) else : cohabiting_females . append ( person ) else : others . append ( person ) # Not living alone/ other # Print the number of individuals in each category logger . info ( f \"Number of children: { len ( children ) } \" ) logger . info ( f \"Number of single parents: { len ( single_parents ) } \" ) logger . info ( f \"Number of individuals living alone: { len ( living_alone ) } \" ) logger . info ( f \"Number of married males: { len ( married_males ) } \" ) logger . info ( f \"Number of married females: { len ( married_females ) } \" ) logger . info ( f \"Number of cohabiting males: { len ( cohabiting_males ) } \" ) logger . info ( f \"Number of cohabiting females: { len ( cohabiting_females ) } \" ) logger . info ( f \"Number of others: { len ( others ) } \" ) return children , single_parents , living_alone , married_males , married_females , cohabiting_males , cohabiting_females , others","title":"split_households_by_householdtype"}]}